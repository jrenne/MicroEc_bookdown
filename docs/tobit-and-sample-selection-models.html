<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Tobit and sample-selection models | Micro-Econometrics</title>
<meta name="author" content="Jean-Paul Renne">
<meta name="description" content="6.1 Tobit models In some situations, the dependent variable is incompletely observed, which may result in a non-representative sample. Typically, in some cases, observations of the dependent...">
<meta name="generator" content="bookdown 0.34 with bs4_book()">
<meta property="og:title" content="Chapter 6 Tobit and sample-selection models | Micro-Econometrics">
<meta property="og:type" content="book">
<meta property="og:description" content="6.1 Tobit models In some situations, the dependent variable is incompletely observed, which may result in a non-representative sample. Typically, in some cases, observations of the dependent...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Tobit and sample-selection models | Micro-Econometrics">
<meta name="twitter:description" content="6.1 Tobit models In some situations, the dependent variable is incompletely observed, which may result in a non-representative sample. Typically, in some cases, observations of the dependent...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.0/transition.js"></script><script src="libs/bs3compat-0.5.0/tabs.js"></script><script src="libs/bs3compat-0.5.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="my-style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Micro-Econometrics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Micro-Econometrics</a></li>
<li><a class="" href="ChapterLS.html"><span class="header-section-number">1</span> Linear Regressions</a></li>
<li><a class="" href="Panel.html"><span class="header-section-number">2</span> Panel regressions</a></li>
<li><a class="" href="estimation-methods.html"><span class="header-section-number">3</span> Estimation Methods</a></li>
<li><a class="" href="binary-choice-models.html"><span class="header-section-number">4</span> Binary-choice models</a></li>
<li><a class="" href="multiple-choice-models.html"><span class="header-section-number">5</span> Multiple Choice Models</a></li>
<li><a class="active" href="tobit-and-sample-selection-models.html"><span class="header-section-number">6</span> Tobit and sample-selection models</a></li>
<li><a class="" href="models-of-count-data.html"><span class="header-section-number">7</span> Models of Count Data</a></li>
<li><a class="" href="append.html"><span class="header-section-number">8</span> Appendix</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="tobit-and-sample-selection-models" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Tobit and sample-selection models<a class="anchor" aria-label="anchor" href="#tobit-and-sample-selection-models"><i class="fas fa-link"></i></a>
</h1>
<div id="tobit" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Tobit models<a class="anchor" aria-label="anchor" href="#tobit"><i class="fas fa-link"></i></a>
</h2>
<p>In some situations, the dependent variable is incompletely observed, which may result in a non-representative sample. Typically, in some cases, observations of the dependent variable can have a lower and/or an upper limit, while the “true”, underlying, dependent variable has not. In this case, OLS regression may lead to inconsistent parameter estimates.</p>
<p>Tobit models have been designed to address some of these situations. This approach has been named after James Tobin, who developed this model in the late 50s (see <span class="citation">Tobin (<a href="references.html#ref-Tobin_1956">1956</a>)</span>).</p>
<p>Figure <a href="tobit-and-sample-selection-models.html#fig:tobit1">6.1</a> illustrates the situation. The dots (white and black) represent the “true” observations. Now, assume that only the black are observed. If ones uses these observations in an OLS regression to estimate the relatonship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, then one gets the red line. It is clear that the sensitivity of <span class="math inline">\(y\)</span> to <span class="math inline">\(x\)</span> is then underestimated. The blue line is the line one would obtain if white dots were also observed; the grey line represents the model used to genrate the data (<span class="math inline">\(y_i=x_i+\varepsilon_i\)</span>).</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:tobit1"></span>
<img src="MicroEc_files/figure-html/tobit1-1.png" alt="Bias in the case of sample selection. The grey line represents the population regression line. The model is $y_i = x_i + \varepsilon_i$, with $\varepsilon_{i,t} \sim \mathcal{N}(0,1)$. The red line is the OLS regression line based on black dots only." width="672"><p class="caption">
Figure 6.1: Bias in the case of sample selection. The grey line represents the population regression line. The model is <span class="math inline">\(y_i = x_i + \varepsilon_i\)</span>, with <span class="math inline">\(\varepsilon_{i,t} \sim \mathcal{N}(0,1)\)</span>. The red line is the OLS regression line based on black dots only.
</p>
</div>
<p>Assume that the (partially) observed dependent variable follows:
<span class="math display">\[
y^* = \boldsymbol\beta'\mathbf{x} + \varepsilon,
\]</span>
with <span class="math inline">\(\varepsilon\)</span> is drawn from a distribution characterized by a p.d.f. denoted by <span class="math inline">\(f_{\boldsymbol\gamma}^*\)</span> and a c.d.f. denoted by <span class="math inline">\(F_{\boldsymbol\gamma}^*\)</span>; these functions depend on a vector of parameters <span class="math inline">\(\boldsymbol{\gamma}\)</span>.</p>
<p>The observed dependent variable is:
<span class="math display">\[\begin{eqnarray*}
\mbox{Censored case:}&amp;&amp;y = \left\{
\begin{array}{ccc}
y^* &amp;if&amp; y^*&gt;L \\
L &amp;if&amp; y^*\le L,
\end{array}
\right.\\
\mbox{Truncated case:}&amp;&amp;y = \left\{
\begin{array}{ccc}
y^* &amp;if&amp; y^*&gt;L \\
- &amp;if&amp; y^*\le L,
\end{array}
\right.
\end{eqnarray*}\]</span>
where “<span class="math inline">\(-\)</span>” stands for missing observations.</p>
<p>This formulation is easily extended to censoring from above (<span class="math inline">\(L \rightarrow U\)</span>), or censoring from both below and above.</p>
<p>The model parameters are gathered in vector <span class="math inline">\(\theta = [\boldsymbol\beta',\boldsymbol\gamma']'\)</span>. Let us write the conditional p.d.f. of the observed variable:
<span class="math display">\[\begin{eqnarray*}
\mbox{Censored case:}&amp;&amp; f(y|\mathbf{x};\theta) = \left\{
\begin{array}{ccc}
f_{\boldsymbol\gamma}^*(y -  \boldsymbol\beta'\mathbf{x}) &amp;if&amp; y&gt;L \\
F_{\boldsymbol\gamma}^*(L-  \boldsymbol\beta'\mathbf{x}) &amp;if&amp; y = L,
\end{array}
\right.\\
\mbox{Truncated case:}&amp;&amp;  f(y|\mathbf{x};\theta) =
\dfrac{f_{\boldsymbol\gamma}^*(y -  \boldsymbol\beta'\mathbf{x})}{1 - F_{\boldsymbol\gamma}^*(L-  \boldsymbol\beta'\mathbf{x})} \quad \mbox{with} \quad y&gt;L.
\end{eqnarray*}\]</span></p>
<p>The (conditional) log-likelihood function is then given by:
<span class="math display">\[
\log \mathcal{L}(\theta;\mathbf{y},\mathbf{X}) = \sum_{i=1}^n \log f(y_i|\mathbf{x}_i;\theta).
\]</span>
In the censored case, we have:
<span class="math display">\[\begin{eqnarray*}
\log \mathcal{L}(\theta;\mathbf{y},\mathbf{X}) &amp;=&amp; \sum_{i=1}^n \left\{
\mathbb{I}_{\{y_i=L\}}\log\left[F_{\boldsymbol\gamma}^*(L-  \boldsymbol\beta'\mathbf{x}_i)\right] + \right.\\
&amp;&amp; \left. \mathbb{I}_{\{y_i&gt;0\}} \log \left[f_{\boldsymbol\gamma}^*(y_i -  \boldsymbol\beta'\mathbf{x}_i)\right]\right\}.
\end{eqnarray*}\]</span></p>
<p>The Tobit, or censored/truncated normal regression model, corresponds to the case described above, but with Gaussian errors <span class="math inline">\(\varepsilon\)</span>. Specifically:
<span class="math display">\[
y^* = \boldsymbol\beta'\mathbf{x} + \varepsilon,
\]</span>
with <span class="math inline">\(\varepsilon \sim \,i.i.d.\,\mathcal{N}(0,\sigma^2)\)</span> (<span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\boldsymbol\gamma = \sigma^2\)</span>).</p>
<p>Without loss of generality, we can assume that <span class="math inline">\(L=0\)</span>. (One can shift observed data if necessary.)</p>
<ul>
<li><p>The censored density (with <span class="math inline">\(L=0\)</span>) is given by:
<span class="math display">\[
f(y) = \left[
\frac{1}{\sqrt{2 \pi \sigma^2}}\exp\left(-\frac{1}{2 \sigma^2}(y - \boldsymbol\beta'\mathbf{x})^2\right)
\right]^{\mathbb{I}_{\{y&gt;0\}}}
\left[
1 - \Phi\left(\frac{\boldsymbol\beta'\mathbf{x}}{\sigma}\right)
\right]^{\mathbb{I}_{\{y=0\}}}.
\]</span></p></li>
<li><p>The truncated density (with <span class="math inline">\(L=0\)</span>) is given by:
<span class="math display">\[
f(y) = \frac{1}{\Phi(\boldsymbol\beta'\mathbf{x})}
\frac{1}{\sqrt{2 \pi \sigma^2}}\exp\left(-\frac{1}{2 \sigma^2}(y - \boldsymbol\beta'\mathbf{x})^2\right).
\]</span></p></li>
</ul>
<p>Results usually heavily rely on distributional assumptions (more than in uncensored/untruncated case). The framework is easy to extend to an heteroskedastic case, for instance by setting <span class="math inline">\(\sigma_i^2=\exp(\alpha'\mathbf{x}_i)\)</span>. Such a situation is illustrated by Figure <a href="tobit-and-sample-selection-models.html#fig:tobit2">6.2</a>.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:tobit2"></span>
<img src="MicroEc_files/figure-html/tobit2-1.png" alt="Censored dataset with heteroskedasticitiy. The model is $y_i = x_i + \varepsilon_i$, with $\varepsilon_{i,t} \sim \mathcal{N}(0,\sigma_i^2)$ where $\sigma_i = \exp(-1 + x_i)$." width="672"><p class="caption">
Figure 6.2: Censored dataset with heteroskedasticitiy. The model is <span class="math inline">\(y_i = x_i + \varepsilon_i\)</span>, with <span class="math inline">\(\varepsilon_{i,t} \sim \mathcal{N}(0,\sigma_i^2)\)</span> where <span class="math inline">\(\sigma_i = \exp(-1 + x_i)\)</span>.
</p>
</div>
<p>Let us consider the conditional means of <span class="math inline">\(y\)</span> in the general case, i.e., for any <span class="math inline">\(\varepsilon\)</span> distribution. Assume <span class="math inline">\(\mathbf{x}\)</span> is observed, such that expectations are conditional on <span class="math inline">\(\mathbf{x}\)</span>.</p>
<ul>
<li><p>For data that are left-truncated at 0, we have:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y) &amp;=&amp; \mathbb{E}(y^*|y^*&gt;0) = \underbrace{\boldsymbol\beta'\mathbf{x}}_{=\mathbb{E}(y^*)} + \underbrace{\mathbb{E}(\varepsilon|\varepsilon&gt;-\boldsymbol\beta'\mathbf{x})}_{&gt;0} &gt; \mathbb{E}(y^*).
\end{eqnarray*}\]</span></p></li>
<li><p>Consider data that are left-censored at 0. By Bayes, we have:
<span class="math display">\[
f_{y^*|y^*&gt;0}(u) = \frac{f_{y^*}(u)}{\mathbb{P}(y^*&gt;0)}\mathbb{I}_{\{u&gt;0\}}.
\]</span>
Therefore:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y^*|y^*&gt;0) &amp;=&amp; \frac{1}{\mathbb{P}(y^*&gt;0)} \int_{-\infty}^\infty u\, f_{y^*}(u)\mathbb{I}_{\{u&gt;0\}} du \\
&amp;=&amp;  \frac{1}{\mathbb{P}(y^*&gt;0)} \mathbb{E}(\underbrace{y^*\mathbb{I}_{\{y^*&gt;0\}}}_{=y}),
\end{eqnarray*}\]</span>
and, further:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y) &amp;=&amp;  \mathbb{P}(y^*&gt;0)\mathbb{E}(y^*|y^*&gt;0)\\
&amp;&gt;&amp;  \mathbb{E}(y^*) =  \mathbb{P}(y^*&gt;0)\mathbb{E}(y^*|y^*&gt;0) +  \mathbb{P}(y^*&lt;0)\underbrace{\mathbb{E}(y^*|y^*&lt;0)}_{&lt;0}.
\end{eqnarray*}\]</span></p></li>
</ul>
<p>Now, let us come back to the Tobit (i.e., Gaussian case) case.</p>
<ul>
<li><p>For data that are left-truncated at 0:
<span class="math display" id="eq:Econdtruncated">\[\begin{eqnarray}
\mathbb{E}(y) &amp;=&amp; \boldsymbol\beta'\mathbf{x} + \mathbb{E}(\varepsilon|\varepsilon&gt;-\boldsymbol\beta'\mathbf{x}) \nonumber\\
&amp;=&amp;  \boldsymbol\beta'\mathbf{x} + \sigma \underbrace{\frac{\phi(\boldsymbol\beta'\mathbf{x}/\sigma)}{\Phi(\boldsymbol\beta'\mathbf{x}/\sigma)}}_{=: \lambda(\boldsymbol\beta'\mathbf{x}/\sigma)} = \sigma \left( \frac{\boldsymbol\beta'\mathbf{x}}{\sigma} + \lambda\left(\frac{\boldsymbol\beta'\mathbf{x}}{\sigma}\right)\right). \tag{6.1}
\end{eqnarray}\]</span>
where the penultimate line is obtained by using Eq. <a href="append.html#eq:Etrunc">(8.4)</a>.</p></li>
<li><p>For data that are left-censored at 0:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y) &amp;=&amp;  \mathbb{P}(y^*&gt;0)\mathbb{E}(y^*|y^*&gt;0)\\
&amp;=&amp;  \Phi\left( \frac{\boldsymbol\beta'\mathbf{x}}{\sigma}\right) \sigma \left(
\frac{\boldsymbol\beta'\mathbf{x}}{\sigma} +   \lambda\left(\frac{\boldsymbol\beta'\mathbf{x}}{\sigma}\right)
\right).
\end{eqnarray*}\]</span></p></li>
</ul>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:tobit3"></span>
<img src="MicroEc_files/figure-html/tobit3-1.png" alt="Conditional means of $y$ in Tobit models. The model is $y_i = x_i + \varepsilon_i$, with $\varepsilon_i \sim \mathcal{N}(0,1)$." width="672"><p class="caption">
Figure 6.3: Conditional means of <span class="math inline">\(y\)</span> in Tobit models. The model is <span class="math inline">\(y_i = x_i + \varepsilon_i\)</span>, with <span class="math inline">\(\varepsilon_i \sim \mathcal{N}(0,1)\)</span>.
</p>
</div>
<!-- %\begin{frame}{Tobit Model} -->
<!-- %\begin{footnotesize} -->
<!-- %\begin{itemize} -->
<!-- %  \item It is easily seen that: -->
<!-- %  $$ -->
<!-- %  \mathbb{P}(y^* \le 0) =  \Phi\left(-\frac{\boldsymbol\beta'\bv{x}}{\sigma}\right) = 1 - \Phi\left(\frac{\boldsymbol\beta'\bv{x}}{\sigma}\right). -->
<!-- %  $$ -->
<!-- %  \item If $y=0$ when $y^*<0$, then the p.d.f. of $y$ therefore is: -->
<!-- %  $$ -->
<!-- %  f(y) = \left[1 - \Phi\left(\frac{\boldsymbol\beta'\bv{x}}{\sigma}\right)\right]^{\mathbb{I}_{\{y=0\}}} -->
<!-- %  \left[\frac{1}{\sqrt{2\pi \sigma^2}}\exp\left(-\frac{(y - \boldsymbol\beta'\bv{x})}{2\sigma^2}\right)\right]^{\mathbb{I}_{\{y>0\}}}. -->
<!-- %  $$ -->
<!-- %  \item The log-likelihood function is: -->
<!-- %  \begin{eqnarray*} -->
<!-- %  \log \mathcal{L}(\boldsymbol\beta,\sigma^2;\bv{y},\bv{X}) &=& \sum_{i=1}^n \left\{ -->
<!-- %  \mathbb{I}_{\{y_i=0\}}\log\left[1 - \Phi\left(\frac{\boldsymbol\beta'\bv{x}_i}{\sigma}\right)\right] + \right.\\ -->
<!-- %  && \left. \mathbb{I}_{\{y_i>0\}} \log \left[\frac{1}{\sqrt{2\pi \sigma^2}}\exp\left(-\frac{(y_i - \boldsymbol\beta'\bv{x}_i)}{2\sigma^2}\right)\right]\right\}. -->
<!-- %  \end{eqnarray*} -->
<!-- %\end{itemize} -->
<!-- %\end{footnotesize} -->
<!-- %\end{frame} -->
<p><strong>Heckit regression</strong></p>
<p>The previous formula (Eq. <a href="tobit-and-sample-selection-models.html#eq:Econdtruncated">(6.1)</a>) can in particular be used in an alternative estimation approach, namely the Heckman two-step estimation. This approach is based on two steps:<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;See 16.10.2 of &lt;span class="citation"&gt;Cameron and Trivedi (&lt;a href="references.html#ref-Cameron_Trivedi_2005"&gt;2005&lt;/a&gt;)&lt;/span&gt; for the derivation of asymptotic standard errors of &lt;span class="math inline"&gt;\(\boldsymbol\beta\)&lt;/span&gt;.&lt;/p&gt;'><sup>16</sup></a></p>
<ol style="list-style-type: decimal">
<li><p>Using the complete sample, fit a Probit model of <span class="math inline">\(\mathbb{I}_{\{y_i&gt;0\}}\)</span> on <span class="math inline">\(\mathbf{x}\)</span>. This provides a consistent estimate of <span class="math inline">\(\frac{\boldsymbol\beta}{\sigma}\)</span>, and therefore of <span class="math inline">\(\lambda(\boldsymbol\beta'\mathbf{x}/\sigma)\)</span>. (Indeed, if <span class="math inline">\(z_i \equiv \mathbb{I}_{\{y_i&gt;0\}}\)</span>, then <span class="math inline">\(\mathbb{P}(z_i=1|\mathbf{x}_i;\boldsymbol\beta/\sigma)=\Phi(\boldsymbol\beta'\mathbf{x}_i/\sigma)\)</span>.)</p></li>
<li><p>Using the truncated sample only: run an OLS regression of <span class="math inline">\(\mathbf{y}\)</span> on <span class="math inline">\(\left\{\mathbf{x},\lambda(\boldsymbol\beta'\mathbf{x}/\sigma)\right\}\)</span> (having Eq. <a href="tobit-and-sample-selection-models.html#eq:Econdtruncated">(6.1)</a> in mind). This provides a consistent estimate of <span class="math inline">\((\boldsymbol\beta,\sigma)\)</span>.</p></li>
</ol>
<p>The underlying specification is of the form:
<span class="math display">\[
\mbox{Conditional mean} + \mbox{disturbance}.
\]</span>
where “Conditional mean” comes from Eq. <a href="tobit-and-sample-selection-models.html#eq:Econdtruncated">(6.1)</a> and “disturbance” is an error with zero conditional mean.</p>
<p>This approach is also applied to the case of <strong>sample selection models</strong> (Section <a href="tobit-and-sample-selection-models.html#SSM">6.2</a>).</p>
<div class="example">
<p><span id="exm:WageMroz1" class="example"><strong>Example 6.1  (Wage prediction) </strong></span>The present example is based on the dataset used in <span class="citation">Mroz (<a href="references.html#ref-Mroz_1987">1987</a>)</span> (whicht is part of the <code>sampleSelection</code> package).</p>
<div class="sourceCode" id="cb125"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sampleSelection.org">sampleSelection</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AER</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Mroz87"</span><span class="op">)</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span> <span class="op">&lt;-</span> <span class="cn">NaN</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">[</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp</span><span class="op">==</span><span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"yes"</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">[</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp</span><span class="op">==</span><span class="fl">0</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"no"</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">)</span></span>
<span><span class="va">ols</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">wage</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>,data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">Mroz87</span>,<span class="va">lfp</span><span class="op">==</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tobit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/AER/man/tobit.html">tobit</a></span><span class="op">(</span><span class="va">wage</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>,</span>
<span>               left <span class="op">=</span> <span class="fl">0</span>, right <span class="op">=</span> <span class="cn">Inf</span>,</span>
<span>               data<span class="op">=</span><span class="va">Mroz87</span><span class="op">)</span></span>
<span><span class="va">Heckit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sampleSelection/man/selection.html">heckit</a></span><span class="op">(</span><span class="va">lfp</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>, <span class="co"># selection equation</span></span>
<span>                 <span class="va">wage</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>, <span class="co"># outcome equation</span></span>
<span>                 data<span class="op">=</span><span class="va">Mroz87</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">ols</span>,<span class="va">Heckit</span>,<span class="va">tobit</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span>,type<span class="op">=</span><span class="st">"text"</span>,omit.stat <span class="op">=</span> <span class="st">"f"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ======================================================================
##                                    Dependent variable:                
##                     --------------------------------------------------
##                                            wage                       
##                           OLS           Heckman           Tobit       
##                                        selection                      
##                           (1)             (2)              (3)        
## ----------------------------------------------------------------------
## educ                    0.481***       0.759***         0.642***      
##                         (0.067)         (0.270)          (0.081)      
## exper                    0.032           0.430          0.461***      
##                         (0.062)         (0.369)          (0.068)      
## I(exper2)               -0.0003         -0.008          -0.009***     
##                         (0.002)         (0.008)          (0.002)      
## city                     0.449           0.113           -0.087       
##                         (0.318)         (0.522)          (0.378)      
## Constant               -2.561***        -12.251        -10.395***     
##                         (0.929)         (8.853)          (1.095)      
## ----------------------------------------------------------------------
## Observations              428             753              753        
## R2                       0.125           0.128                        
## Adjusted R2              0.117           0.117                        
## Log Likelihood                                         -1,462.700     
## rho                                      1.063                        
## Inverse Mills Ratio                  5.165 (4.594)                    
## Residual Std. Error 3.111 (df = 423)                                  
## Wald Test                                          153.892*** (df = 4)
## ======================================================================
## Note:                                      *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Figure <a href="tobit-and-sample-selection-models.html#fig:tobit5">6.4</a> shows that, low wages, the OLS model tends to over-predict wages. The slope between observed and Tobit-predicted wages is closer to one (the adjustment line is closer to the 45-degree line.)</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:tobit5"></span>
<img src="MicroEc_files/figure-html/tobit5-1.png" alt="Predicted versus observed wages." width="672"><p class="caption">
Figure 6.4: Predicted versus observed wages.
</p>
</div>
</div>
<!-- \begin{frame}{Tobit Model} -->
<!-- \begin{footnotesize} -->
<!-- \begin{itemize} -->
<!--    \item Tobit models crucially depend on distributional assumptions. Specification tests, see m-Test (Remark\,\@ref(remark:mTest}). -->
<!--    \item Specific case of (suspected) heteroskedasticity: -->
<!--        $$ -->
<!--        H_0: \,\sigma_i^2=\sigma^2, \qquad \quad H_1:\, \sigma_i^2 = \exp(\bv{x}_i\alpha). -->
<!--        $$ -->
<!--    \href{http://cameron.econ.ucdavis.edu/mmabook/mma.html}{Cameron and Trivedi}  (16.3.7) propose an OPG LM test (see Slide\,\@ref(Slide:OPG}), based on the OLS regression: -->
<!--    $$ -->
<!--    1 = \gamma_1 \bv{s}_{i,1} + \gamma_2 \bv{s}_{i,2} + \varepsilon_i, -->
<!--    $$ -->
<!--    where $\bv{s}_{i,1} = \partial \log f(y_i,\boldsymbol\beta,\boldsymbol\alpha)/\partial \boldsymbol\beta$ and $\bv{s}_{i,2} = \partial \log f(y_i,\boldsymbol\beta,\boldsymbol\alpha)/\partial \boldsymbol\alpha$. -->
<!--    (The test statistics is $n \times R_u^2$, where $R_u^2$ is the uncentered $R^2$.) -->
<!-- \end{itemize} -->
<!-- \end{footnotesize} -->
<!-- \end{frame} -->
<p><strong>Two-part model</strong></p>
<p>In the standard Tobit framework, the model determining censored —or truncated— data <em>censoring mechanism</em> is the same as the one determining non-censored —or observed— data <em>outcome mechanism</em>. A two-part model adds flexibility by permitting the zeros and non-zeros to be generated by different densities. The second model characterizes the outcome <em>conditional on</em> the outcome being observed.</p>
<p>In a seminal paper, <span class="citation">Duan et al. (<a href="references.html#ref-Duan_et_al_1983">1983</a>)</span> employ this methodology to account for individual annual hospital expenses. The two models are then as follows:</p>
<ul>
<li>
<span class="math inline">\(1^{st}\)</span> model: <span class="math inline">\(\mathbb{P}(hosp=1|\mathbf{x}) = \Phi(\mathbf{x}_1'\boldsymbol\beta_1)\)</span>,</li>
<li>
<span class="math inline">\(2^{nd}\)</span> model: <span class="math inline">\(Expense = \exp(\mathbf{x}_2'\boldsymbol\beta_2 + \eta)\)</span>, with <span class="math inline">\(\eta \sim\,i.i.d.\, \mathcal{N}(0,\sigma_2^2)\)</span>.</li>
</ul>
<p>Specifically:
<span class="math display">\[
\mathbb{E}(Expense|\mathbf{x}_1,\mathbf{x}_2) = \Phi(\mathbf{x}_1'\boldsymbol\beta_1)\exp\left(\mathbf{x}_2'\boldsymbol\beta_2+ \frac{\sigma_2^2}{2}\right).
\]</span></p>
<p>In sample-selection models, studied in the next section, one specifies the joint distribution for the censoring and outcome mechanisms (while the two parts are independent here).</p>
</div>
<div id="SSM" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Sample Selection Models<a class="anchor" aria-label="anchor" href="#SSM"><i class="fas fa-link"></i></a>
</h2>
<p>The situation tackled by sample-selection models is the following. The dependent variable of interest, denoted by <span class="math inline">\(y_2\)</span>, depends on observed variables <span class="math inline">\(\mathbf{x}_2\)</span>. Observing <span class="math inline">\(y_2\)</span>, or not, depends on the value of a latent variable (<span class="math inline">\(y_1^*\)</span>) that is correlated to observed variables <span class="math inline">\(\mathbf{x}_1\)</span>. The difference w.r.t. the two-part model skethed above is that, even conditionally on <span class="math inline">\((\mathbf{x}_1,\mathbf{x}_2)\)</span>, <span class="math inline">\(y_1^*\)</span> and <span class="math inline">\(y_2\)</span> may be correlated.</p>
<p>As in the Tobit case, even in the simplest case of population conditional mean linear in regressors (i.e. <span class="math inline">\(y_2 = \mathbf{x}_2'\boldsymbol\beta_2 + \varepsilon_2\)</span>), OLS regression leads to inconsistent parameter estimates because the sample is not representative of the population.</p>
<p>There are two latent variables: <span class="math inline">\(y_1^*\)</span> and <span class="math inline">\(y_2^*\)</span>. We observe <span class="math inline">\(y_1\)</span> and, if the considered entity “participates”, we also observe <span class="math inline">\(y_2\)</span>. More specifically:
<span class="math display">\[\begin{eqnarray*}
y_1 &amp;=&amp; \left\{
\begin{array}{ccc}
1 &amp;\mbox{if}&amp; y_1^* &gt; 0 \\
0 &amp;\mbox{if}&amp; y_1^* \le 0
\end{array}
\right. \quad \mbox{(participation equation)}\\
y_2 &amp;=&amp; \left\{
\begin{array}{ccc}
y_2^* &amp;\mbox{if}&amp; y_1 = 1 \\
- &amp;\mbox{if}&amp; y_1 = 0
\end{array}
\right. \quad \mbox{(outcome equation).}
\end{eqnarray*}\]</span></p>
<p>Moreover:
<span class="math display">\[\begin{eqnarray*}
y_1^* &amp;=&amp; \mathbf{x}_1'\boldsymbol\beta_1 + \varepsilon_1 \\
y_2^* &amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \varepsilon_2.
\end{eqnarray*}\]</span></p>
<p>Note that the Tobit model (Section <a href="tobit-and-sample-selection-models.html#tobit">6.1</a>) is the special case where <span class="math inline">\(y_1^*=y_2^*\)</span>.</p>
<p>Usually:
<span class="math display">\[
\left[\begin{array}{c}\varepsilon_1\\\varepsilon_2\end{array}\right] \sim \mathcal{N}\left(\mathbf{0},
\left[
\begin{array}{cc}
1 &amp; \rho  \sigma_2 \\
\rho  \sigma_2 &amp; \sigma_2^2
\end{array}
\right]
\right).
\]</span>
Let us derive the likelihood associated with this model. We have:
<span class="math display" id="eq:probaPP2">\[\begin{eqnarray}
f(\underbrace{0}_{=y_1},\underbrace{-}_{=y_2}|\mathbf{x};\theta) &amp;=&amp; \mathbb{P}(y_1^*\le 0) = \Phi(-\mathbf{x}_1'\boldsymbol\beta_1) \tag{6.2}\\
f(1,y_2|\mathbf{x};\theta) &amp;=&amp; f(y_2^*|\mathbf{x};\theta) \mathbb{P}(y_1^*&gt;0|y_2^*,\mathbf{x};\theta) \nonumber \\
&amp;=&amp; \frac{1}{\sigma}\phi\left(\frac{y_2 - \mathbf{x}_2'\boldsymbol\beta_2}{\sigma}\right)  \mathbb{P}(y_1^*&gt;0|y_2,\mathbf{x};\theta).\tag{6.3}
\end{eqnarray}\]</span></p>
<p>Let us compute <span class="math inline">\(\mathbb{P}(y_1^*&gt;0|y_2,\mathbf{x};\theta)\)</span>. By Prop. <a href="append.html#prp:update">8.16</a> (in Appendix <a href="append.html#GaussianVar">8.3</a>), applied to (<span class="math inline">\(\varepsilon_1,\varepsilon_2\)</span>), we have:
<span class="math display">\[
y_1^*|y_2 \sim \mathcal{N}\left(\mathbf{x}_1'\boldsymbol\beta_1 + \frac{\rho}{\sigma_2}(y_2-\mathbf{x}_2'\boldsymbol\beta_2),1-\rho^2\right).
\]</span>
which leads to
<span class="math display" id="eq:probaPP3">\[\begin{equation}
\mathbb{P}(y_1^*&gt;0|y_2,\mathbf{x};\theta) = \Phi\left( \frac{\mathbf{x}_1'\boldsymbol\beta_1 + \dfrac{\rho}{\sigma_2}(y_2-\mathbf{x}_2'\boldsymbol\beta_2)}{\sqrt{1-\rho^2}}\right).\tag{6.4}
\end{equation}\]</span></p>
<p>Figure <a href="tobit-and-sample-selection-models.html#fig:SampleSelec">6.5</a> displays <span class="math inline">\(\mathbb{P}(y_1^*&gt;0|y_2,\mathbf{x};\theta)\)</span> for different values of <span class="math inline">\(y_2\)</span> and of <span class="math inline">\(\rho\)</span>, in the case where <span class="math inline">\(\boldsymbol\beta_1=\boldsymbol\beta_2=0\)</span>.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:SampleSelec"></span>
<img src="MicroEc_files/figure-html/SampleSelec-1.png" alt="Probability of observing $y_2$ depending on its value, for different values of conditional correlation between $y_2$ and $y_1^*$." width="672"><p class="caption">
Figure 6.5: Probability of observing <span class="math inline">\(y_2\)</span> depending on its value, for different values of conditional correlation between <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_1^*\)</span>.
</p>
</div>
<p>Using Eqs. <a href="tobit-and-sample-selection-models.html#eq:probaPP1">(6.2)</a>, <a href="tobit-and-sample-selection-models.html#eq:probaPP2">(6.3)</a> and <a href="tobit-and-sample-selection-models.html#eq:probaPP3">(6.4)</a>, one gets the log-likelihood function:
<span class="math display">\[\begin{eqnarray*}
\log \mathcal{L}(\theta;\mathbf{y},\mathbf{X}) &amp;=&amp; \sum_{i=1}^n  (1 - y_{1,i})\log \Phi(-\mathbf{x}_{1,i}'\boldsymbol\beta_1) + \\
&amp;&amp;  \sum_{i=1}^n y_{1,i} \log \left(  \frac{1}{\sigma}\phi\left(\frac{y_{2,i} - \mathbf{x}_{2,i}'\boldsymbol\beta_2}{\sigma}\right)\right) + \\
&amp;&amp;  \sum_{i=1}^n y_{1,i} \log \left(\Phi\left( \frac{\mathbf{x}_{1,i}'\boldsymbol\beta_1 + \dfrac{\rho}{\sigma_2}(y_{2,i}-\mathbf{x}_2'\boldsymbol\beta_2)}{\sqrt{1-\rho^2}}\right)\right).
\end{eqnarray*}\]</span></p>
<p>We can also compute conditional expectations:
<span class="math display" id="eq:y2y11">\[\begin{eqnarray}
\mathbb{E}(y_2^*|y_1=1,\mathbf{x}) &amp;=&amp; \mathbb{E}(\mathbb{E}(y_2^*|y_1^*,\mathbf{x})|y_1=1,\mathbf{x})\nonumber\\
&amp;=&amp; \mathbb{E}(\mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2(y_1^*-\mathbf{x}_1'\boldsymbol\beta_1)|y_1=1,\mathbf{x})\nonumber\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\mathbb{E}( \underbrace{y_1^*-\mathbf{x}_1'\boldsymbol\beta_1}_{=\varepsilon_1 \sim\mathcal{N}(0,1)}|\varepsilon_1&gt;-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x})\nonumber\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\frac{\phi(-\mathbf{x}_1'\boldsymbol\beta_1)}{1 - \Phi(-\mathbf{x}_1'\boldsymbol\beta_1)}\nonumber\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\frac{\phi(\mathbf{x}_1'\boldsymbol\beta_1)}{\Phi(\mathbf{x}_1'\boldsymbol\beta_1)}=\mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\lambda(\mathbf{x}_1'\boldsymbol\beta_1),\tag{6.5}
\end{eqnarray}\]</span>
and:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y_2^*|y_1=0,\mathbf{x}) &amp;=&amp;  \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\mathbb{E}(y_1^*-\mathbf{x}_1'\boldsymbol\beta_1|\varepsilon_1\le-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x})\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\frac{\phi(-\mathbf{x}_1'\boldsymbol\beta_1)}{1 - \Phi(-\mathbf{x}_1'\boldsymbol\beta_1)}\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 - \rho\sigma_2\frac{\phi(-\mathbf{x}_1'\boldsymbol\beta_1)}{\Phi(-\mathbf{x}_1'\boldsymbol\beta_1)}=\mathbf{x}_2'\boldsymbol\beta_2 - \rho\sigma_2\lambda(-\mathbf{x}_1'\boldsymbol\beta_1).
\end{eqnarray*}\]</span></p>
<p><strong>Heckman procedure</strong></p>
<p>As for tobit models (Section <a href="tobit-and-sample-selection-models.html#tobit">6.1</a>), we can use the Heckman procedure to estimate this model. Eq. <a href="tobit-and-sample-selection-models.html#eq:y2y11">(6.5)</a> shows that <span class="math inline">\(\mathbb{E}(y_2^*|y_1=1,\mathbf{x}) \ne \mathbf{x}_2'\boldsymbol\beta_2\)</span> when <span class="math inline">\(\rho \ne 0\)</span>. Therefore, the OLS approach yields biased estimates based when it is employed only on the sub-sample where <span class="math inline">\(y_1=1\)</span>.</p>
<p>The Heckman two-step procedure (or “Heckit”) consists in replacing <span class="math inline">\(\lambda(\mathbf{x}_1'\boldsymbol\beta_1)\)</span> appearing in Eq. <a href="tobit-and-sample-selection-models.html#eq:y2y11">(6.5)</a> with a consistent estimate of it. More precisely:</p>
<ol style="list-style-type: decimal">
<li>Get an estimate <span class="math inline">\(\widehat{\boldsymbol\beta_1}\)</span> of <span class="math inline">\(\boldsymbol\beta_1\)</span> (probit regression of <span class="math inline">\(y_1\)</span> on <span class="math inline">\(\mathbf{x}_1\)</span>).</li>
<li>Run the OLS regression (using only data associated with <span class="math inline">\(y_1=1\)</span>):
<span class="math display" id="eq:OLSregHecki\tag{6.6}on}(#eq:OLSregHeckit)
y_2  = \mathbf{x}_2'\boldsymbol\beta_2 + \rho \sigma_2 \lambda(\mathbf{x}_1'\widehat{\boldsymbol\beta_1}) + \varepsilon_2,
\end{equation}\]&lt;/span&gt;
considering &lt;span class=" math inline>\(\lambda(\mathbf{x}_1'\widehat{\boldsymbol\beta_1})\)</span> as a regressor.</li>
</ol>
<p>How to estimate <span class="math inline">\(\sigma_2^2\)</span>? By Eq. <a href="append.html#eq:Vtrunc">(8.5)</a>, we have:
<span class="math display">\[
\mathbb{V}ar(y_2|y_1^*&gt;0,\mathbf{x}) = \mathbb{V}ar(\varepsilon_2|\varepsilon_1&gt;-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x}).
\]</span>
Using that <span class="math inline">\(\varepsilon_2\)</span> can be decomposed as <span class="math inline">\(\rho\sigma_2\varepsilon_1 + \xi\)</span>, where <span class="math inline">\(\xi \sim \mathcal{N}(0,\sigma_2^2(1-\rho^2))\)</span> is independent from <span class="math inline">\(\varepsilon_1\)</span>, we get:
<span class="math display">\[
\mathbb{V}ar(y_2|y_1^*&gt;0,\mathbf{x}) = \sigma_2^2(1-\rho^2) + \rho^2\sigma_2^2 \mathbb{V}ar(\varepsilon_1|\varepsilon_1&gt;-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x}).
\]</span>
Using Eq. <a href="append.html#eq:Vtrunc2">(8.6)</a>, we get:
<span class="math display">\[
\mathbb{V}ar(\varepsilon_1|\varepsilon_1&gt;-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x}) = 1 - \mathbf{x}_1'\boldsymbol\beta_1 \lambda(\mathbf{x}_1'\boldsymbol\beta_1) - \lambda(\mathbf{x}_1'\boldsymbol\beta_1)^2,
\]</span>
which gives
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}ar(y_2|y_1^*&gt;0,\mathbf{x}) &amp;=&amp; \sigma_2^2(1-\rho^2) + \rho^2\sigma_2^2 (1 - \mathbf{x}_1'\boldsymbol\beta_1 \lambda(\mathbf{x}_1'\boldsymbol\beta_1) - \lambda(\mathbf{x}_1'\boldsymbol\beta_1)^2)\\
&amp;=&amp; \sigma_2^2 - \rho^2\sigma_2^2 \left(\mathbf{x}_1'\boldsymbol\beta_1 \lambda(\mathbf{x}_1'\boldsymbol\beta_1) + \lambda(\mathbf{x}_1'\boldsymbol\beta_1)^2\right),
\end{eqnarray*}\]</span>
and, finally:
<span class="math display">\[
\sigma_2^2 \approx \widehat{\mathbb{V}ar}(y_2|y_1^*&gt;0,\mathbf{x}) + \widehat{\rho \sigma_2}^2 \left(\mathbf{x}_1'\widehat{\boldsymbol\beta_1} \lambda(\mathbf{x}_1'\widehat{\boldsymbol\beta_1}) + \lambda(\mathbf{x}_1'\widehat{\boldsymbol\beta_1})^2\right).
\]</span></p>
<p>The Heckman procedure is computationally simple. Although computational costs are no longer an issue, the two-step solution allows certain generalisations more easily than ML, and is more robust in certain circumstances. The computation of parameter standard errors is fairly complicated because of the two steps (see <span class="citation">Cameron and Trivedi (<a href="references.html#ref-Cameron_Trivedi_2005">2005</a>)</span>, Subsection 16.10.2). Bootstrap can be resorted to.</p>
<div class="example">
<p><span id="exm:WageSample" class="example"><strong>Example 6.2  (Wage prediction) </strong></span>As in Example <a href="tobit-and-sample-selection-models.html#exm:WageMroz1">6.1</a>, let us use the <span class="citation">Mroz (<a href="references.html#ref-Mroz_1987">1987</a>)</span> dataset again, with the objective of explaining wage setting.</p>
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sampleSelection.org">sampleSelection</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AER</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Mroz87"</span><span class="op">)</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span> <span class="op">&lt;-</span> <span class="cn">NaN</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">[</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp</span><span class="op">==</span><span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"yes"</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">[</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp</span><span class="op">==</span><span class="fl">0</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"no"</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">)</span></span>
<span><span class="co">#Logit &amp; Probit (selection equation)</span></span>
<span><span class="va">logitW</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">lfp</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">age</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">kids5</span> <span class="op">+</span> <span class="va">huswage</span> <span class="op">+</span> <span class="va">educ</span>,</span>
<span>              family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Mroz87</span><span class="op">)</span> </span>
<span><span class="va">probitW</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">lfp</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">age</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">kids5</span> <span class="op">+</span> <span class="va">huswage</span> <span class="op">+</span> <span class="va">educ</span>,</span>
<span>               family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"probit"</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Mroz87</span><span class="op">)</span> </span>
<span><span class="co"># OLS for outcome:</span></span>
<span><span class="va">ols1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span> <span class="op">~</span> <span class="va">educ</span><span class="op">+</span><span class="va">exper</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span><span class="op">+</span><span class="va">city</span>,data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">Mroz87</span>,<span class="va">lfp</span><span class="op">==</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Two-step Heckman estimation</span></span>
<span><span class="va">heckvan</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/sampleSelection/man/selection.html">heckit</a></span><span class="op">(</span> <span class="va">lfp</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">age</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">kids5</span> <span class="op">+</span> <span class="va">huswage</span> <span class="op">+</span> <span class="va">educ</span>, <span class="co"># selection equation</span></span>
<span>          <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>, <span class="co"># outcome equation</span></span>
<span>          data<span class="op">=</span><span class="va">Mroz87</span> <span class="op">)</span></span>
<span><span class="co"># Maximun likelihood estimation of selection model:</span></span>
<span><span class="va">ml</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sampleSelection/man/selection.html">selection</a></span><span class="op">(</span><span class="va">lfp</span><span class="op">~</span><span class="va">age</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">age</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">+</span><span class="va">kids5</span><span class="op">+</span><span class="va">huswage</span><span class="op">+</span><span class="va">educ</span>, </span>
<span>                <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span><span class="op">~</span><span class="va">educ</span><span class="op">+</span><span class="va">exper</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">exper</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">+</span><span class="va">city</span>, data <span class="op">=</span> <span class="va">Mroz87</span><span class="op">)</span></span>
<span><span class="co"># Print selection-equation estimates:</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">logitW</span>,<span class="va">probitW</span>,<span class="va">heckvan</span>,<span class="va">ml</span>,type <span class="op">=</span> <span class="st">"text"</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          selection.equation <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ===================================================================
##                                   Dependent variable:              
##                     -----------------------------------------------
##                                           lfp                      
##                     logistic   probit      Heckman      selection  
##                                           selection                
##                        (1)       (2)         (3)           (4)     
## -------------------------------------------------------------------
## age                   0.012     0.010       0.010         0.010    
##                      (0.114)   (0.069)     (0.069)       (0.069)   
## I(age2)              -0.001    -0.0005     -0.0005       -0.0005   
##                      (0.001)   (0.001)     (0.001)       (0.001)   
## kids5               -1.409*** -0.855***   -0.855***     -0.854***  
##                      (0.198)   (0.116)     (0.115)       (0.116)   
## huswage             -0.069*** -0.042***   -0.042***     -0.042***  
##                      (0.020)   (0.012)     (0.012)       (0.013)   
## educ                0.244***  0.148***    0.148***      0.148***   
##                      (0.040)   (0.024)     (0.023)       (0.024)   
## Constant             -0.938    -0.620      -0.620        -0.615    
##                      (2.508)   (1.506)     (1.516)       (1.518)   
## -------------------------------------------------------------------
## Observations           753       753         753           753     
## R2                                          0.158                  
## Adjusted R2                                 0.148                  
## Log Likelihood      -459.955  -459.901                  -891.177   
## Akaike Inf. Crit.    931.910   931.802                             
## rho                                         0.018     0.014 (0.203)
## Inverse Mills Ratio                     0.012 (0.152)              
## ===================================================================
## Note:                                   *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<div class="sourceCode" id="cb129"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print outcome-equation estimates:</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">ols1</span>,<span class="va">heckvan</span>,<span class="va">ml</span>,type <span class="op">=</span> <span class="st">"text"</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span>,omit.stat <span class="op">=</span> <span class="st">"f"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ================================================================
##                                 Dependent variable:             
##                     --------------------------------------------
##                                      log(wage)                  
##                           OLS           Heckman      selection  
##                                        selection                
##                           (1)             (2)           (3)     
## ----------------------------------------------------------------
## educ                    0.106***       0.106***      0.106***   
##                         (0.014)         (0.017)       (0.017)   
## exper                   0.041***       0.041***      0.041***   
##                         (0.013)         (0.013)       (0.013)   
## I(exper2)               -0.001**       -0.001**      -0.001**   
##                         (0.0004)       (0.0004)      (0.0004)   
## city                     0.054           0.053         0.053    
##                         (0.068)         (0.069)       (0.069)   
## Constant               -0.531***        -0.547*      -0.544**   
##                         (0.199)         (0.289)       (0.272)   
## ----------------------------------------------------------------
## Observations              428             753           753     
## R2                       0.158           0.158                  
## Adjusted R2              0.150           0.148                  
## Log Likelihood                                       -891.177   
## rho                                      0.018     0.014 (0.203)
## Inverse Mills Ratio                  0.012 (0.152)              
## Residual Std. Error 0.667 (df = 423)                            
## ================================================================
## Note:                                *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="multiple-choice-models.html"><span class="header-section-number">5</span> Multiple Choice Models</a></div>
<div class="next"><a href="models-of-count-data.html"><span class="header-section-number">7</span> Models of Count Data</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#tobit-and-sample-selection-models"><span class="header-section-number">6</span> Tobit and sample-selection models</a></li>
<li><a class="nav-link" href="#tobit"><span class="header-section-number">6.1</span> Tobit models</a></li>
<li><a class="nav-link" href="#SSM"><span class="header-section-number">6.2</span> Sample Selection Models</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Micro-Econometrics</strong>" was written by Jean-Paul Renne. It was last built on 2025-02-13.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
