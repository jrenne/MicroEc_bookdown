<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Microeconometrics | Micro-Econometrics</title>
<meta name="author" content="Jean-Paul Renne">
<meta name="description" content="In microeconometric models, the variables of interest often feature restricted distributions —for instance with discontinuous support—, which necessitates specific models. Typical examples are...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Chapter 3 Microeconometrics | Micro-Econometrics">
<meta property="og:type" content="book">
<meta property="og:description" content="In microeconometric models, the variables of interest often feature restricted distributions —for instance with discontinuous support—, which necessitates specific models. Typical examples are...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3 Microeconometrics | Micro-Econometrics">
<meta name="twitter:description" content="In microeconometric models, the variables of interest often feature restricted distributions —for instance with discontinuous support—, which necessitates specific models. Typical examples are...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="my-style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Micro-Econometrics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Micro-Econometrics</a></li>
<li><a class="" href="Panel.html"><span class="header-section-number">1</span> Panel regressions</a></li>
<li><a class="" href="estimation-methods.html"><span class="header-section-number">2</span> Estimation Methods</a></li>
<li><a class="active" href="microeconometrics.html"><span class="header-section-number">3</span> Microeconometrics</a></li>
<li><a class="" href="append.html"><span class="header-section-number">4</span> Appendix</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="microeconometrics" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Microeconometrics<a class="anchor" aria-label="anchor" href="#microeconometrics"><i class="fas fa-link"></i></a>
</h1>
<p>In microeconometric models, the variables of interest often feature restricted distributions —for instance with discontinuous support—, which necessitates specific models. Typical examples are discrete-choice models (binary, multinomial, ordered outcomes), sample selection models (censored or truncated outcomes), and count-data models (integer outcomes). This chapter describes the estimation and interpretation of these models. It also shows how the discrete-choice models can emerge from (structural) random-utility frameworks.</p>
<div id="binary-choice-models" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Binary-choice models<a class="anchor" aria-label="anchor" href="#binary-choice-models"><i class="fas fa-link"></i></a>
</h2>
<p>In many instances, the variables to be explained (the <span class="math inline">\(y_i\)</span>’s) have only two possible values (<span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, say). That is, they are binary variables. The probability for them to be equal to either 0 or 1 may depend on independent variables, gathered in vectors <span class="math inline">\(\mathbf{x}_i\)</span> (<span class="math inline">\(K \times 1\)</span>).</p>
<p>The spectrum of applications is wide:</p>
<ul>
<li>Binary decisions (e.g. in referendums, being owner or renter, living in the city or in the countryside, in/out of the labour force,…),</li>
<li>Contamination (disease or default),</li>
<li>Success/failure (exams).</li>
</ul>
<p>Without loss of generality, the model reads:
<span class="math display">\[\begin{equation}\label{eq:binaryBenroulli}
y_i | \mathbf{X} \sim \mathcal{B}(g(\mathbf{x}_i;\boldsymbol\theta)),
\end{equation}\]</span>
where <span class="math inline">\(g(\mathbf{x}_i;\boldsymbol\theta)\)</span> is the parameter of the Bernoulli distribution. In other words, conditionally on <span class="math inline">\(\mathbf{X}\)</span>:
<span class="math display" id="eq:genericBinary">\[\begin{equation}
y_i = \left\{
\begin{array}{cl}
1 &amp; \mbox{ with probability } g(\mathbf{x}_i;\boldsymbol\theta)\\
0 &amp; \mbox{ with probability } 1-g(\mathbf{x}_i;\boldsymbol\theta),
\end{array}
\right.\tag{3.1}
\end{equation}\]</span>
where <span class="math inline">\(\boldsymbol\theta\)</span> is a vector of parameters to be estimated.</p>
<p>An estimation strategy is to assume that <span class="math inline">\(g(\mathbf{x}_i;\boldsymbol\theta)\)</span> can be proxied by <span class="math inline">\(\tilde{\boldsymbol\theta}'\mathbf{x}_i\)</span> and to run a linear regression to estimate <span class="math inline">\(\tilde{\boldsymbol\theta}\)</span> (a situation called <strong>Linear Probability Model, LPM</strong>):
<span class="math display">\[
y_i = \tilde{\boldsymbol\theta}'\mathbf{x}_i + \varepsilon_i.
\]</span>
Notwithstanding the fact that this specification does not exclude negative probabilities or probabilities greater than one, it could be compatible with the <em>assumption of zero conditional mean</em> (Hypothesis <a href="#hyp:exogeneity"><strong>??</strong></a>) and with the <em>assumption of non-correlated residuals</em> (Hypothesis <a href="#hyp:noncorrelResid"><strong>??</strong></a>), but more difficultly with the <em>homoskedasticity assumption</em> (Hypothesis <a href="#hyp:homoskedasticity"><strong>??</strong></a>). Moreover, the <span class="math inline">\(\varepsilon_i\)</span>’s cannot be Gaussian (because <span class="math inline">\(y_i \in \{0,1\}\)</span>). Hence, using a linear regression to study the relationship between <span class="math inline">\(\mathbf{x}_i\)</span> and <span class="math inline">\(y_i\)</span> can be consistent but it is inefficient.</p>
<p>Figure <a href="microeconometrics.html#fig:LPM">3.1</a> illustrates the fit resulting from an application of the LPM model to binary (dependent) variables.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:LPM"></span>
<img src="MicroEc_files/figure-html/LPM-1.png" alt="Fitting a binary variable with a linear model (Linear Probability Model, LPM). The model is $\mathbb{P}(y_i=1|x_i)=\Phi(0.5+2x_i)$, where $\Phi$ is the c.d.f. of the normal distribution and where $x_i \sim \,i.i.d.\,\mathcal{N}(0,1)$." width="95%"><p class="caption">
Figure 3.1: Fitting a binary variable with a linear model (Linear Probability Model, LPM). The model is <span class="math inline">\(\mathbb{P}(y_i=1|x_i)=\Phi(0.5+2x_i)\)</span>, where <span class="math inline">\(\Phi\)</span> is the c.d.f. of the normal distribution and where <span class="math inline">\(x_i \sim \,i.i.d.\,\mathcal{N}(0,1)\)</span>.
</p>
</div>
<p>Except for its last row (LPM case), Table <a href="microeconometrics.html#tab:foo">3.1</a> provides examples of functions <span class="math inline">\(g\)</span> valued in <span class="math inline">\([0,1]\)</span>, and that can therefore used in models of the type: <span class="math inline">\(\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta) = g(\boldsymbol\theta'\mathbf{x}_i)\)</span> (see Eq. <a href="microeconometrics.html#eq:genericBinary">(3.1)</a>). The “linear” case is given for comparison, but note that it does not satisfy <span class="math inline">\(g(\boldsymbol\theta'\mathbf{x}_i) \in [0,1]\)</span> for any value of <span class="math inline">\(\boldsymbol\theta'\mathbf{x}_i\)</span>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:foo">Table 3.1: </span> This table provides examples of function <span class="math inline">\(g\)</span>, s.t. <span class="math inline">\(\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol heta) = g(\boldsymbol\theta'\mathbf{x}_i)\)</span>. The LPM case (last row) is given for comparison but, again, it does not satisfy <span class="math inline">\(g(\boldsymbol\theta'\mathbf{x}_i) \in [0,1]\)</span> for any value of <span class="math inline">\(\boldsymbol\theta'\mathbf{x}_i\)</span>.</caption>
<colgroup>
<col width="21%">
<col width="35%">
<col width="42%">
</colgroup>
<thead><tr class="header">
<th>Model</th>
<th>Function <span class="math inline">\(g\)</span>
</th>
<th>Derivative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Probit</td>
<td><span class="math inline">\(\Phi\)</span></td>
<td><span class="math inline">\(\phi\)</span></td>
</tr>
<tr class="even">
<td>Logit</td>
<td><span class="math inline">\(\dfrac{\exp(x)}{1+\exp(x)}\)</span></td>
<td><span class="math inline">\(\dfrac{\exp(x)}{(1+\exp(x))^2}\)</span></td>
</tr>
<tr class="odd">
<td>log-log</td>
<td><span class="math inline">\(1 - \exp(-\exp(x))\)</span></td>
<td><span class="math inline">\(\exp(-\exp(x))\exp(x)\)</span></td>
</tr>
<tr class="even">
<td>linear (LPM)</td>
<td><span class="math inline">\(x\)</span></td>
<td>1</td>
</tr>
</tbody>
</table></div>
<p>Figure <a href="microeconometrics.html#fig:ProbLogit">3.2</a> displays the first three <span class="math inline">\(g\)</span> functions appearing in Table <a href="microeconometrics.html#tab:foo">3.1</a>.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:ProbLogit"></span>
<img src="MicroEc_files/figure-html/ProbLogit-1.png" alt="Probit, Logit, and Log-log functions." width="95%"><p class="caption">
Figure 3.2: Probit, Logit, and Log-log functions.
</p>
</div>
<p>The <strong>probit</strong> and the <strong>logit</strong> models are popular binary-choice models. In the probit model, we have:
<span class="math display" id="eq:probit">\[\begin{equation}
g(z) = \Phi(z),\tag{3.2}
\end{equation}\]</span>
where <span class="math inline">\(\Phi\)</span> is the c.d.f. of the normal distribution. And for the logit model:
<span class="math display" id="eq:logit">\[\begin{equation}
g(z) = \frac{1}{1+\exp(-z)}.\tag{3.3}
\end{equation}\]</span></p>
<p>Figure <a href="microeconometrics.html#fig:LPM2">3.3</a> shows the conditional probabilities associated with the (probit) model that had been used to generate the data of Figure <a href="microeconometrics.html#fig:LPM">3.1</a>.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:LPM2"></span>
<img src="MicroEc_files/figure-html/LPM2-1.png" alt="The model is $\mathbb{P}(y_i=1|x_i)=\Phi(0.5+2x_i)$, where $\Phi$ is the c.d.f. of the normal distribution and where $x_i \sim \,i.i.d.\,\mathcal{N}(0,1)$. Crosses give the model-implied probabilities of having $y_i=1$ (conditional on $x_i$)." width="95%"><p class="caption">
Figure 3.3: The model is <span class="math inline">\(\mathbb{P}(y_i=1|x_i)=\Phi(0.5+2x_i)\)</span>, where <span class="math inline">\(\Phi\)</span> is the c.d.f. of the normal distribution and where <span class="math inline">\(x_i \sim \,i.i.d.\,\mathcal{N}(0,1)\)</span>. Crosses give the model-implied probabilities of having <span class="math inline">\(y_i=1\)</span> (conditional on <span class="math inline">\(x_i\)</span>).
</p>
</div>
<div id="latent" class="section level3" number="3.1.1">
<h3>
<span class="header-section-number">3.1.1</span> Interpretation in terms of latent variable, and utility-based models<a class="anchor" aria-label="anchor" href="#latent"><i class="fas fa-link"></i></a>
</h3>
<p>The probit model has an interpretation in terms of latent variables, which, in turn, is often exploited in structural models, called <strong>Random Utility Models (RUM)</strong>. In such structural models, it is assumed that the agents that have to take the decision do so by selecting the outcome that provides them with the larger utility (for agent <span class="math inline">\(i\)</span>, two possible outcomes: <span class="math inline">\(y_i=0\)</span> or <span class="math inline">\(y_i=1\)</span>). Part of this utility is observed by the econometrician —it depends on the covariates <span class="math inline">\(\mathbf{x}_i\)</span>— and part of it is latent.</p>
<p>In the probit model, we have:
<span class="math display">\[
\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta) = \Phi(\boldsymbol\theta'\mathbf{x}_i) = \mathbb{P}(-\varepsilon_{i}&lt;\boldsymbol\theta'\mathbf{x}_i),
\]</span>
where <span class="math inline">\(\varepsilon_{i} \sim \mathcal{N}(0,1)\)</span>. That is:
<span class="math display">\[
\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta) = \mathbb{P}(0&lt; y_i^*),
\]</span>
where <span class="math inline">\(y_i^* = \boldsymbol\theta'\mathbf{x}_i + \varepsilon_i\)</span>, with <span class="math inline">\(\varepsilon_{i} \sim \mathcal{N}(0,1)\)</span>. Variable <span class="math inline">\(y_i^*\)</span> can be interpreted as a (latent) variable that determines <span class="math inline">\(y_i\)</span> (since <span class="math inline">\(y_i = \mathbb{I}_{\{y_i^*&gt;0\}}\)</span>).</p>
<p>Figure <a href="microeconometrics.html#fig:Latent">3.4</a> illustrates this situation.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:Latent"></span>
<img src="MicroEc_files/figure-html/Latent-1.png" alt="Distribution of $y_i^*$ conditional on $\bv{x}_i$." width="95%"><p class="caption">
Figure 3.4: Distribution of <span class="math inline">\(y_i^*\)</span> conditional on <span class="math inline">\(\mathbf{x}_i\)</span>.
</p>
</div>
<p>Assume that agent (<span class="math inline">\(i\)</span>) chooses <span class="math inline">\(y_i=1\)</span> if the utility associated with this choice (<span class="math inline">\(U_{i,1}\)</span>) is higher than the one associated with <span class="math inline">\(y_i=0\)</span> (that is <span class="math inline">\(U_{i,0}\)</span>). Assume further that the utility of agent <span class="math inline">\(i\)</span>, if she chooses outcome <span class="math inline">\(j\)</span> (<span class="math inline">\(\in \{0,1\}\)</span>), is given by
<span class="math display">\[
U_{i,j} = V_{i,j} + \varepsilon_{i,j},
\]</span>
where <span class="math inline">\(V_{i,j}\)</span> is the deterministic component of the utility associated with choice and where <span class="math inline">\(\varepsilon_{i,j}\)</span> is a random (agent-specific) component. Moreover, posit <span class="math inline">\(V_{i,j} = \boldsymbol\theta_j'\mathbf{x}_i\)</span>. We then have:
<span class="math display" id="eq:utility">\[\begin{eqnarray}
\mathbb{P}(y_i = 1|\mathbf{x}_i;\boldsymbol\theta) &amp;=&amp; \mathbb{P}(\boldsymbol\theta_1'\mathbf{x}_i+\varepsilon_{i,1}&gt;\boldsymbol\theta_0'\mathbf{x}_i+\varepsilon_{i,0}) \nonumber\\
&amp;=&amp; F(\boldsymbol\theta_1'\mathbf{x}_i-\boldsymbol\theta_0'\mathbf{x}_i) = F([\boldsymbol\theta_1-\boldsymbol\theta_0]'\mathbf{x}_i),\tag{3.4}
\end{eqnarray}\]</span>
where <span class="math inline">\(F\)</span> is the c.d.f. of <span class="math inline">\(\varepsilon_{i,0}-\varepsilon_{i,1}\)</span>.</p>
<p>Note that only the difference <span class="math inline">\(\boldsymbol\theta_1-\boldsymbol\theta_0\)</span> is identifiable (as opposed to <span class="math inline">\(\boldsymbol\theta_1\)</span> <em>and</em> <span class="math inline">\(\boldsymbol\theta_0\)</span>). Indeed, replacing <span class="math inline">\(U\)</span> with <span class="math inline">\(aU\)</span> (<span class="math inline">\(a&gt;0\)</span>) gives the same model. This <em>scaling</em> issue can be solved by fixing the variance of <span class="math inline">\(\varepsilon_{i,0}-\varepsilon_{i,1}\)</span>.</p>
<div class="example">
<p><span id="exm:migration" class="example"><strong>Example 3.1  (Migration and income) </strong></span>The RUM approach has been used by <span class="citation">Nakosteen and Zimmer (<a href="references.html#ref-Nakosteen_Zimmer_1980" role="doc-biblioref">1980</a>)</span> to study migration choices. Their model is based on the comparison of marginal costs and benefits associated with migration. The main ingredients of their approach are as follows:</p>
<ul>
<li>Wage that can be earned at the present location: <span class="math inline">\(y_p^* = \boldsymbol\theta_p'\mathbf{x}_p + \varepsilon_p\)</span>.</li>
<li>Migration cost: <span class="math inline">\(C^*= \boldsymbol\theta_c'\mathbf{x}_c + \varepsilon_c\)</span>.</li>
<li>Wage earned elsewhere: <span class="math inline">\(y_m^* = \boldsymbol\theta_m'\mathbf{x}_m + \varepsilon_m\)</span>.</li>
</ul>
<p>In this context, agents decision to migrate if <span class="math inline">\(y_m^* &gt; y_p^* + C^*\)</span>, i.e. if
<span class="math display">\[
y^* = y_m^* -  y_p^* - C^* =  \boldsymbol\theta'\mathbf{x} + \underbrace{\varepsilon}_{=\varepsilon_m - \varepsilon_c - \varepsilon_p}&gt;0,
\]</span>
where <span class="math inline">\(\mathbf{x}\)</span> is the union of the <span class="math inline">\(\mathbf{x}_i\)</span>s, for <span class="math inline">\(i \in \{p,m,c\}\)</span>.</p>
</div>
</div>
<div id="Avregressors" class="section level3" number="3.1.2">
<h3>
<span class="header-section-number">3.1.2</span> Alternative-Varying Regressors<a class="anchor" aria-label="anchor" href="#Avregressors"><i class="fas fa-link"></i></a>
</h3>
<p>In some cases, regressors may depend on the considered alternative (<span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>). For instance:</p>
<ul>
<li>When modeling the decision to participate in the labour force (or not), the wage depends on the alternative. Typically, it is zero if the considered agent has decided not to work (and strictly positive otherwise).</li>
<li>In the context of the choice of transportation mode, “time cost” depends on the considered transportation mode.</li>
</ul>
<p>In terms of utility, we then have:
<span class="math display">\[
V_{i,j} = {\theta^{(u)}_{j}}'\mathbf{u}_{i,j} + {\theta^{(v)}_{j}}'\mathbf{v}_{i},
\]</span>
where the <span class="math inline">\(\mathbf{u}_{i,j}\)</span>’s are regressors associated with agent <span class="math inline">\(i\)</span>, but taking different values for the different choices (<span class="math inline">\(j=0\)</span> or <span class="math inline">\(j=1\)</span>). In that case, Eq. <a href="microeconometrics.html#eq:utility">(3.4)</a> becomes:
<span class="math display" id="eq:utility2">\[\begin{equation}
\mathbb{P}(y_i = 1|\mathbf{x}_i;\boldsymbol\theta)  = F\left({\theta^{(u)}_{1}}'\mathbf{u}_{i,1}-{\theta^{(u)}_{0}}'\mathbf{u}_{i,0}+[\boldsymbol\theta_1^{(v)}-\boldsymbol\theta_0^{(v)}]'\mathbf{v}_i\right),\tag{3.5}
\end{equation}\]</span>
and, if <span class="math inline">\(\theta^{(u)}_{1}=\theta^{(u)}_{0}=\theta^{(u)}\)</span> —as is customary— we get:
<span class="math display" id="eq:utility3">\[\begin{equation}
\mathbb{P}(y_i = 1|\mathbf{x}_i;\boldsymbol\theta)  = F\left({\theta^{(u)}_{1}}'(\mathbf{u}_{i,1}-\mathbf{u}_{i,0})+[\boldsymbol\theta_1^{(v)}-\boldsymbol\theta_0^{(v)}]'\mathbf{v}_i\right).\tag{3.6}
\end{equation}\]</span></p>
<div class="example">
<p><span id="exm:FishingTable" class="example"><strong>Example 3.2  (Fishing-mode dataset) </strong></span>The fishing-mode dataset used in <span class="citation">Cameron and Trivedi (<a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref">2005</a>)</span> (Chapters 14 and 15) contains alternative-specific variables. Specifically, for each individual, the price and catch rate depend on the fishing model. In the table reported below, lines <code>price</code> and <code>catch</code> correspond to the prices and catch rates associated with the chosen alternative.</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=mlogit">mlogit</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Fishing"</span>,package<span class="op">=</span><span class="st">"mlogit"</span><span class="op">)</span></span>
<span><span class="fu">stargazer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">Fishing</span>,type<span class="op">=</span><span class="st">"text"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ==========================================================
## Statistic       N     Mean    St. Dev.    Min      Max    
## ----------------------------------------------------------
## price.beach   1,182  103.422   103.641   1.290   843.186  
## price.pier    1,182  103.422   103.641   1.290   843.186  
## price.boat    1,182  55.257    62.713    2.290   666.110  
## price.charter 1,182  84.379    63.545   27.290   691.110  
## catch.beach   1,182   0.241     0.191    0.068    0.533   
## catch.pier    1,182   0.162     0.160    0.001    0.452   
## catch.boat    1,182   0.171     0.210   0.0002    0.737   
## catch.charter 1,182   0.629     0.706    0.002    2.310   
## income        1,182 4,099.337 2,461.964 416.667 12,500.000
## ----------------------------------------------------------</code></pre>
</div>
</div>
<div id="estimation" class="section level3" number="3.1.3">
<h3>
<span class="header-section-number">3.1.3</span> Estimation<a class="anchor" aria-label="anchor" href="#estimation"><i class="fas fa-link"></i></a>
</h3>
<p>These models can be estimated by Maximum Likelihood approaches (see Section <a href="estimation-methods.html#secMLE">2.2</a>).</p>
<p>To simplify the exposition, we consider the <span class="math inline">\(\mathbf{x}_i\)</span> vectors of covariates to be deterministic. Moreover, we assume that the r.v. are independent across entities <span class="math inline">\(i\)</span>. How to write the likelihood in that case? It is easily checked that:
<span class="math display">\[
f(y_i|\mathbf{x}_i;\boldsymbol\theta) =   g(\boldsymbol\theta'\mathbf{x}_i)^{y_i}(1-g(\boldsymbol\theta'\mathbf{x}_i))^{1-y_i}.
\]</span></p>
<p>Therefore, if the observations <span class="math inline">\((\mathbf{x}_i,y_i)\)</span> are independent across entities <span class="math inline">\(i\)</span>, we obtain:
<span class="math display">\[
\log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X}) = \sum_{i=1}^{n}y_i \log[g(\boldsymbol\theta'\mathbf{x}_i)] + (1-y_i)\log[1-g(\boldsymbol\theta'\mathbf{x}_i)].
\]</span></p>
<p>The likelihood equation reads (FOC of the optimization program, see Def. <a href="estimation-methods.html#def:likFunction">2.7</a>):
<span class="math display">\[
\dfrac{\partial \log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta} = \mathbf{0},
\]</span>
that is:
<span class="math display">\[
\sum_{i=1}^{n} y_i \mathbf{x}_i\frac{g'(\boldsymbol\theta'\mathbf{x}_i)}{g(\boldsymbol\theta'\mathbf{x}_i)} - (1-y_i) \mathbf{x}_i \frac{g'(\boldsymbol\theta'\mathbf{x}_i)}{1-g(\boldsymbol\theta'\mathbf{x}_i)} = \mathbf{0}.
\]</span></p>
<p>This is a nonlinear (multivariate) equation that can be solved numerically. Under regularity conditions (Hypotheses <a href="estimation-methods.html#hyp:MLEregularity">2.1</a>), we approximately have (Prop. <a href="estimation-methods.html#prp:MLEproperties">2.4</a>):
<span class="math display">\[
\boldsymbol\theta_{MLE} \sim \mathcal{N}(\boldsymbol\theta_0,\mathbf{I}(\boldsymbol\theta_0)^{-1}),
\]</span>
where
<span class="math display">\[
\mathbf{I}(\boldsymbol\theta_0) = - \mathbb{E}_0 \left( \frac{\partial^2 \log \mathcal{L}(\theta;\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta \partial \boldsymbol\theta'}\right) = n \mathcal{I}_Y(\boldsymbol\theta_0).
\]</span></p>
<p>For finite samples, we can e.g. approximate <span class="math inline">\(\mathbf{I}(\boldsymbol\theta_0)^{-1}\)</span> by Eq. <a href="estimation-methods.html#eq:III1">(2.10)</a>:
<span class="math display">\[
\mathbf{I}(\boldsymbol\theta_0)^{-1} \approx -\left(\frac{\partial^2 \log \mathcal{L}(\boldsymbol\theta_{MLE};\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta \partial \boldsymbol\theta'}\right)^{-1}.
\]</span></p>
<p>In the Probit case (see Table <a href="microeconometrics.html#tab:foo">3.1</a>), it can be shown that we have:
<span class="math display">\[\begin{eqnarray*}
&amp;&amp;\frac{\partial^2 \log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta \partial \boldsymbol\theta'} = - \sum_{i=1}^{n} g'(\boldsymbol\theta'\mathbf{x}_i) [\mathbf{x}_i \mathbf{x}_i'] \times \\
&amp;&amp;\left[y_i \frac{g'(\boldsymbol\theta'\mathbf{x}_i) + \boldsymbol\theta'\mathbf{x}_ig(\boldsymbol\theta'\mathbf{x}_i)}{g(\boldsymbol\theta'\mathbf{x}_i)^2} + (1-y_i) \frac{g'(\boldsymbol\theta'\mathbf{x}_i) - \boldsymbol\theta'\mathbf{x}_i (1 - g(\boldsymbol\theta'\mathbf{x}_i))}{(1-g(\boldsymbol\theta'\mathbf{x}_i))^2}\right].
\end{eqnarray*}\]</span></p>
<p>In the Logit case (see Table <a href="microeconometrics.html#tab:foo">3.1</a>), it can be shown that we have:
<span class="math display">\[
\frac{\partial^2 \log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta \partial \boldsymbol\theta'} = - \sum_{i=1}^{n} g'(\boldsymbol\theta'\mathbf{x}_i) \mathbf{x}_i\mathbf{x}_i',
\]</span>
where <span class="math inline">\(g'(x)=\dfrac{\exp(-x)}{(1 + \exp(-x))^2}\)</span>.</p>
<p>Remark that, since <span class="math inline">\(g'(x)&gt;0\)</span>, <span class="math inline">\(-\partial^2 \log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X})/\partial \boldsymbol\theta \partial \boldsymbol\theta'\)</span> is positive definite.</p>
</div>
<div id="marginalFX" class="section level3" number="3.1.4">
<h3>
<span class="header-section-number">3.1.4</span> Marginal effects<a class="anchor" aria-label="anchor" href="#marginalFX"><i class="fas fa-link"></i></a>
</h3>
<p>How to measure marginal effects, i.e. the effect on the probability that <span class="math inline">\(y_i=1\)</span> of a marginal increase of <span class="math inline">\(x_{i,k}\)</span>? This object is given by:
<span class="math display">\[
\frac{\partial \mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta)}{\partial x_{i,k}} = \underbrace{g'(\boldsymbol\theta'\mathbf{x}_i)}_{&gt;0}\theta_k,
\]</span>
which is of the same sign as <span class="math inline">\(\theta_k\)</span> if function <span class="math inline">\(g\)</span> is monotonously increasing.</p>
<p>For agent <span class="math inline">\(i\)</span>, this marginal effect is consistently estimated by <span class="math inline">\(g'(\boldsymbol\theta_{MLE}'\mathbf{x}_i)\theta_{MLE,k}\)</span>. It is important to see that the marginal effect depends on <span class="math inline">\(\mathbf{x}_i\)</span>: respective increases by 1 unit of <span class="math inline">\(x_{i,k}\)</span> (entity <span class="math inline">\(i\)</span>) and of <span class="math inline">\(x_{j,k}\)</span> (entity <span class="math inline">\(j\)</span>) do not necessarily have the same effect on <span class="math inline">\(\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta)\)</span> as on <span class="math inline">\(\mathbb{P}(y_j=1|\mathbf{x}_j;\boldsymbol\theta)\)</span>. To address this issue, one can compute some measures of “average” marginal effect. There are two main solutions. For each explanatory variable <span class="math inline">\(k\)</span>:</p>
<ol style="list-style-type: lower-roman">
<li>Denoting by <span class="math inline">\(\hat{\mathbf{x}}\)</span> the sample average of the <span class="math inline">\(\mathbf{x}_i\)</span>s, compute <span class="math inline">\(g'(\boldsymbol\theta_{MLE}'\hat{\mathbf{x}})\theta_{MLE,k}\)</span>.</li>
<li>Compute the average (across <span class="math inline">\(i\)</span>) of <span class="math inline">\(g'(\boldsymbol\theta_{MLE}'\mathbf{x}_i)\theta_{MLE,k}\)</span>.</li>
</ol>
</div>
<div id="goodness-of-fit" class="section level3" number="3.1.5">
<h3>
<span class="header-section-number">3.1.5</span> Goodness of fit<a class="anchor" aria-label="anchor" href="#goodness-of-fit"><i class="fas fa-link"></i></a>
</h3>
<p>There is no obvious version of “<span class="math inline">\(R^2\)</span>” for binary-choice models. Existing measures are called <strong>pseudo-<span class="math inline">\(R^2\)</span> measures</strong>.</p>
<p>Denoting by <span class="math inline">\(\log \mathcal{L}_0(\mathbf{y})\)</span> the (maximum) log-likelihood that would be obtained for a model containing only a constant term (i.e. with <span class="math inline">\(\mathbf{x}_i = 1\)</span> for all <span class="math inline">\(i\)</span>), the McFadden’s pseudo-<span class="math inline">\(R^2\)</span> is given by:
<span class="math display">\[
R^2_{MF} = 1 - \frac{\log \mathcal{L}(\boldsymbol\theta;\mathbf{y})}{\log \mathcal{L}_0(\mathbf{y})}.
\]</span>
Intuitively, <span class="math inline">\(R^2_{MF}=0\)</span> if the explanatory variables do not convey any information on the outcome <span class="math inline">\(y\)</span>. Indeed, in this case, the model is not better than the reference model, that simply captures the fraction of <span class="math inline">\(y_i\)</span>’s that are equal to 1.</p>
<div class="example">
<p><span id="exm:creditProbit" class="example"><strong>Example 3.3  (Credit and defaults (Lending-club dataset)) </strong></span>This example makes use of the <code>credit</code> data of package <code>AEC</code>. The objective is to model the default probabilities of borrowers.</p>
<p>Let us first represent the relationship between the fraction of households that have defaulted on their loan and their annual income:</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AEC</span><span class="op">)</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">Default</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">Default</span><span class="op">[</span><span class="va">credit</span><span class="op">$</span><span class="va">loan_status</span> <span class="op">==</span> <span class="st">"Charged Off"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">Default</span><span class="op">[</span><span class="va">credit</span><span class="op">$</span><span class="va">loan_status</span> <span class="op">==</span></span>
<span>                 <span class="st">"Does not meet the credit policy. Status:Charged Off"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">amt2income</span> <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">$</span><span class="va">loan_amnt</span><span class="op">/</span><span class="va">credit</span><span class="op">$</span><span class="va">annual_inc</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">credit</span><span class="op">$</span><span class="va">Default</span><span class="op">)</span><span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">credit</span><span class="op">$</span><span class="va">annual_inc</span><span class="op">)</span>,</span>
<span>     ylevels<span class="op">=</span><span class="fl">2</span><span class="op">:</span><span class="fl">1</span>,ylab<span class="op">=</span><span class="st">"Default status"</span>,xlab<span class="op">=</span><span class="st">"log(annual income)"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="MicroEc_files/figure-html/Probitlending-1.png" width="672"></div>
<p>The previous figure suggests that the effect of annual income on the probability of default is non-monotonous. We will therefore include a quadratic term in one of our specification (namely <code>eq1</code> below).</p>
<p>We consider three specifications. The first one (<code>eq0</code>), with no explanatory variables, is trivial. It will just be used to compute the pseudo-<span class="math inline">\(R^2\)</span>. In the second (<code>eq1</code>), we consider a few covariates (loan amount, the ratio between the amount and annual income, The number of more-than-30 days past-due incidences of delinquency in the borrower’s credit file for the past 2 years, and a quadratic function of annual income). In the third model (<code>eq2</code>), we add a credit rating.</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">eq0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="fl">1</span>,data<span class="op">=</span><span class="va">credit</span>,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eq1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">loan_amnt</span><span class="op">)</span> <span class="op">+</span> <span class="va">amt2income</span> <span class="op">+</span> <span class="va">delinq_2yrs</span> <span class="op">+</span> </span>
<span>             <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">annual_inc</span><span class="op">)</span><span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">annual_inc</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>           data<span class="op">=</span><span class="va">credit</span>,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eq2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="va">grade</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">loan_amnt</span><span class="op">)</span> <span class="op">+</span> <span class="va">amt2income</span> <span class="op">+</span> <span class="va">delinq_2yrs</span> <span class="op">+</span> </span>
<span>             <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">annual_inc</span><span class="op">)</span><span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">annual_inc</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>           data<span class="op">=</span><span class="va">credit</span>,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">stargazer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">eq0</span>,<span class="va">eq1</span>,<span class="va">eq2</span>,type<span class="op">=</span><span class="st">"text"</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ====================================================
##                           Dependent variable:       
##                     --------------------------------
##                                 Default             
##                        (1)        (2)        (3)    
## ----------------------------------------------------
## gradeB                                     0.400*** 
##                                            (0.055)  
## gradeC                                     0.587*** 
##                                            (0.057)  
## gradeD                                     0.820*** 
##                                            (0.061)  
## gradeE                                     0.874*** 
##                                            (0.091)  
## gradeF                                     1.230*** 
##                                            (0.147)  
## gradeG                                     1.439*** 
##                                            (0.227)  
## log(loan_amnt)                  -0.149**  -0.194*** 
##                                 (0.060)    (0.061)  
## amt2income                      1.266***   1.222*** 
##                                 (0.383)    (0.393)  
## delinq_2yrs                     0.096***    0.009   
##                                 (0.034)    (0.035)  
## log(annual_inc)                 -1.444**    -0.874  
##                                 (0.569)    (0.586)  
## I(log(annual_inc)2)             0.064**     0.038   
##                                 (0.025)    (0.026)  
## Constant            -1.231***   7.937***    4.749   
##                      (0.017)    (3.060)    (3.154)  
## ----------------------------------------------------
## Observations          9,156      9,156      9,156   
## Log Likelihood      -3,157.696 -3,120.625 -2,981.343
## Akaike Inf. Crit.   6,317.392  6,253.250  5,986.686 
## ====================================================
## Note:                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Let us compute the pseudo R2 for the last two models:</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">logL0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">eq0</span><span class="op">)</span>;<span class="va">logL1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">eq1</span><span class="op">)</span>;<span class="va">logL2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">eq2</span><span class="op">)</span></span>
<span><span class="va">pseudoR2_eq1</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">logL1</span><span class="op">/</span><span class="va">logL0</span> <span class="co"># pseudo R2</span></span>
<span><span class="va">pseudoR2_eq2</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">logL2</span><span class="op">/</span><span class="va">logL0</span> <span class="co"># pseudo R2</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">pseudoR2_eq1</span>,<span class="va">pseudoR2_eq2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.01173993 0.05584870</code></pre>
<p>Let us now compute the (average) marginal effects, using method ii of Section <a href="microeconometrics.html#marginalFX">3.1.4</a>:</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">eq2</span><span class="op">)</span><span class="op">)</span>,na.rm<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">*</span><span class="va">eq2</span><span class="op">$</span><span class="va">coefficients</span></span></code></pre></div>
<pre><code>##          (Intercept)               gradeB               gradeC 
##          0.840731198          0.070747353          0.103944305 
##               gradeD               gradeE               gradeF 
##          0.145089219          0.154773742          0.217702041 
##               gradeG       log(loan_amnt)           amt2income 
##          0.254722161         -0.034289921          0.216251992 
##          delinq_2yrs      log(annual_inc) I(log(annual_inc)^2) 
##          0.001574178         -0.154701321          0.006813694</code></pre>
<p>There is an issue for the <code>annual_inc</code> variable. Indeed, the previous computation does not realize that this variable appears twice among the explanatory variables (through <code>log(annual_inc)</code> and <code>I(log(annual_inc)^2)</code>). To address this, one can proceed as follows: (1) we construct a new counterfactual dataset where annual incomes are increased by 1%, (2) we use the model to compute model-implied probabilities of default on this new dataset and (3), we subtract the probabilities resulting from the original dataset from these counterfactual probabilities:</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_credit</span> <span class="op">&lt;-</span> <span class="va">credit</span></span>
<span><span class="va">new_credit</span><span class="op">$</span><span class="va">annual_inc</span> <span class="op">&lt;-</span> <span class="fl">1.01</span> <span class="op">*</span> <span class="va">new_credit</span><span class="op">$</span><span class="va">annual_inc</span></span>
<span><span class="va">bas_predict_eq2</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">eq2</span>, newdata <span class="op">=</span> <span class="va">credit</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="co"># This is equivalent to pnorm(predict(eq2, newdata = credit))</span></span>
<span><span class="va">new_predict_eq2</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">eq2</span>, newdata <span class="op">=</span> <span class="va">new_credit</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">new_predict_eq2</span> <span class="op">-</span> <span class="va">bas_predict_eq2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] -6.562126e-05</code></pre>
<p>The negative sign means that, on average across the entities considered in the analysis, a 1% increase in annual income results in a decrease in the default probability. This average effect is however pretty low. To get an economic sense of the size of this effect, let us compute the average effect associated with a unit increase in the number of delinquencies:</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_credit</span> <span class="op">&lt;-</span> <span class="va">credit</span></span>
<span><span class="va">new_credit</span><span class="op">$</span><span class="va">delinq_2yrs</span> <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">$</span><span class="va">delinq_2yrs</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="va">new_predict_eq2</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">eq2</span>, newdata <span class="op">=</span> <span class="va">new_credit</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">new_predict_eq2</span> <span class="op">-</span> <span class="va">bas_predict_eq2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.001582332</code></pre>
<p>We can employ a likelihood ratio test (see Def. <a href="estimation-methods.html#def:LR">2.8</a>) to see if the two variables associated with annual income are jointly statistically significant (in the context of <code>eq1</code>):</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">eq1restr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">loan_amnt</span><span class="op">)</span> <span class="op">+</span> <span class="va">amt2income</span> <span class="op">+</span> <span class="va">delinq_2yrs</span>,</span>
<span>                data<span class="op">=</span><span class="va">credit</span>,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">LRstat</span> <span class="op">&lt;-</span> <span class="fl">2</span><span class="op">*</span><span class="op">(</span><span class="va">logL1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">eq1restr</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">pvalue</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="va">LRstat</span>,df<span class="op">=</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The computation gives a p-value of 0.0436.</p>
</div>
<div class="example">
<p><span id="exm:Fisch142" class="example"><strong>Example 3.4  (Replicating Table 14.2 of Cameron and Trivedi (2005)) </strong></span>The following lines of codes replicate Table 14.2 of <span class="citation">Cameron and Trivedi (<a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref">2005</a>)</span> (see Example <a href="microeconometrics.html#exm:FishingTable">3.2</a>).</p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data.reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">Fishing</span>,<span class="va">mode</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"charter"</span>,<span class="st">"pier"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data.reduced</span><span class="op">$</span><span class="va">lnrelp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">price.charter</span><span class="op">/</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">price.pier</span><span class="op">)</span></span>
<span><span class="va">data.reduced</span><span class="op">$</span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">mode</span><span class="op">==</span><span class="st">"charter"</span><span class="op">)</span></span>
<span><span class="co"># check first line of Table 14.1:</span></span>
<span><span class="va">price.charter.y0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">pcharter</span><span class="op">[</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">y</span><span class="op">==</span><span class="fl">0</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">price.charter.y1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">pcharter</span><span class="op">[</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">y</span><span class="op">==</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">price.charter</span>    <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">pcharter</span><span class="op">)</span></span>
<span><span class="co"># Run probit regression:</span></span>
<span><span class="va">reg.probit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">lnrelp</span>,</span>
<span>                  data<span class="op">=</span><span class="va">data.reduced</span>,</span>
<span>                  family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Run Logit regression:</span></span>
<span><span class="va">reg.logit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">lnrelp</span>,</span>
<span>                 data<span class="op">=</span><span class="va">data.reduced</span>,</span>
<span>                 family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"logit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Run OLS regression:</span></span>
<span><span class="va">reg.OLS</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">lnrelp</span>,</span>
<span>              data<span class="op">=</span><span class="va">data.reduced</span><span class="op">)</span></span>
<span><span class="co"># Replicates Table 14.2 of Cameron and Trivedi:</span></span>
<span><span class="fu">stargazer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">reg.logit</span>, <span class="va">reg.probit</span>, <span class="va">reg.OLS</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                     type<span class="op">=</span><span class="st">"text"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ================================================================
##                                 Dependent variable:             
##                     --------------------------------------------
##                                          y                      
##                     logistic   probit             OLS           
##                        (1)       (2)              (3)           
## ----------------------------------------------------------------
## lnrelp              -1.823*** -1.056***        -0.243***        
##                      (0.145)   (0.075)          (0.010)         
## Constant            2.053***  1.194***          0.784***        
##                      (0.169)   (0.088)          (0.013)         
## ----------------------------------------------------------------
## Observations           630       630              630           
## R2                                               0.463          
## Adjusted R2                                      0.462          
## Log Likelihood      -206.827  -204.411                          
## Akaike Inf. Crit.    417.654   412.822                          
## Residual Std. Error                         0.330 (df = 628)    
## F Statistic                             542.123*** (df = 1; 628)
## ================================================================
## Note:                                *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
<div id="predictions-and-roc-curves" class="section level3" number="3.1.6">
<h3>
<span class="header-section-number">3.1.6</span> Predictions and ROC curves<a class="anchor" aria-label="anchor" href="#predictions-and-roc-curves"><i class="fas fa-link"></i></a>
</h3>
<p>How to compute model-implied predicted outcomes? As is the case for <span class="math inline">\(y_i\)</span>, predicted outcomes <span class="math inline">\(\hat{y}_i\)</span> need to be valued in <span class="math inline">\(\{0,1\}\)</span>. A natural choice consists in considering that <span class="math inline">\(\hat{y}_i=1\)</span> if <span class="math inline">\(\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta) &gt; 0.5\)</span>, i.e., in taking a cutoff of <span class="math inline">\(c=0.5\)</span>. There exist, though, situations where doing so is not relevant. For instance, we may have some models where all predicted probabilities are small, but some less than others. In this context, a model-implied probability of 10% (say) could characterize a “high-risk” entity. However, using a cutoff of 50% would not identify this level of riskiness.</p>
<p>The <strong>receiver operating characteristics (ROC)</strong> curve consitutes a more general approach. The idea is to remain agnostic and to consider all possible values of the cutoff <span class="math inline">\(c\)</span>. It works as follows. For each potential cutoff <span class="math inline">\(c \in [0,1]\)</span>, compute (and plot):</p>
<ul>
<li>The fraction of <span class="math inline">\(y = 1\)</span> values correctly classified (<em>True Positive Rate</em>) against</li>
<li>The fraction of <span class="math inline">\(y = 0\)</span> values incorrectly specified (<em>False Positive Rate</em>).</li>
</ul>
<p>Such a curve mechanically starts at (0,0) —which corresponds to <span class="math inline">\(c=1\)</span>— and terminates at (1,1) –situation when <span class="math inline">\(c=0\)</span>.</p>
<p>In the case of no predictive ability (worst situation), the ROC curve is a straight line between (0,0) and (1,1).</p>
<div class="example">
<p><span id="exm:FishingROC" class="example"><strong>Example 3.5  (ROC with the fishing-mode dataset) </strong></span>Figure <a href="microeconometrics.html#fig:fishing3">3.5</a> shows the ROC curve associated with the probit model estimated in Example <a href="microeconometrics.html#exm:Fisch142">3.4</a>.</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://expasy.org/tools/pROC/">pROC</a></span><span class="op">)</span></span>
<span><span class="va">predict_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.glm.html">predict.glm</a></span><span class="op">(</span><span class="va">reg.probit</span>,type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/pROC/man/roc.html">roc</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">y</span>, <span class="va">predict_model</span>, percent<span class="op">=</span><span class="cn">T</span>,</span>
<span>    boot.n<span class="op">=</span><span class="fl">1000</span>, ci.alpha<span class="op">=</span><span class="fl">0.9</span>, stratified<span class="op">=</span><span class="cn">T</span>, plot<span class="op">=</span><span class="cn">TRUE</span>, grid<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>    show.thres<span class="op">=</span><span class="cn">TRUE</span>, legacy.axes <span class="op">=</span> <span class="cn">TRUE</span>, reuse.auc <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    print.auc <span class="op">=</span> <span class="cn">TRUE</span>, print.thres.col <span class="op">=</span> <span class="st">"blue"</span>, ci<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>    ci.type<span class="op">=</span><span class="st">"bars"</span>, print.thres.cex <span class="op">=</span> <span class="fl">0.7</span>, col <span class="op">=</span> <span class="st">'red'</span>,</span>
<span>    main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"ROC curve using"</span>,<span class="st">"(N = "</span>,<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">)</span>,<span class="st">")"</span><span class="op">)</span> <span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:fishing3"></span>
<img src="MicroEc_files/figure-html/fishing3-1.png" alt="Application of the ROC methodology on the fishing-mode dataset." width="95%"><p class="caption">
Figure 3.5: Application of the ROC methodology on the fishing-mode dataset.
</p>
</div>
</div>
</div>
</div>
<div id="multiple-choice-models" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Multiple Choice Models<a class="anchor" aria-label="anchor" href="#multiple-choice-models"><i class="fas fa-link"></i></a>
</h2>
<p>We will now consider cases where the number of possible outcomes (or alternatives) is larger than two. Let us denote by <span class="math inline">\(J\)</span> this number. We have <span class="math inline">\(y_j \in \{1,\dots,J\}\)</span>. This situation arise for instance when the outcome variable reflects:</p>
<ul>
<li>Opinions: strongly opposed / opposed / neutral / support (ranked choices),</li>
<li>Occupational field: lawyer / farmer / engineer / doctor / …,</li>
<li>Alternative shopping areas,</li>
<li>Transportation types.</li>
</ul>
<p>In a few cases, the values associated with the choices will themselves be meaningful, for example, number of accidents per day: <span class="math inline">\(y = 0, 1,2, \dots\)</span> (count data). In most cases, the values are meaningless.</p>
<p>We assume the existence of covariates, gathered in vector <span class="math inline">\(\mathbf{x}_i\)</span> (<span class="math inline">\(K \times 1\)</span>), that are suspected to influence for the probabilities of obtaining the different outcomes (<span class="math inline">\(y_i=j\)</span>, <span class="math inline">\(j \in \{1,\dots,J\}\)</span>).</p>
<p>In what follows, we will assume that the <span class="math inline">\(y_i\)</span>’s are assumed to be independently distributed, with:
<span class="math display" id="eq:generalMultiNom">\[\begin{equation}
y_i = \left\{
\begin{array}{cl}
1 &amp; \mbox{ with probability } g_1(\mathbf{x}_i;\boldsymbol\theta)\\
\vdots \\
J &amp; \mbox{ with probability } g_J(\mathbf{x}_i;\boldsymbol\theta).
\end{array}
\right.\tag{3.7}
\end{equation}\]</span></p>
<p>(Of course, for all entities (<span class="math inline">\(i\)</span>), we must have <span class="math inline">\(\sum_{j=1}^J g_j(\mathbf{x}_i;\boldsymbol\theta)=1\)</span>.) Our objective is to estimate the vector of population parameters <span class="math inline">\(\boldsymbol\theta\)</span> given functional forms for the <span class="math inline">\(g_j\)</span>’s.</p>
<div id="ordered-case" class="section level3" number="3.2.1">
<h3>
<span class="header-section-number">3.2.1</span> Ordered case<a class="anchor" aria-label="anchor" href="#ordered-case"><i class="fas fa-link"></i></a>
</h3>
<p>Sometimes, there exists a natural order for the different alternatives. This is typically the case where respondents have to choose a level of agreement to a statement, e.g.: (1) Strongly disagree; (2) Disagree; (3) Neither agree nor disagree; (4) Agree; (5) Strongly agree. Another standard case is that of ratings (from A to F, say).</p>
<p>The ordered probit model consists in extending the binary case, considering the latent-variable view of the latter (see Section <a href="microeconometrics.html#latent">3.1.1</a>). Formally, the model is as follows:
<span class="math display" id="eq:Pordered">\[\begin{equation}
\mathbb{P}(y_i = j | \mathbf{x}_i) = \mathbb{P}(\alpha_{j-1} &lt;y^*_i &lt; \alpha_{j} |\mathbf{x}_i), \tag{3.8}
\end{equation}\]</span>
where
<span class="math display">\[
y_{i}^* = \boldsymbol\theta'\mathbf{x}_i + \varepsilon_i,
\]</span>
with <span class="math inline">\(\varepsilon_i \sim \,i.i.d.\,\mathcal{N}(0,1)\)</span>. The <span class="math inline">\(\alpha_j\)</span>’s, <span class="math inline">\(j \in \{1,\dots,J-1\}\)</span>, are (new) parameters that have to be estimated, on top of <span class="math inline">\(\boldsymbol\theta\)</span>. Naturally, we have <span class="math inline">\(\alpha_1&lt;\alpha_2&lt;\dots&lt;\alpha_{J-1}\)</span>. Moreover <span class="math inline">\(\alpha_0\)</span> is <span class="math inline">\(- \infty\)</span> and <span class="math inline">\(\alpha_J\)</span> is <span class="math inline">\(+ \infty\)</span>, so that Eq. <a href="microeconometrics.html#eq:Pordered">(3.8)</a> is valid for any <span class="math inline">\(j \in \{1,\dots,J\}\)</span> (including <span class="math inline">\(1\)</span> and <span class="math inline">\(J\)</span>).</p>
<p>We have:
<span class="math display">\[\begin{eqnarray*}
g_j(\mathbf{x}_i;\boldsymbol\theta,\boldsymbol\alpha) = \mathbb{P}(y_i = j | \mathbf{x}_i) &amp;=&amp; \mathbb{P}(\alpha_{j-1} &lt;y^*_i &lt; \alpha_{j} |\mathbf{x}_i) \\
&amp;=&amp; \mathbb{P}(\alpha_{j-1} - \boldsymbol\theta'\mathbf{x}_i  &lt;\varepsilon_i &lt; \alpha_{j} - \boldsymbol\theta'\mathbf{x}_i) \\
&amp;=&amp; \Phi(\alpha_{j} - \boldsymbol\theta'\mathbf{x}_i) - \Phi(\alpha_{j-1} - \boldsymbol\theta'\mathbf{x}_i),
\end{eqnarray*}\]</span>
where <span class="math inline">\(\Phi\)</span> is the c.d.f. of <span class="math inline">\(\mathcal{N}(0,1)\)</span>.</p>
<p>If, for all <span class="math inline">\(i\)</span>, one of the components of <span class="math inline">\(\mathbf{x}_i\)</span> is equal to 1 (which is what is done in linear regression to introduce an intercept in the specification), then one of the <span class="math inline">\(\alpha_j\)</span> (<span class="math inline">\(j\in\{1,\dots,J-1\}\)</span>) is not identified. One can then arbitrarily set <span class="math inline">\(\alpha_1=0\)</span>. This is what is done in the binary logit/probit cases.</p>
<p>This model can be estimated by maximizing the likelihood function (see Section <a href="estimation-methods.html#secMLE">2.2</a>). This function is given by:
<span class="math display" id="eq:multipleLogLik">\[\begin{equation}
\log \mathcal{L}(\boldsymbol\theta,\boldsymbol\alpha;\mathbf{y},\mathbf{X}) = \sum_{i=1}^n  \sum_{j=1}^J \mathbb{I}_{\{y_i=j\}} \log \left(g_j(\mathbf{x}_i;\boldsymbol\theta,\boldsymbol\alpha)\right). \tag{3.9}
\end{equation}\]</span></p>
<p>Let us stress that we have two types of parameters to estimate: those included in vector <span class="math inline">\(\boldsymbol\theta\)</span>, and the <span class="math inline">\(\alpha_j\)</span>’s, gathered in vector <span class="math inline">\(\boldsymbol\alpha\)</span>.</p>
<p>The estimated values of the <span class="math inline">\(\theta_j\)</span>’s are slightly more complicated to interpret (at least in term of sign) than in the binary case. Indeed, we have:
<span class="math display">\[
\mathbb{P}(y_i \le j | \mathbf{x}_i) = \Phi(\alpha_{j} - \boldsymbol\theta'\mathbf{x}_i) \Rightarrow \frac{\partial \mathbb{P}(y_i \le j | \mathbf{x}_i)}{\mathbf{x}_i} =- \underbrace{\Phi'(\alpha_{j} - \boldsymbol\theta'\mathbf{x}_i)}_{&gt;0}\boldsymbol\theta.
\]</span>
Hence the sign of <span class="math inline">\(\theta_k\)</span> indicates whether <span class="math inline">\(\mathbb{P}(y_i \le j | \mathbf{x}_i)\)</span> increases or decreases w.r.t. <span class="math inline">\(x_{i,k}\)</span> (the <span class="math inline">\(k^{th}\)</span> component of <span class="math inline">\(\mathbf{x}_i\)</span>). By contrast:
<span class="math display">\[
\frac{\partial \mathbb{P}(y_i = j | \mathbf{x}_i)}{\mathbf{x}_i} = \underbrace{\left(-F'(\alpha_{j} + \boldsymbol\theta'\mathbf{x}_i)+F'(\alpha_{j-1} + \boldsymbol\theta'\mathbf{x}_i)\right)}_{A}\boldsymbol\theta.
\]</span>
Therefore the signs of the components of <span class="math inline">\(\boldsymbol\theta\)</span> are not necessarily those of the marginal effects. (For the sign of <span class="math inline">\(A\)</span> is a priori unknown.)</p>
<div class="example">
<p><span id="exm:orderedCredit" class="example"><strong>Example 3.6  (Predicting credit ratings (Lending-club dataset)) </strong></span>Let us use credit dataset again (see Example <a href="microeconometrics.html#exm:creditProbit">3.3</a>), and let use try and model the ratings attributed by the lending-club:</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AEC</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">emp_length_low5y</span>   <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">$</span><span class="va">emp_length</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"&lt; 1 year"</span>,<span class="st">"1 year"</span>,<span class="st">"2 years"</span>,<span class="st">"3 years"</span>,<span class="st">"4 years"</span><span class="op">)</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">emp_length_high10y</span> <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">$</span><span class="va">emp_length</span><span class="op">==</span><span class="st">"10+ years"</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">annual_inc</span> <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">$</span><span class="va">annual_inc</span><span class="op">/</span><span class="fl">1000</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">loan_amnt</span>  <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">$</span><span class="va">loan_amnt</span><span class="op">/</span><span class="fl">1000</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">income2loan</span> <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">$</span><span class="va">annual_inc</span><span class="op">/</span><span class="va">credit</span><span class="op">$</span><span class="va">loan_amnt</span></span>
<span><span class="va">training</span> <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">20000</span>,<span class="op">]</span> <span class="co"># sample is reduced</span></span>
<span><span class="va">training</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">training</span>,<span class="va">grade</span><span class="op">!=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"E"</span>,<span class="st">"F"</span>,<span class="st">"G"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">training</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">training</span><span class="op">)</span></span>
<span><span class="va">training</span><span class="op">$</span><span class="va">grade.ordered</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">training</span><span class="op">$</span><span class="va">grade</span>,ordered<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>                                 levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"D"</span>,<span class="st">"C"</span>,<span class="st">"B"</span>,<span class="st">"A"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/polr.html">polr</a></span><span class="op">(</span><span class="va">grade.ordered</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">loan_amnt</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">income2loan</span><span class="op">)</span> <span class="op">+</span> <span class="va">delinq_2yrs</span>,</span>
<span>               data<span class="op">=</span><span class="va">training</span>, Hess<span class="op">=</span><span class="cn">TRUE</span>, method<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span></span>
<span><span class="va">model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/polr.html">polr</a></span><span class="op">(</span><span class="va">grade.ordered</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">loan_amnt</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">income2loan</span><span class="op">)</span> <span class="op">+</span> <span class="va">delinq_2yrs</span> <span class="op">+</span></span>
<span>                 <span class="va">emp_length_low5y</span> <span class="op">+</span> <span class="va">emp_length_high10y</span>,</span>
<span>               data<span class="op">=</span><span class="va">training</span>, Hess<span class="op">=</span><span class="cn">TRUE</span>, method<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span></span>
<span><span class="fu">stargazer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">model1</span>,<span class="va">model2</span>,ord.intercepts <span class="op">=</span> <span class="cn">TRUE</span>,type<span class="op">=</span><span class="st">"text"</span>,</span>
<span>                     no.space <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ===============================================
##                        Dependent variable:     
##                    ----------------------------
##                           grade.ordered        
##                         (1)            (2)     
## -----------------------------------------------
## log(loan_amnt)         -0.014        -0.040*   
##                       (0.022)        (0.022)   
## log(income2loan)      0.115***      0.092***   
##                       (0.022)        (0.022)   
## delinq_2yrs          -0.399***      -0.404***  
##                       (0.025)        (0.025)   
## emp_length_low5y                    -0.096***  
##                                      (0.027)   
## emp_length_high10y                   0.088**   
##                                      (0.035)   
## D| C                 -0.937***      -1.073***  
##                       (0.082)        (0.086)   
## C| B                  -0.160**      -0.295***  
##                       (0.082)        (0.085)   
## B| A                  0.696***      0.564***   
##                       (0.082)        (0.086)   
## -----------------------------------------------
## Observations           8,695          8,695    
## ===============================================
## Note:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Predicted ratings (and probabilties of being given a given rating) can be computed as follows:</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pred.grade</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model1</span>,newdata <span class="op">=</span> <span class="va">training</span><span class="op">)</span></span>
<span><span class="co"># pred.grade = predicted grade, defined as the most likely according model</span></span>
<span><span class="va">pred.proba</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model1</span>,newdata <span class="op">=</span> <span class="va">training</span>, type<span class="op">=</span><span class="st">"probs"</span><span class="op">)</span></span></code></pre></div>
</div>
<!-- \begin{exerc}[Political information] -->
<!-- Using the data available \href{https://vincentarelbundock.github.io/Rdatasets/csv/pscl/politicalInformation.csv}{here} and documented \href{https://vincentarelbundock.github.io/Rdatasets/doc/pscl/politicalInformation.html}{here}, propose a model for the political information level. -->
<!-- \end{exerc} -->
<!-- \vspace{.5cm} -->
<!-- \begin{exerc}[Wine quality] -->
<!-- Using the data available \href{https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv}{here} and documented \href{https://archive.ics.uci.edu/ml/datasets/Wine+Quality}{here}, propose a model for wine quality. -->
<!-- \end{exerc} -->
</div>
<div id="MNL" class="section level3" number="3.2.2">
<h3>
<span class="header-section-number">3.2.2</span> General multinomial logit model<a class="anchor" aria-label="anchor" href="#MNL"><i class="fas fa-link"></i></a>
</h3>
<p>This section introduces the general multinomial logit model, which is the natural extension of the binary logit model (see Table <a href="microeconometrics.html#tab:foo">3.1</a>). Its general formulation is as follows:
<span class="math display" id="eq:GeneralMNL">\[\begin{equation}
g_j(\mathbf{x}_i;\boldsymbol\theta) = \frac{\exp(\theta_j'\mathbf{x}_i)}{\sum_{k=1}^J \exp(\theta_k'\mathbf{x}_i)}.\tag{3.10}
\end{equation}\]</span></p>
<p>Note that, by construction, <span class="math inline">\(g_j(\mathbf{x}_i;\boldsymbol\theta) \in [0,1]\)</span> and <span class="math inline">\(\sum_{j}g_j(\mathbf{x}_i;\boldsymbol\theta)=1\)</span>.</p>
<p>The components of <span class="math inline">\(\mathbf{x}_i\)</span> (regressors, or covariates) may be <em>alternative-specific</em> or <em>alternative invariant</em> (see also Section <a href="microeconometrics.html#Avregressors">3.1.2</a>). We may, e.g., organize <span class="math inline">\(\mathbf{x}_i\)</span> as follows:
<span class="math display" id="eq:xorganiz">\[\begin{equation}
\mathbf{x}_i = [\mathbf{u}_{i,1}',\dots,\mathbf{u}_{i,J}',\mathbf{v}_{i}']',\tag{3.11}
\end{equation}\]</span>
where the notations are as in Section <a href="microeconometrics.html#Avregressors">3.1.2</a>, that is:</p>
<ul>
<li>
<span class="math inline">\(\mathbf{u}_{i,j}\)</span> (<span class="math inline">\(j \in \{1,\dots,J\}\)</span>): vector of variables associated with agent <span class="math inline">\(i\)</span> and alternative <span class="math inline">\(j\)</span> (alternative-specific regressors). Examples: Travel time per type of transportation (transportation choice), wage per type of work, cost per type of car.</li>
<li>
<span class="math inline">\(\mathbf{v}_{i}\)</span>: vector of variables associated with agent <span class="math inline">\(i\)</span> but alternative-invariant. Examples: age or gender of agent <span class="math inline">\(i\)</span>,</li>
</ul>
<p>When <span class="math inline">\(\mathbf{x}_i\)</span> is as in Eq. <a href="microeconometrics.html#eq:xorganiz">(3.11)</a>, with obvious notations, <span class="math inline">\(\theta_j\)</span> is of the form:
<span class="math display" id="eq:thetaOrganiz">\[\begin{equation}
\theta_j = [{\theta^{(u)}_{1,j}}',\dots,{\theta^{(u)}_{J,j}}',{\theta_j^{(v)}}']',\tag{3.12}
\end{equation}\]</span>
and <span class="math inline">\(\boldsymbol\theta=[\theta_1',\dots,\theta_J']'\)</span>.</p>
<p>The literature has considered different specific cases of the general multinomial logit model:<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The labelling “CL” and “MNL” —used in the literature— are relatively &lt;em&gt;ad hoc&lt;/em&gt; (see 15.4.1 in &lt;span class="citation"&gt;Cameron and Trivedi (&lt;a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref"&gt;2005&lt;/a&gt;)&lt;/span&gt;).&lt;/p&gt;'><sup>9</sup></a></p>
<ul>
<li>
<strong>Conditional logit (CL)</strong> with alternative-varying regressors:
<span class="math display" id="eq:thetaOrganizCL">\[\begin{equation}
\theta_j = [\mathbf{0}',\dots,\mathbf{0}',\underbrace{\boldsymbol\beta'}_{\mbox{j$^{th}$ position}},\mathbf{0}',\dots]',\tag{3.13}
\end{equation}\]</span>
i.e., we have <span class="math inline">\(\boldsymbol\beta=\theta^{(u)}_{1,1}=\dots=\theta^{(u)}_{J,J}\)</span> and <span class="math inline">\(\theta^{(u)}_{i,j}=\mathbf{0}\)</span> for <span class="math inline">\(i \ne j\)</span>.</li>
<li>
<strong>Multinomial logit (MNL)</strong> with alternative-invariant regressors:
<span class="math display" id="eq:thetaOrganizML">\[\begin{equation}
\theta_j = \left[\mathbf{0}',\dots,\mathbf{0}',{\theta_j^{(v)}}'\right]'.\tag{3.14}
\end{equation}\]</span>
</li>
<li>
<strong>Mixed logit:</strong>
<span class="math display" id="eq:thetaOrganizCL">\[\begin{equation}
\theta_j = \left[\mathbf{0}',\dots,\mathbf{0}',\boldsymbol\beta',\mathbf{0}',\dots,\mathbf{0}',{\theta_j^{(v)}}'\right]'.\tag{3.13}
\end{equation}\]</span>
</li>
</ul>
<div class="example">
<p><span id="exm:FishingGeneralLogit" class="example"><strong>Example 3.7  (CL and MNL with the fishing-mode dataset) </strong></span>The following lines replicate Table 15.2 in <span class="citation">Cameron and Trivedi (<a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref">2005</a>)</span> (see also Examples <a href="microeconometrics.html#exm:FishingTable">3.2</a> and <a href="microeconometrics.html#exm:Fisch142">3.4</a>):</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Specify data organization:</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=mlogit">mlogit</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">stargazer</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Fishing"</span>,package<span class="op">=</span><span class="st">"mlogit"</span><span class="op">)</span></span>
<span><span class="va">Fish</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit-deprecated.html">mlogit.data</a></span><span class="op">(</span><span class="va">Fishing</span>,</span>
<span>                    varying <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span>,</span>
<span>                    choice <span class="op">=</span> <span class="st">"mode"</span>,</span>
<span>                    shape <span class="op">=</span> <span class="st">"wide"</span><span class="op">)</span></span>
<span><span class="va">MNL1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">price</span> <span class="op">+</span> <span class="va">catch</span>, data <span class="op">=</span> <span class="va">Fish</span><span class="op">)</span></span>
<span><span class="va">MNL2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">price</span> <span class="op">+</span> <span class="va">catch</span> <span class="op">-</span> <span class="fl">1</span>, data <span class="op">=</span> <span class="va">Fish</span><span class="op">)</span></span>
<span><span class="va">MNL3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">income</span>, data <span class="op">=</span> <span class="va">Fish</span><span class="op">)</span></span>
<span><span class="va">MNL4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">price</span> <span class="op">+</span> <span class="va">catch</span> <span class="op">|</span> <span class="va">income</span>, data <span class="op">=</span> <span class="va">Fish</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">MNL1</span>,<span class="va">MNL2</span>,<span class="va">MNL3</span>,<span class="va">MNL4</span>,type<span class="op">=</span><span class="st">"text"</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          omit.stat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lr"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ===============================================================
##                                 Dependent variable:            
##                     -------------------------------------------
##                                        mode                    
##                        (1)        (2)        (3)        (4)    
## ---------------------------------------------------------------
## (Intercept):boat     0.871***              0.739***   0.527**  
##                      (0.114)               (0.197)    (0.223)  
## (Intercept):charter  1.499***              1.341***   1.694*** 
##                      (0.133)               (0.195)    (0.224)  
## (Intercept):pier     0.307***              0.814***   0.778*** 
##                      (0.115)               (0.229)    (0.220)  
## price               -0.025***  -0.020***             -0.025*** 
##                      (0.002)    (0.001)               (0.002)  
## catch                0.377***   0.953***              0.358*** 
##                      (0.110)    (0.089)               (0.110)  
## income:boat                                0.0001**   0.0001*  
##                                           (0.00004)   (0.0001) 
## income:charter                             -0.00003   -0.00003 
##                                           (0.00004)   (0.0001) 
## income:pier                               -0.0001*** -0.0001** 
##                                            (0.0001)   (0.0001) 
## ---------------------------------------------------------------
## Observations          1,182      1,182      1,182      1,182   
## R2                    0.178      0.014      0.189              
## Log Likelihood      -1,230.784 -1,311.980 -1,477.151 -1,215.138
## ===============================================================
## Note:                               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
<p><strong>ML estimation</strong></p>
<p>General multinomial logit models can be estimated by Maximum Likelihood techniques (see Section <a href="estimation-methods.html#secMLE">2.2</a>). Consider the general model described in Eq. <a href="microeconometrics.html#eq:generalMultiNom">(3.7)</a>. It can be noted that:
<span class="math display">\[
f(y_i|\mathbf{x}_i;\boldsymbol\theta) = \prod_{j=1}^J g_j(\mathbf{x}_i;\boldsymbol\theta)^{\mathbb{I}_{\{y_i=j\}}},
\]</span>
which leads to
<span class="math display">\[
\log f(y_i|\mathbf{x}_i;\boldsymbol\theta) = \sum_{j=1}^J \mathbb{I}_{\{y_i=j\}} \log \left(g_j(\mathbf{x}_i;\boldsymbol\theta)\right).
\]</span>
The log-likelihood function is therefore given by:
<span class="math display" id="eq:multipleLogLik">\[\begin{equation}
\log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X}) = \sum_{i=1}^n  \sum_{j=1}^J \mathbb{I}_{\{y_i=j\}} \log \left(g_j(\mathbf{x}_i;\boldsymbol\theta)\right).\tag{3.9}
\end{equation}\]</span>
Numerical methods have to be employed in order to find the maximum-likelihood estimate of <span class="math inline">\(\boldsymbol\theta\)</span>. (Standard packages contain fast algorithms.)</p>
<p><strong>Marginal Effects</strong></p>
<p>Let us consider the computation of marginal effects in the general multinomial logit model (Eq. <a href="microeconometrics.html#eq:GeneralMNL">(3.10)</a>). Using the notation <span class="math inline">\(p_{i,j} \equiv \mathbb{P}(y_i=j|\mathbf{x}_i;\boldsymbol\theta)\)</span>, we have:
<span class="math display">\[\begin{eqnarray*}
\frac{\partial p_{i,j}}{\partial x_{i,s}} &amp;=&amp; \frac{\theta_{j,s}\exp(\theta_j'\mathbf{x}_i)\sum_{k=1}^J \exp(\theta_k'\mathbf{x}_i)}{(\sum_{k=1}^J \exp(\theta_k'\mathbf{x}_i))^2} \\
&amp;&amp; - \frac{\exp(\theta_j'\mathbf{x}_i)\sum_{k=1}^J \theta_{k,s} \exp(\theta_k'\mathbf{x}_i)}{(\sum_{k=1}^J \exp(\theta_k'\mathbf{x}_i))^2}\\
&amp;=&amp; \theta_{j,s} p_{i,j} - \sum_{k=1}^J \theta_{k,s} p_{i,j}p_{i,k}\\
&amp;=&amp;  p_{i,j} \times \Big(\theta_{j,s} - \underbrace{\sum_{k=1}^J \theta_{k,s} p_{i,k}}_{=\overline{\boldsymbol{\theta}}^{(i)}_{s}}\Big),
\end{eqnarray*}\]</span>
where <span class="math inline">\(\overline{\boldsymbol\theta}^{(i)}_{s}\)</span> does not depend on <span class="math inline">\(j\)</span>. Note that the sign of the marginal effect is not necessarily that of <span class="math inline">\(\theta_{j,s}\)</span>.</p>
<p><strong>Random Utility models</strong></p>
<p>The general multinomial logit model may arise as the natural specification arising in structural contexts where agents compare (random) utilities associated with <span class="math inline">\(J\)</span> potential outcomes (see Section <a href="microeconometrics.html#latent">3.1.1</a> for the binary situation).</p>
<p>Let’s drop the <span class="math inline">\(i\)</span> subscript for simplicity and assume that the utility derived form choosing <span class="math inline">\(j\)</span> is given by <span class="math inline">\(U_j = V_j + \varepsilon_j\)</span>, where <span class="math inline">\(V_j\)</span> is deterministic (may depend on observed covariates) and <span class="math inline">\(\varepsilon_j\)</span> is stochastic. We have (with obvious notations):
<span class="math display">\[\begin{eqnarray*}
\mathbb{P}(y=j) &amp;=&amp; \mathbb{P}(U_j&gt;U_k,\,\forall k \ne j)\\
\mathbb{P}(y=j) &amp;=&amp; \mathbb{P}(U_k-U_j&lt;0,\,\forall k \ne j)\\
\mathbb{P}(y=j) &amp;=&amp; \mathbb{P}(\underbrace{\varepsilon_k-\varepsilon_j}_{=:\tilde\varepsilon_{k,j}}&lt;\underbrace{V_j - V_k}_{=:-\tilde{V}_{k,j}},\,\forall k \ne j).
\end{eqnarray*}\]</span></p>
<p>The last expression is an <span class="math inline">\((J-1)\)</span>-variate integral. While it has, in general, no analytical solution, Prop. <a href="microeconometrics.html#prp:Weibull">3.1</a> shows that it is the case when employing Gumbel distributions (see Def. <a href="microeconometrics.html#def:Gumbel">3.1</a>).</p>
<div class="definition">
<p><span id="def:Gumbel" class="definition"><strong>Definition 3.1  (Gumbel distribution) </strong></span>The c.d.f. of the Gumbel distribution (<span class="math inline">\(\mathcal{W}\)</span>) is:
<span class="math display">\[
F(u) = \exp(-\exp(-u)), \qquad f(u)=\exp(-u-\exp(u)).
\]</span></p>
</div>
<p>Remark: if <span class="math inline">\(X\sim\mathcal{W}\)</span>, then <span class="math inline">\(\mathbb{E}(X)=0.577\)</span> (Euler constant)<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The Euler constant &lt;span class="math inline"&gt;\(\gamma\)&lt;/span&gt; satisfies &lt;span class="math inline"&gt;\(\gamma = \lim_{n\rightarrow \infty} \left(- \ln(n) + \sum_{k=1}^n \frac{1}{k}\right)\)&lt;/span&gt;.&lt;/p&gt;'><sup>10</sup></a> and <span class="math inline">\(\mathbb{V}ar(X)=\pi^2/6\)</span>.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:Gumbel"></span>
<img src="MicroEc_files/figure-html/Gumbel-1.png" alt="C.d.f. of the Gumbel distribution ($F(x)=\exp(-\exp(-x))$)." width="95%"><p class="caption">
Figure 3.6: C.d.f. of the Gumbel distribution (<span class="math inline">\(F(x)=\exp(-\exp(-x))\)</span>).
</p>
</div>
<div class="proposition">
<p><span id="prp:Weibull" class="proposition"><strong>Proposition 3.1  (Weibull) </strong></span>In the context of the utility model described above, if <span class="math inline">\(\varepsilon_j \sim \,i.i.d.\,\mathcal{W}\)</span>, then
<span class="math display">\[
\mathbb{P}(y=j) = \frac{\exp(V_j)}{\sum_{k=1}^J \exp(V_k)}.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-10" class="proof"><em>Proof</em>. </span>We have:
<span class="math display">\[\begin{eqnarray*}
\mathbb{P}(y=j) &amp;=&amp; \mathbb{P}(\forall\,k \ne j,\,U_k &lt; U_j) =  \mathbb{P}(\forall\,k \ne j,\,\varepsilon_k &lt; V_j - V_k + \varepsilon_j) \\
&amp;=&amp; \int \prod_{k \ne j} F(V_j - V_k + \varepsilon) f(\varepsilon)d\varepsilon.
\end{eqnarray*}\]</span>
After computation, it comes that
<span class="math display">\[
\prod_{k \ne j} F(V_j - V_k + \varepsilon) f(\varepsilon) = \exp\left[-\varepsilon-\exp(-\varepsilon+\lambda_j)\right],
\]</span>
where <span class="math inline">\(\lambda_j = \log\left(1 + \frac{\sum_{k \ne j} \exp(V_k)}{\exp(V_j)}\right)\)</span>. We then have:
<span class="math display">\[\begin{eqnarray*}
\mathbb{P}(y=j) &amp;=&amp; \int  \exp\left[-\varepsilon-\exp(-\varepsilon+\lambda_j)\right] d\varepsilon\\
&amp;=&amp; \int  \exp\left[-t - \lambda_j-\exp(-t)\right] d\varepsilon = \exp(- \lambda_j),
\end{eqnarray*}\]</span>
which leads to the result.</p>
</div>
<p>Some remarks on identification (see Def. <a href="estimation-methods.html#def:identif">2.5</a>) are in order.</p>
<ol style="list-style-type: decimal">
<li>We have:
<span class="math display">\[\begin{eqnarray*}
\mathbb{P}(y=j) &amp;=&amp; \frac{\exp(V_j)}{\sum_{k=1}^J \exp(V_k)}= \frac{\exp(V^*_j)}{1 + \sum_{k=2}^J \exp(V^*_k)},
\end{eqnarray*}\]</span>
where <span class="math inline">\(V^*_j = V_j - V_1\)</span>. We can therefore always assume that <span class="math inline">\(V_{1}=0\)</span>. In the case where <span class="math inline">\(V_{i,j} = \theta_j'\mathbf{x}_i = \boldsymbol\beta'\mathbf{u}_{i,j}+{\theta_j^{(v)}}'\mathbf{v}_i\)</span> (see Eqs. <a href="microeconometrics.html#eq:xorganiz">(3.11)</a> and <a href="microeconometrics.html#eq:thetaOrganizCL">(3.13)</a>), we can for instance assume that:
<span class="math display">\[\begin{eqnarray*}
&amp;(A)&amp; \mathbf{u}_{i,1}=0,\\
&amp;(B)&amp; \theta_1^{(v)} = 0.
\end{eqnarray*}\]</span>
If (A) does not hold, we can replace <span class="math inline">\(\mathbf{u}_{i,j}\)</span> with <span class="math inline">\(\mathbf{u}_{i,j}-\mathbf{u}_{i,1}\)</span>.</li>
<li>If <span class="math inline">\(J=2\)</span> and <span class="math inline">\(j \in \{0,1\}\)</span> (shift by one unit), we have <span class="math inline">\(\mathbb{P}(y=1|\mathbf{x})=\dfrac{\exp(\boldsymbol\theta'\mathbf{x})}{1+\exp(\boldsymbol\theta'\mathbf{x})}\)</span>, this is the logit model (Table <a href="microeconometrics.html#tab:foo">3.1</a>).</li>
</ol>
<p><strong>Limitations of logit models</strong></p>
<p>In a Logit model, we have:
<span class="math display" id="eq:condiProba">\[\begin{equation}
\mathbb{P}(y=j|y \in \{k,j\}) = \frac{\exp(\theta_j'\mathbf{x})}{\exp(\theta_j'\mathbf{x}) + \exp(\theta_k'\mathbf{x})}.\tag{3.15}
\end{equation}\]</span>
This conditional probability does not depend on other alternatives (i.e., it does not depend on <span class="math inline">\(\theta_m\)</span>, <span class="math inline">\(m \ne j,k\)</span>). In particular, if <span class="math inline">\(\mathbf{x} = [\mathbf{u}_1',\dots,\mathbf{u}_J',\mathbf{v}']'\)</span>, then changes in <span class="math inline">\(\mathbf{u}_m\)</span> (<span class="math inline">\(m \ne j,\,k\)</span>) have no impact on the object shown in Eq. <a href="microeconometrics.html#eq:condiProba">(3.15)</a>.</p>
<p>That is, a Multinomial Logit can be seen as a series of pairwise comparisons that are unaffected by the characteristics of alternatives. Such a model is said to satisfy the <strong>independence from irrelevant alternatives (IIA)</strong> property. That is, in these models, for any individual, the ratio of probabilities of choosing two alternatives is independent of the availability or attributes of any other alternatives. While this may not sound alarming, there are situations where you would like it not to be the case, this is for instance the case when you want to extrapolate the results of your estimated model to a situation where there is a novel outcome that is highly susbstitutable to one of the previous ones. This can be illustrated with the famous “red-blue bus” example:</p>
<div class="example">
<p><span id="exm:redbluebus" class="example"><strong>Example 3.8  (Red-blue bus and IIA) </strong></span>Assume one has a logit model capturing the decision to travel using either a car (<span class="math inline">\(y=1\)</span>) or a (red) bus (<span class="math inline">\(y=2\)</span>). Assume you want to augment this model to allow for a third choice (<span class="math inline">\(y=3\)</span>): travel with a blue bus. If a blue bus (<span class="math inline">\(y=3\)</span>) is exactly as a red bus, except for the color, then one would expect to have:
<span class="math display">\[
\mathbb{P}(y=3|y \in \{2,3\}) = 0.5,
\]</span>
i.e. <span class="math inline">\(\theta_2 = \theta_3\)</span>.</p>
<p>Assume we had <span class="math inline">\(V_1=V_2\)</span>. We expect to have <span class="math inline">\(V_2=V_3\)</span> (hence <span class="math inline">\(p_2=p_3\)</span>). A multinomial logit model would then imply <span class="math inline">\(p_1=p_2=p_3=0.33\)</span>. It would however seem more reasonable to have <span class="math inline">\(p_1 = p_2 + p_3 = 0.5\)</span> and <span class="math inline">\(p_2=p_3=0.25\)</span>.</p>
</div>
<!-- **Sequential models** -->
<!-- Naturally, other possible ad-hoc modelling strategy are possible, e.g. sequential modelling: -->
<!-- \begin{eqnarray*} -->
<!-- \mathbb{P}(y=1|\bv{x}) &=& F(\theta_1'\bv{x}) \\ -->
<!-- \mathbb{P}(y=2|\bv{x}) &=& (1-F(\theta_1'\bv{x})) \times F(\theta_2'\bv{x}) \\ -->
<!-- \mathbb{P}(y=3|\bv{x}) &=& (1-F(\theta_1'\bv{x})) \times (1 - F(\theta_2'\bv{x})). -->
<!-- \end{eqnarray*} -->
<!-- Easily checked that $\sum_j \mathbb{P}(y=j|\bv{x})=1$. -->
<!-- Example: car purchase; 1st choice = brand, 2nd choice = color. -->
<!-- Likelihood function: -->
<!-- \begin{eqnarray*} -->
<!-- \mathcal{L}(\theta_1,\theta_2;\bv{y},\bv{X}) &=& \prod_{j \in \{1,2,3\}} \left( \prod_{i\,s.t.\,y_i=j} \mathbb{P}(y_i=j|\bv{x}_i)\right). -->
<!-- \end{eqnarray*} -->
<!-- The maximization of the log-likelihood can be performed sequentially (w.r.t. to $\theta_1$ first, and next w.r.t. $\theta_2$). -->
<!-- Weaknesses: results may depend on the chosen sequence + no clear mapping with utility framework. -->
<!-- Alternative: nested logit model (see below) where utilities of alternatives 2 and 3 are affected by correlated shocks. -->
</div>
<div id="nested-logits" class="section level3" number="3.2.3">
<h3>
<span class="header-section-number">3.2.3</span> Nested logits<a class="anchor" aria-label="anchor" href="#nested-logits"><i class="fas fa-link"></i></a>
</h3>
<p>Nested Logits are natural extensions of logit models when choices feature a nesting structure. This approach is relevant when it makes sense to group some choices into the same <em>nest</em>, also called <em>limbs</em>. Intuitively, this framework is consistent with the idea according to which, for each agent, there exist unobserved nest-specific variables.</p>
<!-- %  \item Choice of selecting $j_1 \in \{1,\dots,J_1\}$ and then $j_2 \in \{1,\dots,J_2\}$ is given by: -->
<!-- %  $$ -->
<!-- %  \mathbb{P}(y_1 = j_1,y_2=j_2) = \underbrace{\mathbb{P}(y_2=j_2|y_1 = j_1)}_{\mbox{2$^{nd}$ logit}}\underbrace{\mathbb{P}(y_1 = j_1)}_{\mbox{1$^{st}$ logit}}. -->
<!-- %  $$ -->
<p>The setup is as follows: we consider <span class="math inline">\(J\)</span> <em>limbs</em>. For each limb <span class="math inline">\(j\)</span>, we have <span class="math inline">\(K_j\)</span> <em>branches</em>. Let us denotes by <span class="math inline">\(y_1\)</span> the limb choice (i.e., <span class="math inline">\(y_1 \in \{1,\dots,J\}\)</span>) and by <span class="math inline">\(y_2\)</span> the branch choice (with <span class="math inline">\(y_2 \in \{1,\dots,K_j\}\)</span>). The utility associated with the pair of choices <span class="math inline">\((j,k)\)</span> is given by
<span class="math display">\[
U_{j,k} = V_{j,k} + \varepsilon_{j,k}.
\]</span>
We have:
<span class="math display">\[
\mathbb{P}[(y_1,y_2) = (j,k)|\mathbf{x}] = \mathbb{P}(U_{j,k}&gt;U_{l,m},\,(l,m) \ne (j,k)|\mathbf{x}).
\]</span></p>
<p>One usually make the following two assumptions:</p>
<ol style="list-style-type: lower-roman">
<li><p>The deterministic part of the utility is given by <span class="math inline">\(V_{j,k} = \mathbf{u}_j'\boldsymbol\alpha + \mathbf{v}_{j,k}'\boldsymbol\beta_j\)</span>, where <span class="math inline">\(\boldsymbol\alpha\)</span> is common to all nests and the <span class="math inline">\(\boldsymbol\beta_j\)</span>’s are nest-specific.</p></li>
<li><p>The disturbances <span class="math inline">\(\boldsymbol\varepsilon\)</span> follow the Generalized Extreme Value (GEV) distribution (see Def. <a href="append.html#def:GEVdistri">4.15</a>).</p></li>
</ol>
<p>The following figure displays simulations of pairs <span class="math inline">\((\varepsilon_1,\varepsilon_2)\)</span> drawn from GEV distributions for different values of <span class="math inline">\(\rho\)</span>. The simulation approach is based on <a href="http://www.caee.utexas.edu/prof/bhat/ABSTRACTS/Supp_material.pdf">Bhat</a>. The code used to produce this chart is provided in Appendix <a href="append.html#App:GEV">4.6.1</a>.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:GEV"></span>
<img src="images/Figure_GEV.png" alt="GEV simulations." width="95%"><p class="caption">
Figure 3.7: GEV simulations.
</p>
</div>
<p>Under (i) and (ii), we have:
<span class="math display" id="eq:Nested">\[\begin{eqnarray}
\mathbb{P}[(y_1,y_2) = (j,k)|\mathbf{x}] &amp;=&amp; \underbrace{\frac{\exp(\mathbf{u}_j'\boldsymbol\alpha + \rho_j I_j)}{\sum_{m=1}^J \exp(\mathbf{u}_m'\boldsymbol\alpha + \rho_m I_m)}}_{= \mathbb{P}[y_1 = j|\mathbf{x}]} \times \nonumber\\
&amp;&amp; \underbrace{\frac{\exp(\mathbf{v}_{j,k}'\boldsymbol\beta_j/\rho_j)}{\sum_{l=1}^{K_j} \exp(\mathbf{v}_{j,l}'\boldsymbol\beta_j/\rho_j)}}_{= \mathbb{P}[y_2 = k|y_1=j,\mathbf{x}]}, \tag{3.16}
\end{eqnarray}\]</span>
where <span class="math inline">\(I_j\)</span>’s are called inclusive values (or log sums), given by:
<span class="math display">\[
I_j = \log \left( \sum_{l=1}^{K_j} \exp(\mathbf{v}_{j,l}'\boldsymbol\beta_j/\rho_j)\right).
\]</span></p>
<p>Some remarks are in order:</p>
<ol style="list-style-type: lower-alpha">
<li>It can be shown that <span class="math inline">\(\rho_j = \sqrt{1 - \mathbb{C}or(\varepsilon_{j,k},\varepsilon_{j,l})}\)</span>, for <span class="math inline">\(k \ne l\)</span>.</li>
<li>
<span class="math inline">\(\rho_j=1\)</span> implies that <span class="math inline">\(\varepsilon_{j,k}\)</span> and <span class="math inline">\(\varepsilon_{j,l}\)</span> are uncorrelated (we are then back to the multinomial logit case).</li>
<li>When <span class="math inline">\(J=1\)</span>:
<span class="math display">\[
F([\varepsilon_1,\dots,\varepsilon_K]',\rho) = \exp\left(-\left(\sum_{k=1}^{K} \exp(-\varepsilon_k/\rho)\right)^{\rho}\right).
\]</span>
</li>
<li>We have:
<span class="math display">\[\begin{eqnarray*}
I_j = \mathbb{E}(\max_k(U_{j,k})) &amp;=&amp; \mathbb{E}(\max_k(V_{j,k} + \varepsilon_{j,k})),
\end{eqnarray*}\]</span>
The inclusive values can therefore be seen as measures of the relative attractiveness of a nest.</li>
</ol>
<p>This approach allows for some level of correlation across the <span class="math inline">\(\varepsilon_{j,k}\)</span> (for a given <span class="math inline">\(j\)</span>). This can be interpreted as the existence of an (unobserved) <em>common error component</em> for the alternatives of a same nest. This component contributes to making the alternatives of a given nest more similar. In other words, this approach can accommodate a higher sensitivity (cross-elasticity) between the alternatives of a given nest.</p>
<p>Note that if the common component is reduced to zero (i.e. <span class="math inline">\(\rho_i=1\)</span>), the model boils down to the multinomial logit model with no covariance of error terms among the alternatives.</p>
<p>Contrary to the general multinmial model, nested logits can solve the Red-Blue problem described in Section <a href="microeconometrics.html#MNL">3.2.2</a> (see Example <a href="microeconometrics.html#exm:redbluebus">3.8</a>). Assume you have estimated a model specifying <span class="math inline">\(U_{1} = V_{1} + \varepsilon_{1}\)</span> (car choice) and <span class="math inline">\(U_{2} = V_{2} + \varepsilon_{2}\)</span> (red bus choice). You can then assume that the blue-bus utility is of the form <span class="math inline">\(U_{3} = V_{2} + \varepsilon_{3}\)</span> where <span class="math inline">\(\varepsilon_{3}\)</span> is perfectly correlated to <span class="math inline">\(\varepsilon_{2}\)</span>. This is done by redefining the set of choices as follows:
<span class="math display">\[\begin{eqnarray*}
j=1 &amp;\Leftrightarrow&amp; (j'=1,k=1) \\
j=2 &amp;\Leftrightarrow&amp; (j'=2,k=1) \\
j=3 &amp;\Leftrightarrow&amp; (j'=2,k=2),
\end{eqnarray*}\]</span>
and by setting <span class="math inline">\(\rho_2 \rightarrow 0\)</span>.</p>
<p>IIA holds within a nest, but not when considering alternatives in different nests. Indeed, using Eq. <a href="microeconometrics.html#eq:Nested">(3.16)</a>:
<span class="math display">\[
\frac{\mathbb{P}[y_1=j,y_2=k_A|\mathbf{x}] }{\mathbb{P}[y_1=j,y_2=k_B|\mathbf{x}]} = \frac{\exp(\mathbf{v}_{j,k_A}'\boldsymbol\beta_j/\rho_j)}{\exp(\mathbf{v}_{j,k_B}'\boldsymbol\beta_j/\rho_j)},
\]</span>
i.e. we have IIA in nest <span class="math inline">\(j\)</span>.</p>
<p>By contrast:
<span class="math display">\[\begin{eqnarray*}
\frac{\mathbb{P}[y_1=j_A,y_2=k_A|\mathbf{x}] }{\mathbb{P}[y_1=j_B,y_2=k_B|\mathbf{x}]} &amp;=&amp; \frac{\exp(\mathbf{u}_{j_A}'\boldsymbol\alpha + \rho_{j_A} I_{j_A})\exp(\mathbf{v}_{{j_A},{k_A}}'\boldsymbol\beta_{j_A}/\rho_{j_A})}{\exp(\mathbf{u}_{j_B}'\boldsymbol\alpha + \rho_{j_B} I_{j_B})\exp(\mathbf{v}_{{j_B},{k_B}}'\boldsymbol\beta_{j_B}/\rho_{j_B})}\times\\
&amp;&amp; \frac{\sum_{l=1}^{K_{j_B}} \exp(\mathbf{v}_{{j_B},l}'\boldsymbol\beta_{j_B}/\rho_{j_B})}{\sum_{l=1}^{K_{j_A}} \exp(\mathbf{v}_{{j_A},l}'\boldsymbol\beta_{J_A}/\rho_{j_A})},
\end{eqnarray*}\]</span>
which depends on the expected utilities of all alternatives in nest <span class="math inline">\(j_A\)</span> and <span class="math inline">\(j_B\)</span>. So the IIA does not hold.</p>
<div class="example">
<p><span id="exm:nestedTravel" class="example"><strong>Example 3.9  (Travel-mode dataset) </strong></span>Let us illustrate nested logits on the travel-mode dataset used, e.g., by <span class="citation">Hensher and Greene (<a href="references.html#ref-Hensher_Greene_2002" role="doc-biblioref">2002</a>)</span> (see also <span class="citation">Heiss (<a href="references.html#ref-Heiss_2002" role="doc-biblioref">2002</a>)</span>).</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=mlogit">mlogit</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">stargazer</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"TravelMode"</span>, package <span class="op">=</span> <span class="st">"AER"</span><span class="op">)</span></span>
<span><span class="va">Prepared.TravelMode</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit-deprecated.html">mlogit.data</a></span><span class="op">(</span><span class="va">TravelMode</span>,chid.var <span class="op">=</span> <span class="st">"individual"</span>,</span>
<span>                                   alt.var <span class="op">=</span> <span class="st">"mode"</span>,choice <span class="op">=</span> <span class="st">"choice"</span>,</span>
<span>                                   shape <span class="op">=</span> <span class="st">"long"</span><span class="op">)</span></span>
<span><span class="co"># Fit a multinomial model:</span></span>
<span><span class="va">hl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">wait</span> <span class="op">+</span> <span class="va">travel</span> <span class="op">+</span> <span class="va">vcost</span>, <span class="va">Prepared.TravelMode</span>,</span>
<span>             method <span class="op">=</span> <span class="st">"bfgs"</span>, heterosc <span class="op">=</span> <span class="cn">TRUE</span>, tol <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">## Fit a nested logit model:</span></span>
<span><span class="va">TravelMode</span><span class="op">$</span><span class="va">avincome</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">TravelMode</span>, <span class="va">income</span> <span class="op">*</span> <span class="op">(</span><span class="va">mode</span> <span class="op">==</span> <span class="st">"air"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">TravelMode</span><span class="op">$</span><span class="va">time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">TravelMode</span>, <span class="va">travel</span> <span class="op">+</span> <span class="va">wait</span><span class="op">)</span><span class="op">/</span><span class="fl">60</span></span>
<span><span class="va">TravelMode</span><span class="op">$</span><span class="va">timeair</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">TravelMode</span>, <span class="va">time</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mode</span> <span class="op">==</span> <span class="st">"air"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">TravelMode</span><span class="op">$</span><span class="va">income</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">TravelMode</span>, <span class="va">income</span> <span class="op">/</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co"># Hensher and Greene (2002), table 1 p.8-9 model 5</span></span>
<span><span class="va">TravelMode</span><span class="op">$</span><span class="va">incomeother</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">TravelMode</span>,</span>
<span>                               <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">mode</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'air'</span>, <span class="st">'car'</span><span class="op">)</span>, <span class="va">income</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">nl1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">gcost</span> <span class="op">+</span> <span class="va">wait</span> <span class="op">+</span> <span class="va">incomeother</span>, <span class="va">TravelMode</span>,</span>
<span>              shape<span class="op">=</span><span class="st">'long'</span>, <span class="co"># Indicates how the dataset is organized</span></span>
<span>              alt.var<span class="op">=</span><span class="st">'mode'</span>, <span class="co"># variable that defines the alternative choices.</span></span>
<span>              nests<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>public<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'train'</span>, <span class="st">'bus'</span><span class="op">)</span>,</span>
<span>                         car<span class="op">=</span><span class="st">'car'</span>,air<span class="op">=</span><span class="st">'air'</span><span class="op">)</span>, <span class="co"># defines the "limbs".</span></span>
<span>              un.nest.el <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">nl2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">gcost</span> <span class="op">+</span> <span class="va">wait</span> <span class="op">+</span> <span class="va">time</span>, <span class="va">TravelMode</span>,</span>
<span>              shape<span class="op">=</span><span class="st">'long'</span>, <span class="co"># Inidcates how the dataset is organized</span></span>
<span>              alt.var<span class="op">=</span><span class="st">'mode'</span>, <span class="co"># variable that defines the alternative choices.</span></span>
<span>              nests<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>public<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'train'</span>, <span class="st">'bus'</span><span class="op">)</span>,</span>
<span>                         car<span class="op">=</span><span class="st">'car'</span>,air<span class="op">=</span><span class="st">'air'</span><span class="op">)</span>, <span class="co"># defines the "limbs".</span></span>
<span>              un.nest.el <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">nl1</span>,<span class="va">nl2</span>,type<span class="op">=</span><span class="st">"text"</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ==============================================
##                       Dependent variable:     
##                   ----------------------------
##                              choice           
##                        (1)            (2)     
## ----------------------------------------------
## (Intercept):train     -0.211        -0.284    
##                      (0.562)        (0.551)   
## (Intercept):bus       -0.824        -0.712    
##                      (0.708)        (0.690)   
## (Intercept):car     -5.237***      -3.845***  
##                      (0.785)        (0.844)   
## gcost               -0.013***       -0.004    
##                      (0.004)        (0.006)   
## wait                -0.088***      -0.089***  
##                      (0.011)        (0.011)   
## incomeother          0.430***                 
##                      (0.113)                  
## time                               -0.202***  
##                                     (0.060)   
## iv                   0.835***      0.877***   
##                      (0.192)        (0.198)   
## ----------------------------------------------
## Observations           210            210     
## R2                    0.328          0.313    
## Log Likelihood       -190.779      -194.841   
## LR Test (df = 7)    185.959***    177.836***  
## ==============================================
## Note:              *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
</div>
<div id="tobit" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> Tobit models<a class="anchor" aria-label="anchor" href="#tobit"><i class="fas fa-link"></i></a>
</h2>
<p>In some situations, the dependent variable is incompletely observed, which may result in a non-representative sample. Typically, in some cases, observations of the dependent variable can have a lower and/or an upper limit, while the “true”, underlying, dependent variable has not. In this case, OLS regression may lead to inconsistent parameter estimates.</p>
<p>Tobit models have been designed to address some of these situations. This approach has been named after James Tobin, who developed this model in the late 50s (see <span class="citation">Tobin (<a href="references.html#ref-Tobin_1956" role="doc-biblioref">1956</a>)</span>).</p>
<p>Figure <a href="microeconometrics.html#fig:tobit1">3.8</a> illustrates the situation. The dots (white and black) represent the “true” observations. Now, assume that only the black are observed. If ones uses these observations in an OLS regression to estimate the relatonship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, then one gets the red line. It is clear that the sensitivity of <span class="math inline">\(y\)</span> to <span class="math inline">\(x\)</span> is then underestimated. The blue line is the line one would obtain if white dots were also observed; the grey line represents the model used to genrate the data (<span class="math inline">\(y_i=x_i+\varepsilon_i\)</span>).</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:tobit1"></span>
<img src="MicroEc_files/figure-html/tobit1-1.png" alt="Bias in the case of sample selection. The grey line represents the population regression line. The model is $y_i = x_i + \varepsilon_i$, with $\varepsilon_{i,t} \sim \mathcal{N}(0,1)$. The red line is the OLS regression line based on black dots only." width="672"><p class="caption">
Figure 3.8: Bias in the case of sample selection. The grey line represents the population regression line. The model is <span class="math inline">\(y_i = x_i + \varepsilon_i\)</span>, with <span class="math inline">\(\varepsilon_{i,t} \sim \mathcal{N}(0,1)\)</span>. The red line is the OLS regression line based on black dots only.
</p>
</div>
<p>Assume that the (partially) observed dependent variable follows:
<span class="math display">\[
y^* = \boldsymbol\beta'\mathbf{x} + \varepsilon,
\]</span>
with <span class="math inline">\(\varepsilon\)</span> is drawn from a distribution characterized by a p.d.f. denoted by <span class="math inline">\(f_{\boldsymbol\gamma}^*\)</span> and a c.d.f. denoted by <span class="math inline">\(F_{\boldsymbol\gamma}^*\)</span>; these functions depend on a vector of parameters <span class="math inline">\(\boldsymbol{\gamma}\)</span>.</p>
<p>The observed dependent variable is:
<span class="math display">\[\begin{eqnarray*}
\mbox{Censored case:}&amp;&amp;y = \left\{
\begin{array}{ccc}
y^* &amp;if&amp; y^*&gt;L \\
L &amp;if&amp; y^*\le L,
\end{array}
\right.\\
\mbox{Truncated case:}&amp;&amp;y = \left\{
\begin{array}{ccc}
y^* &amp;if&amp; y^*&gt;L \\
- &amp;if&amp; y^*\le L,
\end{array}
\right.
\end{eqnarray*}\]</span>
where “<span class="math inline">\(-\)</span>” stands for missing observations.</p>
<p>This formulation is easily extended to censoring from above (<span class="math inline">\(L \rightarrow U\)</span>), or censoring from both below and above.</p>
<p>The model parameters are gathered in vector <span class="math inline">\(\theta = [\boldsymbol\beta',\boldsymbol\gamma']'\)</span>. Let us write the conditional p.d.f. of the observed variable:
<span class="math display">\[\begin{eqnarray*}
\mbox{Censored case:}&amp;&amp; f(y|\mathbf{x};\theta) = \left\{
\begin{array}{ccc}
f_{\boldsymbol\gamma}^*(y -  \boldsymbol\beta'\mathbf{x}) &amp;if&amp; y&gt;L \\
F_{\boldsymbol\gamma}^*(L-  \boldsymbol\beta'\mathbf{x}) &amp;if&amp; y = L,
\end{array}
\right.\\
\mbox{Truncated case:}&amp;&amp;  f(y|\mathbf{x};\theta) =
\dfrac{f_{\boldsymbol\gamma}^*(y -  \boldsymbol\beta'\mathbf{x})}{1 - F_{\boldsymbol\gamma}^*(L-  \boldsymbol\beta'\mathbf{x})} \quad \mbox{with} \quad y&gt;L.
\end{eqnarray*}\]</span></p>
<p>The (conditional) log-likelihood function is then given by:
<span class="math display">\[
\log \mathcal{L}(\theta;\mathbf{y},\mathbf{X}) = \sum_{i=1}^n \log f(y_i|\mathbf{x}_i;\theta).
\]</span>
In the censored case, we have:
<span class="math display">\[\begin{eqnarray*}
\log \mathcal{L}(\theta;\mathbf{y},\mathbf{X}) &amp;=&amp; \sum_{i=1}^n \left\{
\mathbb{I}_{\{y_i=L\}}\log\left[F_{\boldsymbol\gamma}^*(L-  \boldsymbol\beta'\mathbf{x}_i)\right] + \right.\\
&amp;&amp; \left. \mathbb{I}_{\{y_i&gt;0\}} \log \left[f_{\boldsymbol\gamma}^*(y_i -  \boldsymbol\beta'\mathbf{x}_i)\right]\right\}.
\end{eqnarray*}\]</span></p>
<p>The Tobit, or censored/truncated normal regression model, corresponds to the case described above, but with Gaussian errors <span class="math inline">\(\varepsilon\)</span>. Specifically:
<span class="math display">\[
y^* = \boldsymbol\beta'\mathbf{x} + \varepsilon,
\]</span>
with <span class="math inline">\(\varepsilon \sim \,i.i.d.\,\mathcal{N}(0,\sigma^2)\)</span> (<span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\boldsymbol\gamma = \sigma^2\)</span>).</p>
<p>Without loss of generality, we can assume that <span class="math inline">\(L=0\)</span>. (One can shift observed data if necessary.)</p>
<ul>
<li><p>The censored density (with <span class="math inline">\(L=0\)</span>) is given by:
<span class="math display">\[
f(y) = \left[
\frac{1}{\sqrt{2 \pi \sigma^2}}\exp\left(-\frac{1}{2 \sigma^2}(y - \boldsymbol\beta'\mathbf{x})^2\right)
\right]^{\mathbb{I}_{\{y&gt;0\}}}
\left[
1 - \Phi\left(\frac{\boldsymbol\beta'\mathbf{x}}{\sigma}\right)
\right]^{\mathbb{I}_{\{y=0\}}}.
\]</span></p></li>
<li><p>The truncated density (with <span class="math inline">\(L=0\)</span>) is given by:
<span class="math display">\[
f(y) = \frac{1}{\Phi(\boldsymbol\beta'\mathbf{x})}
\frac{1}{\sqrt{2 \pi \sigma^2}}\exp\left(-\frac{1}{2 \sigma^2}(y - \boldsymbol\beta'\mathbf{x})^2\right).
\]</span></p></li>
</ul>
<p>Results usually heavily rely on distributional assumptions (more than in uncensored/untruncated case). The framework is easy to extend to an heteroskedastic case, for instance by setting <span class="math inline">\(\sigma_i^2=\exp(\alpha'\mathbf{x}_i)\)</span>. Such a situation is illustrated by Figure <a href="microeconometrics.html#fig:tobit2">3.9</a>.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:tobit2"></span>
<img src="MicroEc_files/figure-html/tobit2-1.png" alt="Censored dataset with heteroskedasticitiy. The model is $y_i = x_i + \varepsilon_i$, with $\varepsilon_{i,t} \sim \mathcal{N}(0,\sigma_i^2)$ where $\sigma_i = \exp(-1 + x_i)$." width="672"><p class="caption">
Figure 3.9: Censored dataset with heteroskedasticitiy. The model is <span class="math inline">\(y_i = x_i + \varepsilon_i\)</span>, with <span class="math inline">\(\varepsilon_{i,t} \sim \mathcal{N}(0,\sigma_i^2)\)</span> where <span class="math inline">\(\sigma_i = \exp(-1 + x_i)\)</span>.
</p>
</div>
<p>Let us consider the conditional means of <span class="math inline">\(y\)</span> in the general case, i.e., for any <span class="math inline">\(\varepsilon\)</span> distribution. Assume <span class="math inline">\(\mathbf{x}\)</span> is observed, such that expectations are conditional on <span class="math inline">\(\mathbf{x}\)</span>.</p>
<ul>
<li><p>For data that are left-truncated at 0, we have:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y) &amp;=&amp; \mathbb{E}(y^*|y^*&gt;0) = \underbrace{\boldsymbol\beta'\mathbf{x}}_{=\mathbb{E}(y^*)} + \underbrace{\mathbb{E}(\varepsilon|\varepsilon&gt;-\boldsymbol\beta'\mathbf{x})}_{&gt;0} &gt; \mathbb{E}(y^*).
\end{eqnarray*}\]</span></p></li>
<li><p>Consider data that are left-censored at 0. By Bayes, we have:
<span class="math display">\[
f_{y^*|y^*&gt;0}(u) = \frac{f_{y^*}(u)}{\mathbb{P}(y^*&gt;0)}\mathbb{I}_{\{u&gt;0\}}.
\]</span>
Therefore:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y^*|y^*&gt;0) &amp;=&amp; \frac{1}{\mathbb{P}(y^*&gt;0)} \int_{-\infty}^\infty u\, f_{y^*}(u)\mathbb{I}_{\{u&gt;0\}} du \\
&amp;=&amp;  \frac{1}{\mathbb{P}(y^*&gt;0)} \mathbb{E}(\underbrace{y^*\mathbb{I}_{\{y^*&gt;0\}}}_{=y}),
\end{eqnarray*}\]</span>
and, further:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y) &amp;=&amp;  \mathbb{P}(y^*&gt;0)\mathbb{E}(y^*|y^*&gt;0)\\
&amp;&gt;&amp;  \mathbb{E}(y^*) =  \mathbb{P}(y^*&gt;0)\mathbb{E}(y^*|y^*&gt;0) +  \mathbb{P}(y^*&lt;0)\underbrace{\mathbb{E}(y^*|y^*&lt;0)}_{&lt;0}.
\end{eqnarray*}\]</span></p></li>
</ul>
<p>Now, let us come back to the Tobit (i.e., Gaussian case) case.</p>
<ul>
<li><p>For data that are left-truncated at 0:
<span class="math display" id="eq:Econdtruncated">\[\begin{eqnarray}
\mathbb{E}(y) &amp;=&amp; \boldsymbol\beta'\mathbf{x} + \mathbb{E}(\varepsilon|\varepsilon&gt;-\boldsymbol\beta'\mathbf{x}) \nonumber\\
&amp;=&amp;  \boldsymbol\beta'\mathbf{x} + \sigma \underbrace{\frac{\phi(\boldsymbol\beta'\mathbf{x}/\sigma)}{\Phi(\boldsymbol\beta'\mathbf{x}/\sigma)}}_{=: \lambda(\boldsymbol\beta'\mathbf{x}/\sigma)} = \sigma \left( \frac{\boldsymbol\beta'\mathbf{x}}{\sigma} + \lambda\left(\frac{\boldsymbol\beta'\mathbf{x}}{\sigma}\right)\right). \tag{3.17}
\end{eqnarray}\]</span>
where the penultimate line is obtained by using Eq. <a href="append.html#eq:Etrunc">(4.5)</a>.</p></li>
<li><p>For data that are left-censored at 0:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y) &amp;=&amp;  \mathbb{P}(y^*&gt;0)\mathbb{E}(y^*|y^*&gt;0)\\
&amp;=&amp;  \Phi\left( \frac{\boldsymbol\beta'\mathbf{x}}{\sigma}\right) \sigma \left(
\frac{\boldsymbol\beta'\mathbf{x}}{\sigma} +   \lambda\left(\frac{\boldsymbol\beta'\mathbf{x}}{\sigma}\right)
\right).
\end{eqnarray*}\]</span></p></li>
</ul>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:tobit3"></span>
<img src="MicroEc_files/figure-html/tobit3-1.png" alt="Conditional means of $y$ in Tobit models. The model is $y_i = x_i + \varepsilon_i$, with $\varepsilon_i \sim \mathcal{N}(0,1)$." width="672"><p class="caption">
Figure 3.10: Conditional means of <span class="math inline">\(y\)</span> in Tobit models. The model is <span class="math inline">\(y_i = x_i + \varepsilon_i\)</span>, with <span class="math inline">\(\varepsilon_i \sim \mathcal{N}(0,1)\)</span>.
</p>
</div>
<!-- %\begin{frame}{Tobit Model} -->
<!-- %\begin{footnotesize} -->
<!-- %\begin{itemize} -->
<!-- %  \item It is easily seen that: -->
<!-- %  $$ -->
<!-- %  \mathbb{P}(y^* \le 0) =  \Phi\left(-\frac{\boldsymbol\beta'\bv{x}}{\sigma}\right) = 1 - \Phi\left(\frac{\boldsymbol\beta'\bv{x}}{\sigma}\right). -->
<!-- %  $$ -->
<!-- %  \item If $y=0$ when $y^*<0$, then the p.d.f. of $y$ therefore is: -->
<!-- %  $$ -->
<!-- %  f(y) = \left[1 - \Phi\left(\frac{\boldsymbol\beta'\bv{x}}{\sigma}\right)\right]^{\mathbb{I}_{\{y=0\}}} -->
<!-- %  \left[\frac{1}{\sqrt{2\pi \sigma^2}}\exp\left(-\frac{(y - \boldsymbol\beta'\bv{x})}{2\sigma^2}\right)\right]^{\mathbb{I}_{\{y>0\}}}. -->
<!-- %  $$ -->
<!-- %  \item The log-likelihood function is: -->
<!-- %  \begin{eqnarray*} -->
<!-- %  \log \mathcal{L}(\boldsymbol\beta,\sigma^2;\bv{y},\bv{X}) &=& \sum_{i=1}^n \left\{ -->
<!-- %  \mathbb{I}_{\{y_i=0\}}\log\left[1 - \Phi\left(\frac{\boldsymbol\beta'\bv{x}_i}{\sigma}\right)\right] + \right.\\ -->
<!-- %  && \left. \mathbb{I}_{\{y_i>0\}} \log \left[\frac{1}{\sqrt{2\pi \sigma^2}}\exp\left(-\frac{(y_i - \boldsymbol\beta'\bv{x}_i)}{2\sigma^2}\right)\right]\right\}. -->
<!-- %  \end{eqnarray*} -->
<!-- %\end{itemize} -->
<!-- %\end{footnotesize} -->
<!-- %\end{frame} -->
<p><strong>Heckit regression</strong></p>
<p>The previous formula (Eq. <a href="microeconometrics.html#eq:Econdtruncated">(3.17)</a>) can in particular be used in an alternative estimation approach, namely the Heckman two-step estimation. This approach is based on two steps:<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;See 16.10.2 of &lt;span class="citation"&gt;Cameron and Trivedi (&lt;a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref"&gt;2005&lt;/a&gt;)&lt;/span&gt; for the derivation of asymptotic standard errors of &lt;span class="math inline"&gt;\(\boldsymbol\beta\)&lt;/span&gt;.&lt;/p&gt;'><sup>11</sup></a></p>
<ol style="list-style-type: decimal">
<li><p>Using the complete sample, fit a Probit model of <span class="math inline">\(\mathbb{I}_{\{y_i&gt;0\}}\)</span> on <span class="math inline">\(\mathbf{x}\)</span>. This provides a consistent estimate of <span class="math inline">\(\frac{\boldsymbol\beta}{\sigma}\)</span>, and therefore of <span class="math inline">\(\lambda(\boldsymbol\beta'\mathbf{x}/\sigma)\)</span>. (Indeed, if <span class="math inline">\(z_i \equiv \mathbb{I}_{\{y_i&gt;0\}}\)</span>, then <span class="math inline">\(\mathbb{P}(z_i=1|\mathbf{x}_i;\boldsymbol\beta/\sigma)=\Phi(\boldsymbol\beta'\mathbf{x}_i/\sigma)\)</span>.)</p></li>
<li><p>Using the truncated sample only: run an OLS regression of <span class="math inline">\(\mathbf{y}\)</span> on <span class="math inline">\(\left\{\mathbf{x},\lambda(\boldsymbol\beta'\mathbf{x}/\sigma)\right\}\)</span> (having Eq. <a href="microeconometrics.html#eq:Econdtruncated">(3.17)</a> in mind). This provides a consistent estimate of <span class="math inline">\((\boldsymbol\beta,\sigma)\)</span>.</p></li>
</ol>
<p>The underlying specification is of the form:
<span class="math display">\[
\mbox{Conditional mean} + \mbox{disturbance}.
\]</span>
where “Conditional mean” comes from Eq. <a href="microeconometrics.html#eq:Econdtruncated">(3.17)</a> and “disturbance” is an error with zero conditional mean.</p>
<p>This approach is also applied to the case of <strong>sample selection models</strong> (Section <a href="microeconometrics.html#SSM">3.4</a>).</p>
<div class="example">
<p><span id="exm:WageMroz1" class="example"><strong>Example 3.10  (Wage prediction) </strong></span>The present example is based on the dataset used in <span class="citation">Mroz (<a href="references.html#ref-Mroz_1987" role="doc-biblioref">1987</a>)</span> (whicht is part of the <code>sampleSelection</code> package).</p>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sampleSelection.org">sampleSelection</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AER</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Mroz87"</span><span class="op">)</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span> <span class="op">&lt;-</span> <span class="cn">NaN</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">[</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp</span><span class="op">==</span><span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"yes"</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">[</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp</span><span class="op">==</span><span class="fl">0</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"no"</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">)</span></span>
<span><span class="va">ols</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">wage</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>,data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">Mroz87</span>,<span class="va">lfp</span><span class="op">==</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tobit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/AER/man/tobit.html">tobit</a></span><span class="op">(</span><span class="va">wage</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>,</span>
<span>               left <span class="op">=</span> <span class="fl">0</span>, right <span class="op">=</span> <span class="cn">Inf</span>,</span>
<span>               data<span class="op">=</span><span class="va">Mroz87</span><span class="op">)</span></span>
<span><span class="va">Heckit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sampleSelection/man/selection.html">heckit</a></span><span class="op">(</span><span class="va">lfp</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>, <span class="co"># selection equation</span></span>
<span>                 <span class="va">wage</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>, <span class="co"># outcome equation</span></span>
<span>                 data<span class="op">=</span><span class="va">Mroz87</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">ols</span>,<span class="va">Heckit</span>,<span class="va">tobit</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span>,type<span class="op">=</span><span class="st">"text"</span>,omit.stat <span class="op">=</span> <span class="st">"f"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ======================================================================
##                                    Dependent variable:                
##                     --------------------------------------------------
##                                            wage                       
##                           OLS           Heckman           Tobit       
##                                        selection                      
##                           (1)             (2)              (3)        
## ----------------------------------------------------------------------
## educ                    0.481***       0.759***         0.642***      
##                         (0.067)         (0.270)          (0.081)      
## exper                    0.032           0.430          0.461***      
##                         (0.062)         (0.369)          (0.068)      
## I(exper2)               -0.0003         -0.008          -0.009***     
##                         (0.002)         (0.008)          (0.002)      
## city                     0.449           0.113           -0.087       
##                         (0.318)         (0.522)          (0.378)      
## Constant               -2.561***        -12.251        -10.395***     
##                         (0.929)         (8.853)          (1.095)      
## ----------------------------------------------------------------------
## Observations              428             753              753        
## R2                       0.125           0.128                        
## Adjusted R2              0.117           0.117                        
## Log Likelihood                                         -1,462.700     
## rho                                      1.063                        
## Inverse Mills Ratio                  5.165 (4.594)                    
## Residual Std. Error 3.111 (df = 423)                                  
## Wald Test                                          153.892*** (df = 4)
## ======================================================================
## Note:                                      *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Figure <a href="microeconometrics.html#fig:tobit5">3.11</a> shows that, low wages, the OLS model tends to over-predict wages. The slope between observed and Tobit-predicted wages is closer to one (the adjustment line is closer to the 45-degree line.)</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:tobit5"></span>
<img src="MicroEc_files/figure-html/tobit5-1.png" alt="Predicted versus observed wages." width="672"><p class="caption">
Figure 3.11: Predicted versus observed wages.
</p>
</div>
</div>
<!-- \begin{frame}{Tobit Model} -->
<!-- \begin{footnotesize} -->
<!-- \begin{itemize} -->
<!--    \item Tobit models crucially depend on distributional assumptions. Specification tests, see m-Test (Remark\,\@ref(remark:mTest}). -->
<!--    \item Specific case of (suspected) heteroskedasticity: -->
<!--        $$ -->
<!--        H_0: \,\sigma_i^2=\sigma^2, \qquad \quad H_1:\, \sigma_i^2 = \exp(\bv{x}_i\alpha). -->
<!--        $$ -->
<!--    \href{http://cameron.econ.ucdavis.edu/mmabook/mma.html}{Cameron and Trivedi}  (16.3.7) propose an OPG LM test (see Slide\,\@ref(Slide:OPG}), based on the OLS regression: -->
<!--    $$ -->
<!--    1 = \gamma_1 \bv{s}_{i,1} + \gamma_2 \bv{s}_{i,2} + \varepsilon_i, -->
<!--    $$ -->
<!--    where $\bv{s}_{i,1} = \partial \log f(y_i,\boldsymbol\beta,\boldsymbol\alpha)/\partial \boldsymbol\beta$ and $\bv{s}_{i,2} = \partial \log f(y_i,\boldsymbol\beta,\boldsymbol\alpha)/\partial \boldsymbol\alpha$. -->
<!--    (The test statistics is $n \times R_u^2$, where $R_u^2$ is the uncentered $R^2$.) -->
<!-- \end{itemize} -->
<!-- \end{footnotesize} -->
<!-- \end{frame} -->
<p><strong>Two-part model</strong></p>
<p>In the standard Tobit framework, the model determining censored —or truncated— data <em>censoring mechanism</em> is the same as the one determining non-censored —or observed— data <em>outcome mechanism</em>. A two-part model adds flexibility by permitting the zeros and non-zeros to be generated by different densities. The second model characterizes the outcome <em>conditional on</em> the outcome being observed.</p>
<p>In a seminal paper, <span class="citation">Duan et al. (<a href="references.html#ref-Duan_et_al_1983" role="doc-biblioref">1983</a>)</span> employ this methodology to account for individual annual hospital expenses. The two models are then as follows:</p>
<ul>
<li>
<span class="math inline">\(1^{st}\)</span> model: <span class="math inline">\(\mathbb{P}(hosp=1|\mathbf{x}) = \Phi(\mathbf{x}_1'\boldsymbol\beta_1)\)</span>,</li>
<li>
<span class="math inline">\(2^{nd}\)</span> model: <span class="math inline">\(Expense = \exp(\mathbf{x}_2'\boldsymbol\beta_2 + \eta)\)</span>, with <span class="math inline">\(\eta \sim\,i.i.d.\, \mathcal{N}(0,\sigma_2^2)\)</span>.</li>
</ul>
<p>Specifically:
<span class="math display">\[
\mathbb{E}(Expense|\mathbf{x}_1,\mathbf{x}_2) = \Phi(\mathbf{x}_1'\boldsymbol\beta_1)\exp\left(\mathbf{x}_2'\boldsymbol\beta_2+ \frac{\sigma_2^2}{2}\right).
\]</span></p>
<p>In sample-selection models, studied in the next section, one specifies the joint distribution for the censoring and outcome mechanisms (while the two parts are independent here).</p>
</div>
<div id="SSM" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> Sample Selection Models<a class="anchor" aria-label="anchor" href="#SSM"><i class="fas fa-link"></i></a>
</h2>
<p>The situation tackled by sample-selection models is the following. The dependent variable of interest, denoted by <span class="math inline">\(y_2\)</span>, depends on observed variables <span class="math inline">\(\mathbf{x}_2\)</span>. Observing <span class="math inline">\(y_2\)</span>, or not, depends on the value of a latent variable (<span class="math inline">\(y_1^*\)</span>) that is correlated to observed variables <span class="math inline">\(\mathbf{x}_1\)</span>. The difference w.r.t. the two-part model skethed above is that, even conditionally on <span class="math inline">\((\mathbf{x}_1,\mathbf{x}_2)\)</span>, <span class="math inline">\(y_1^*\)</span> and <span class="math inline">\(y_2\)</span> may be correlated.</p>
<p>As in the Tobit case, even in the simplest case of population conditional mean linear in regressors (i.e. <span class="math inline">\(y_2 = \mathbf{x}_2'\boldsymbol\beta_2 + \varepsilon_2\)</span>), OLS regression leads to inconsistent parameter estimates because the sample is not representative of the population.</p>
<p>There are two latent variables: <span class="math inline">\(y_1^*\)</span> and <span class="math inline">\(y_2^*\)</span>. We observe <span class="math inline">\(y_1\)</span> and, if the considered entity “participates”, we also observe <span class="math inline">\(y_2\)</span>. More specifically:
<span class="math display">\[\begin{eqnarray*}
y_1 &amp;=&amp; \left\{
\begin{array}{ccc}
1 &amp;\mbox{if}&amp; y_1^* &gt; 0 \\
0 &amp;\mbox{if}&amp; y_1^* \le 0
\end{array}
\right. \quad \mbox{(participation equation)}\\
y_2 &amp;=&amp; \left\{
\begin{array}{ccc}
y_2^* &amp;\mbox{if}&amp; y_1 = 1 \\
- &amp;\mbox{if}&amp; y_1 = 0
\end{array}
\right. \quad \mbox{(outcome equation).}
\end{eqnarray*}\]</span></p>
<p>Moreover:
<span class="math display">\[\begin{eqnarray*}
y_1^* &amp;=&amp; \mathbf{x}_1'\boldsymbol\beta_1 + \varepsilon_1 \\
y_2^* &amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \varepsilon_2.
\end{eqnarray*}\]</span></p>
<p>Note that the Tobit model (Section <a href="microeconometrics.html#tobit">3.3</a>) is the special case where <span class="math inline">\(y_1^*=y_2^*\)</span>.</p>
<p>Usually:
<span class="math display">\[
\left[\begin{array}{c}\varepsilon_1\\\varepsilon_2\end{array}\right] \sim \mathcal{N}\left(\mathbf{0},
\left[
\begin{array}{cc}
1 &amp; \rho  \sigma_2 \\
\rho  \sigma_2 &amp; \sigma_2^2
\end{array}
\right]
\right).
\]</span>
Let us derive the likelihood associated with this model. We have:
<span class="math display" id="eq:probaPP2">\[\begin{eqnarray}
f(\underbrace{0}_{=y_1},\underbrace{-}_{=y_2}|\mathbf{x};\theta) &amp;=&amp; \mathbb{P}(y_1^*\le 0) = \Phi(-\mathbf{x}_1'\boldsymbol\beta_1) \tag{3.18}\\
f(1,y_2|\mathbf{x};\theta) &amp;=&amp; f(y_2^*|\mathbf{x};\theta) \mathbb{P}(y_1^*&gt;0|y_2^*,\mathbf{x};\theta) \nonumber \\
&amp;=&amp; \frac{1}{\sigma}\phi\left(\frac{y_2 - \mathbf{x}_2'\boldsymbol\beta_2}{\sigma}\right)  \mathbb{P}(y_1^*&gt;0|y_2,\mathbf{x};\theta).\tag{3.19}
\end{eqnarray}\]</span></p>
<p>Let us compute <span class="math inline">\(\mathbb{P}(y_1^*&gt;0|y_2,\mathbf{x};\theta)\)</span>. By Prop. <a href="append.html#prp:update">4.16</a> (in Appendix <a href="append.html#GaussianVar">4.4</a>), applied to (<span class="math inline">\(\varepsilon_1,\varepsilon_2\)</span>), we have:
<span class="math display">\[
y_1^*|y_2 \sim \mathcal{N}\left(\mathbf{x}_1'\boldsymbol\beta_1 + \frac{\rho}{\sigma_2}(y_2-\mathbf{x}_2'\boldsymbol\beta_2),1-\rho^2\right).
\]</span>
which leads to
<span class="math display" id="eq:probaPP3">\[\begin{equation}
\mathbb{P}(y_1^*&gt;0|y_2,\mathbf{x};\theta) = \Phi\left( \frac{\mathbf{x}_1'\boldsymbol\beta_1 + \dfrac{\rho}{\sigma_2}(y_2-\mathbf{x}_2'\boldsymbol\beta_2)}{\sqrt{1-\rho^2}}\right).\tag{3.20}
\end{equation}\]</span></p>
<p>Figure <a href="microeconometrics.html#fig:SampleSelec">3.12</a> displays <span class="math inline">\(\mathbb{P}(y_1^*&gt;0|y_2,\mathbf{x};\theta)\)</span> for different values of <span class="math inline">\(y_2\)</span> and of <span class="math inline">\(\rho\)</span>, in the case where <span class="math inline">\(\boldsymbol\beta_1=\boldsymbol\beta_2=0\)</span>.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:SampleSelec"></span>
<img src="MicroEc_files/figure-html/SampleSelec-1.png" alt="Probability of observing $y_2$ depending on its value, for different values of conditional correlation between $y_2$ and $y_1^*$." width="672"><p class="caption">
Figure 3.12: Probability of observing <span class="math inline">\(y_2\)</span> depending on its value, for different values of conditional correlation between <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_1^*\)</span>.
</p>
</div>
<p>Using Eqs. <a href="microeconometrics.html#eq:probaPP1">(3.18)</a>, <a href="microeconometrics.html#eq:probaPP2">(3.19)</a> and <a href="microeconometrics.html#eq:probaPP3">(3.20)</a>, one gets the log-likelihood function:
<span class="math display">\[\begin{eqnarray*}
\log \mathcal{L}(\theta;\mathbf{y},\mathbf{X}) &amp;=&amp; \sum_{i=1}^n  (1 - y_{1,i})\log \Phi(-\mathbf{x}_{1,i}'\boldsymbol\beta_1) + \\
&amp;&amp;  \sum_{i=1}^n y_{1,i} \log \left(  \frac{1}{\sigma}\phi\left(\frac{y_{2,i} - \mathbf{x}_{2,i}'\boldsymbol\beta_2}{\sigma}\right)\right) + \\
&amp;&amp;  \sum_{i=1}^n y_{1,i} \log \left(\Phi\left( \frac{\mathbf{x}_{1,i}'\boldsymbol\beta_1 + \dfrac{\rho}{\sigma_2}(y_{2,i}-\mathbf{x}_2'\boldsymbol\beta_2)}{\sqrt{1-\rho^2}}\right)\right).
\end{eqnarray*}\]</span></p>
<p>We can also compute conditional expectations:
<span class="math display" id="eq:y2y11">\[\begin{eqnarray}
\mathbb{E}(y_2^*|y_1=1,\mathbf{x}) &amp;=&amp; \mathbb{E}(\mathbb{E}(y_2^*|y_1^*,\mathbf{x})|y_1=1,\mathbf{x})\nonumber\\
&amp;=&amp; \mathbb{E}(\mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2(y_1^*-\mathbf{x}_1'\boldsymbol\beta_1)|y_1=1,\mathbf{x})\nonumber\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\mathbb{E}( \underbrace{y_1^*-\mathbf{x}_1'\boldsymbol\beta_1}_{=\varepsilon_1 \sim\mathcal{N}(0,1)}|\varepsilon_1&gt;-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x})\nonumber\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\frac{\phi(-\mathbf{x}_1'\boldsymbol\beta_1)}{1 - \Phi(-\mathbf{x}_1'\boldsymbol\beta_1)}\nonumber\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\frac{\phi(\mathbf{x}_1'\boldsymbol\beta_1)}{\Phi(\mathbf{x}_1'\boldsymbol\beta_1)}=\mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\lambda(\mathbf{x}_1'\boldsymbol\beta_1),\tag{3.21}
\end{eqnarray}\]</span>
and:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y_2^*|y_1=0,\mathbf{x}) &amp;=&amp;  \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\mathbb{E}(y_1^*-\mathbf{x}_1'\boldsymbol\beta_1|\varepsilon_1\le-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x})\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 + \rho\sigma_2\frac{\phi(-\mathbf{x}_1'\boldsymbol\beta_1)}{1 - \Phi(-\mathbf{x}_1'\boldsymbol\beta_1)}\\
&amp;=&amp; \mathbf{x}_2'\boldsymbol\beta_2 - \rho\sigma_2\frac{\phi(-\mathbf{x}_1'\boldsymbol\beta_1)}{\Phi(-\mathbf{x}_1'\boldsymbol\beta_1)}=\mathbf{x}_2'\boldsymbol\beta_2 - \rho\sigma_2\lambda(-\mathbf{x}_1'\boldsymbol\beta_1).
\end{eqnarray*}\]</span></p>
<p><strong>Heckman procedure</strong></p>
<p>As for tobit models (Section <a href="microeconometrics.html#tobit">3.3</a>), we can use the Heckman procedure to estimate this model. Eq. <a href="microeconometrics.html#eq:y2y11">(3.21)</a> shows that <span class="math inline">\(\mathbb{E}(y_2^*|y_1=1,\mathbf{x}) \ne \mathbf{x}_2'\boldsymbol\beta_2\)</span> when <span class="math inline">\(\rho \ne 0\)</span>. Therefore, the OLS approach yields biased estimates based when it is employed only on the sub-sample where <span class="math inline">\(y_1=1\)</span>.</p>
<p>The Heckman two-step procedure (or “Heckit”) consists in replacing <span class="math inline">\(\lambda(\mathbf{x}_1'\boldsymbol\beta_1)\)</span> appearing in Eq. <a href="microeconometrics.html#eq:y2y11">(3.21)</a> with a consistent estimate of it. More precisely:</p>
<ol style="list-style-type: decimal">
<li>Get an estimate <span class="math inline">\(\widehat{\boldsymbol\beta_1}\)</span> of <span class="math inline">\(\boldsymbol\beta_1\)</span> (probit regression of <span class="math inline">\(y_1\)</span> on <span class="math inline">\(\mathbf{x}_1\)</span>).</li>
<li>Run the OLS regression (using only data associated with <span class="math inline">\(y_1=1\)</span>):
<span class="math display" id="eq:OLSregHecki\tag{3.22}on}(#eq:OLSregHeckit)
y_2  = \mathbf{x}_2'\boldsymbol\beta_2 + \rho \sigma_2 \lambda(\mathbf{x}_1'\widehat{\boldsymbol\beta_1}) + \varepsilon_2,
\end{equation}\]&lt;/span&gt;
considering &lt;span class=" math inline>\(\lambda(\mathbf{x}_1'\widehat{\boldsymbol\beta_1})\)</span> as a regressor.</li>
</ol>
<p>How to estimate <span class="math inline">\(\sigma_2^2\)</span>? By Eq. <a href="append.html#eq:Vtrunc">(4.6)</a>, we have:
<span class="math display">\[
\mathbb{V}ar(y_2|y_1^*&gt;0,\mathbf{x}) = \mathbb{V}ar(\varepsilon_2|\varepsilon_1&gt;-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x}).
\]</span>
Using that <span class="math inline">\(\varepsilon_2\)</span> can be decomposed as <span class="math inline">\(\rho\sigma_2\varepsilon_1 + \xi\)</span>, where <span class="math inline">\(\xi \sim \mathcal{N}(0,\sigma_2^2(1-\rho^2))\)</span> is independent from <span class="math inline">\(\varepsilon_1\)</span>, we get:
<span class="math display">\[
\mathbb{V}ar(y_2|y_1^*&gt;0,\mathbf{x}) = \sigma_2^2(1-\rho^2) + \rho^2\sigma_2^2 \mathbb{V}ar(\varepsilon_1|\varepsilon_1&gt;-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x}).
\]</span>
Using Eq. <a href="append.html#eq:Vtrunc2">(4.7)</a>, we get:
<span class="math display">\[
\mathbb{V}ar(\varepsilon_1|\varepsilon_1&gt;-\mathbf{x}_1'\boldsymbol\beta_1,\mathbf{x}) = 1 - \mathbf{x}_1'\boldsymbol\beta_1 \lambda(\mathbf{x}_1'\boldsymbol\beta_1) - \lambda(\mathbf{x}_1'\boldsymbol\beta_1)^2,
\]</span>
which gives
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}ar(y_2|y_1^*&gt;0,\mathbf{x}) &amp;=&amp; \sigma_2^2(1-\rho^2) + \rho^2\sigma_2^2 (1 - \mathbf{x}_1'\boldsymbol\beta_1 \lambda(\mathbf{x}_1'\boldsymbol\beta_1) - \lambda(\mathbf{x}_1'\boldsymbol\beta_1)^2)\\
&amp;=&amp; \sigma_2^2 - \rho^2\sigma_2^2 \left(\mathbf{x}_1'\boldsymbol\beta_1 \lambda(\mathbf{x}_1'\boldsymbol\beta_1) + \lambda(\mathbf{x}_1'\boldsymbol\beta_1)^2\right),
\end{eqnarray*}\]</span>
and, finally:
<span class="math display">\[
\sigma_2^2 \approx \widehat{\mathbb{V}ar}(y_2|y_1^*&gt;0,\mathbf{x}) + \widehat{\rho \sigma_2}^2 \left(\mathbf{x}_1'\widehat{\boldsymbol\beta_1} \lambda(\mathbf{x}_1'\widehat{\boldsymbol\beta_1}) + \lambda(\mathbf{x}_1'\widehat{\boldsymbol\beta_1})^2\right).
\]</span></p>
<p>The Heckman procedure is computationally simple. Although computational costs are no longer an issue, the two-step solution allows certain generalisations more easily than ML, and is more robust in certain circumstances. The computation of parameter standard errors is fairly complicated because of the two steps (see <span class="citation">Cameron and Trivedi (<a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref">2005</a>)</span>, Subsection 16.10.2). Bootstrap can be resorted to.</p>
<div class="example">
<p><span id="exm:WageSample" class="example"><strong>Example 3.11  (Wage prediction) </strong></span>As in Example <a href="microeconometrics.html#exm:WageMroz1">3.10</a>, let us use the <span class="citation">Mroz (<a href="references.html#ref-Mroz_1987" role="doc-biblioref">1987</a>)</span> dataset again, with the objective of explaining wage setting.</p>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sampleSelection.org">sampleSelection</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AER</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Mroz87"</span><span class="op">)</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span> <span class="op">&lt;-</span> <span class="cn">NaN</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">[</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp</span><span class="op">==</span><span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"yes"</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">[</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp</span><span class="op">==</span><span class="fl">0</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"no"</span></span>
<span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Mroz87</span><span class="op">$</span><span class="va">lfp.yesno</span><span class="op">)</span></span>
<span><span class="co">#Logit &amp; Probit (selection equation)</span></span>
<span><span class="va">logitW</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">lfp</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">age</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">kids5</span> <span class="op">+</span> <span class="va">huswage</span> <span class="op">+</span> <span class="va">educ</span>,</span>
<span>              family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Mroz87</span><span class="op">)</span> </span>
<span><span class="va">probitW</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">lfp</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">age</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">kids5</span> <span class="op">+</span> <span class="va">huswage</span> <span class="op">+</span> <span class="va">educ</span>,</span>
<span>               family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"probit"</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Mroz87</span><span class="op">)</span> </span>
<span><span class="co"># OLS for outcome:</span></span>
<span><span class="va">ols1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span> <span class="op">~</span> <span class="va">educ</span><span class="op">+</span><span class="va">exper</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span><span class="op">+</span><span class="va">city</span>,data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">Mroz87</span>,<span class="va">lfp</span><span class="op">==</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Two-step Heckman estimation</span></span>
<span><span class="va">heckvan</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/sampleSelection/man/selection.html">heckit</a></span><span class="op">(</span> <span class="va">lfp</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">age</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">kids5</span> <span class="op">+</span> <span class="va">huswage</span> <span class="op">+</span> <span class="va">educ</span>, <span class="co"># selection equation</span></span>
<span>          <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span> <span class="op">~</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">exper</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span> <span class="va">exper</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span> <span class="op">+</span> <span class="va">city</span>, <span class="co"># outcome equation</span></span>
<span>          data<span class="op">=</span><span class="va">Mroz87</span> <span class="op">)</span></span>
<span><span class="co"># Maximun likelihood estimation of selection model:</span></span>
<span><span class="va">ml</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sampleSelection/man/selection.html">selection</a></span><span class="op">(</span><span class="va">lfp</span><span class="op">~</span><span class="va">age</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">age</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">+</span><span class="va">kids5</span><span class="op">+</span><span class="va">huswage</span><span class="op">+</span><span class="va">educ</span>, </span>
<span>                <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span><span class="op">~</span><span class="va">educ</span><span class="op">+</span><span class="va">exper</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">exper</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">+</span><span class="va">city</span>, data <span class="op">=</span> <span class="va">Mroz87</span><span class="op">)</span></span>
<span><span class="co"># Print selection-equation estimates:</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">logitW</span>,<span class="va">probitW</span>,<span class="va">heckvan</span>,<span class="va">ml</span>,type <span class="op">=</span> <span class="st">"text"</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          selection.equation <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ===================================================================
##                                   Dependent variable:              
##                     -----------------------------------------------
##                                           lfp                      
##                     logistic   probit      Heckman      selection  
##                                           selection                
##                        (1)       (2)         (3)           (4)     
## -------------------------------------------------------------------
## age                   0.012     0.010       0.010         0.010    
##                      (0.114)   (0.069)     (0.069)       (0.069)   
## I(age2)              -0.001    -0.0005     -0.0005       -0.0005   
##                      (0.001)   (0.001)     (0.001)       (0.001)   
## kids5               -1.409*** -0.855***   -0.855***     -0.854***  
##                      (0.198)   (0.116)     (0.115)       (0.116)   
## huswage             -0.069*** -0.042***   -0.042***     -0.042***  
##                      (0.020)   (0.012)     (0.012)       (0.013)   
## educ                0.244***  0.148***    0.148***      0.148***   
##                      (0.040)   (0.024)     (0.023)       (0.024)   
## Constant             -0.938    -0.620      -0.620        -0.615    
##                      (2.508)   (1.506)     (1.516)       (1.518)   
## -------------------------------------------------------------------
## Observations           753       753         753           753     
## R2                                          0.158                  
## Adjusted R2                                 0.148                  
## Log Likelihood      -459.955  -459.901                  -891.177   
## Akaike Inf. Crit.    931.910   931.802                             
## rho                                         0.018     0.014 (0.203)
## Inverse Mills Ratio                     0.012 (0.152)              
## ===================================================================
## Note:                                   *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print outcome-equation estimates:</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">ols1</span>,<span class="va">heckvan</span>,<span class="va">ml</span>,type <span class="op">=</span> <span class="st">"text"</span>,no.space <span class="op">=</span> <span class="cn">TRUE</span>,omit.stat <span class="op">=</span> <span class="st">"f"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ================================================================
##                                 Dependent variable:             
##                     --------------------------------------------
##                                      log(wage)                  
##                           OLS           Heckman      selection  
##                                        selection                
##                           (1)             (2)           (3)     
## ----------------------------------------------------------------
## educ                    0.106***       0.106***      0.106***   
##                         (0.014)         (0.017)       (0.017)   
## exper                   0.041***       0.041***      0.041***   
##                         (0.013)         (0.013)       (0.013)   
## I(exper2)               -0.001**       -0.001**      -0.001**   
##                         (0.0004)       (0.0004)      (0.0004)   
## city                     0.054           0.053         0.053    
##                         (0.068)         (0.069)       (0.069)   
## Constant               -0.531***        -0.547*      -0.544**   
##                         (0.199)         (0.289)       (0.272)   
## ----------------------------------------------------------------
## Observations              428             753           753     
## R2                       0.158           0.158                  
## Adjusted R2              0.150           0.148                  
## Log Likelihood                                       -891.177   
## rho                                      0.018     0.014 (0.203)
## Inverse Mills Ratio                  0.012 (0.152)              
## Residual Std. Error 0.667 (df = 423)                            
## ================================================================
## Note:                                *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
<div id="models-of-count-data" class="section level2" number="3.5">
<h2>
<span class="header-section-number">3.5</span> Models of Count Data<a class="anchor" aria-label="anchor" href="#models-of-count-data"><i class="fas fa-link"></i></a>
</h2>
<p>Count-data models aim at explaining dependent variables <span class="math inline">\(y_i\)</span> that take integer values. Typically, one may want to account for the number of doctor visits, of customers, of hospital stays, of borrowers’ defaults, of recreational trips, of accidents. Quite often, these data feature large proportion of zeros (see, e.g., Table 20.1 in <span class="citation">Cameron and Trivedi (<a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref">2005</a>)</span>), and/or are skewed to the right.</p>
<div id="poisson-model" class="section level3" number="3.5.1">
<h3>
<span class="header-section-number">3.5.1</span> Poisson model<a class="anchor" aria-label="anchor" href="#poisson-model"><i class="fas fa-link"></i></a>
</h3>
<p>The most basic count-data model is the Poisson model. In this model, we have <span class="math inline">\(y \sim \mathcal{P}(\mu)\)</span>, i.e.
<span class="math display">\[
\mathbb{P}(y=k) = \frac{\mu^k e^{-\mu}}{k!},
\]</span>
implying <span class="math inline">\(\mathbb{E}(y) = \mathbb{V}ar(y) = \mu\)</span>.</p>
<p>the Poisson parameter, <span class="math inline">\(\mu\)</span>, is then assumed to depend on some observed variables, gathered in vector <span class="math inline">\(\mathbf{x}_i\)</span> for entity <span class="math inline">\(i\)</span>. To ensure that <span class="math inline">\(\mu_i \ge 0\)</span>, it is common to take <span class="math inline">\(\mu_i = \exp(\boldsymbol\beta'\mathbf{x}_i)\)</span>, which gives:
<span class="math display">\[
y_i \sim \mathcal{P}(\exp[\boldsymbol\beta'\mathbf{x}_i]).
\]</span></p>
<p>The Poisson regression is intrinsically heteroskedastic (since <span class="math inline">\(\mathbb{V}ar(y_i) = \mu_i = \exp(\boldsymbol\beta'\mathbf{x}_i)\)</span>).</p>
<p>Under the assumption of independence across entities, the log-likelihood is given by:
<span class="math display">\[
\log \mathcal{L}(\boldsymbol\beta;\mathbf{y},\mathbf{X}) = \sum_{i=1}^n (y_i \boldsymbol\beta'\mathbf{x}_i - \exp[\boldsymbol\beta'\mathbf{x}_i] - \ln[y_i!]).
\]</span>
The first-order condition to get the MLE is:
<span class="math display" id="eq:FOCPoisson">\[\begin{equation}
\sum_{i=1}^n (y_i - \exp[\boldsymbol\beta'\mathbf{x}_i])\mathbf{x}_i = \underbrace{\mathbf{0}}_{K \times 1}. \tag{3.23}
\end{equation}\]</span></p>
<p>Eq. <a href="microeconometrics.html#eq:FOCPoisson">(3.23)</a> is equivalent to what would define the <strong>Pseudo Maximum-Likelihood</strong> estimator of <span class="math inline">\(\boldsymbol\beta\)</span> in the (misspecified) model
<span class="math display">\[
y_i \sim i.i.d.\,\mathcal{N}(\exp[\boldsymbol\beta'\mathbf{x}_i],\sigma^2).
\]</span>
That is, Eq. <a href="microeconometrics.html#eq:FOCPoisson">(3.23)</a> also characterizes the (true) ML estimator of <span class="math inline">\(\boldsymbol\beta\)</span> in the previous model.</p>
<p>Since <span class="math inline">\(\mathbb{E}(y_i|\mathbf{x}_i) = \exp(\boldsymbol\beta'\mathbf{x}_i)\)</span>, we have:
<span class="math display">\[
y_i = \exp(\boldsymbol\beta'\mathbf{x}_i) + \varepsilon_i,
\]</span>
with <span class="math inline">\(\mathbb{E}(\varepsilon_i|\mathbf{x}_i) = 0\)</span>. This notably implies that the (N)LS estimator of <span class="math inline">\(\boldsymbol\beta\)</span> is consistent.</p>
<p>How to interpret regression coefficients (the components of <span class="math inline">\(\boldsymbol\beta\)</span>)? We have:
<span class="math display">\[
\frac{\partial \mathbb{E}(y_i|\mathbf{x}_i)}{\partial x_{i,j}} = \beta_j \exp(\boldsymbol\beta'\mathbf{x}_i),
\]</span>
which depends on the considered individual.</p>
<p>The average estimated response is:
<span class="math display">\[
\widehat{\beta}_j \frac{1}{n}\sum_{i=1}^n  \exp(\widehat{\boldsymbol\beta}'\mathbf{x}_i),
\]</span>
which is equal to <span class="math inline">\(\widehat{\beta}_j \overline{y}\)</span> if the model includes a constant (e.g., if <span class="math inline">\(x_{1,i}=1\)</span> for all entities <span class="math inline">\(i\)</span>).</p>
<p>The limitation of the standard Poisson model is that the distribution of <span class="math inline">\(y_i\)</span> conditional on <span class="math inline">\(\mathbf{x}_i\)</span> depends on a single parameter (<span class="math inline">\(\mu_i\)</span>). Besides, there is often a tension between fitting the fraction of zeros, i.e. <span class="math inline">\(\mathbb{P}(y_i=0|\mathbf{x}_i)=\exp[-\exp(\boldsymbol\beta'\mathbf{x}_i)]\)</span>, and the distribution of <span class="math inline">\(y_i|\mathbf{x}_i,y_i&gt;0\)</span>. The following models (negative binomial, or NB model, the Hurdle model, and the Zero-Inflated model) have been designed to address these points.</p>
</div>
<div id="negative-binomial-model" class="section level3" number="3.5.2">
<h3>
<span class="header-section-number">3.5.2</span> Negative binomial model<a class="anchor" aria-label="anchor" href="#negative-binomial-model"><i class="fas fa-link"></i></a>
</h3>
<p>In the negative binomial model, we have:
<span class="math display">\[
y_i|\lambda_i \sim \mathcal{P}(\lambda_i),
\]</span>
but <span class="math inline">\(\lambda_i\)</span> is now random. Specifically, it takes the form:
<span class="math display">\[
\lambda_i = \nu_i \times \exp(\boldsymbol\beta'\mathbf{x}_i),
\]</span>
where <span class="math inline">\(\nu_i \sim \,i.i.d.\,\Gamma(\underbrace{\delta}_{\mbox{shape}},\underbrace{1/\delta}_{\mbox{scale}})\)</span>. That is, the p.d.f. of <span class="math inline">\(\nu_i\)</span> is:
<span class="math display">\[
g(\nu) = \frac{\nu^{\delta - 1}e^{-\nu\delta}\delta^\delta}{\Gamma(\delta)},
\]</span>
where <span class="math inline">\(\Gamma:\,z \mapsto \int_0^{+\infty}t^{z-1}e^{-t}dt\)</span> (and <span class="math inline">\(\Gamma(k+1)=k!\)</span>).</p>
<p>This notably implies that:
<span class="math display">\[
\mathbb{E}(\nu_i) = 1 \quad \mbox{and} \quad \mathbb{V}ar(\nu) = \frac{1}{\delta}.
\]</span></p>
<p>Hence, the p.d.f. of <span class="math inline">\(y_i\)</span> conditional on <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\delta\)</span> (with <span class="math inline">\(\mu=\exp(\boldsymbol\beta'\mathbf{x}_i)\)</span>) is obtained as a mixture of densities:
<span class="math display">\[
\mathbb{P}(y_i=k|\exp(\boldsymbol\beta'\mathbf{x}_i)=\mu;\delta)=\int_0^\infty \frac{e^{-\mu \nu}(\mu \nu)^k}{k!} \frac{\nu^{\delta - 1}e^{-\nu\delta}\delta^\delta}{\Gamma(\delta)} d \nu.
\]</span></p>
<p>It can be shown that:
<span class="math display">\[
\mathbb{E}(y|\mathbf{x}) = \mu \quad \mbox{and}\quad \mathbb{V}ar(y|\mathbf{x}) = \mu\left(1+\alpha \mu\right),
\]</span>
where <span class="math inline">\(\exp(\boldsymbol\beta'\mathbf{x}_i)=\mu\)</span> and <span class="math inline">\(\alpha = 1/\delta\)</span>.</p>
<p>We have one additional degree of freedom w.r.t. the Poisson model (<span class="math inline">\(\alpha\)</span>).</p>
<p>Note that <span class="math inline">\(\mathbb{V}ar(y|\mathbf{x}) &gt; \mathbb{E}(y|\mathbf{x})\)</span> (which is often called for by the data). Moreover, the conditional variance is quadratic in the mean:
<span class="math display">\[
\mathbb{V}ar(y|\mathbf{x}) = \mu+\alpha \mu^2.
\]</span>
The previous expression is the basis of the so-called <strong>NB2</strong> specification. If <span class="math inline">\(\delta\)</span> is replaced with <span class="math inline">\(\mu/\gamma\)</span>, then we get the <strong>NB1</strong> model:
<span class="math display">\[
\mathbb{V}ar(y|\mathbf{x}) = \mu(1+\gamma).
\]</span></p>
<div class="example">
<p><span id="exm:Doctorvisits" class="example"><strong>Example 3.12  (Number of doctor visits) </strong></span>The following example compares different specifications, namely a linear regression model, a Poisson model, and a NB model, to account for the number of doctor visits. The dataset (`<code>randdata</code>) is the one used in Chapter 20 of <span class="citation">Cameron and Trivedi (<a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref">2005</a>)</span> (available on <a href="http://cameron.econ.ucdavis.edu/mmabook/mmadata.html">that page</a>).</p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AEC</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">COUNT</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://github.com/atahk/pscl">pscl</a></span><span class="op">)</span> <span class="co"># for predprob function and hurdle model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>plt<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.15</span>,<span class="fl">.95</span>,<span class="fl">.1</span>,<span class="fl">.95</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">randdata</span><span class="op">$</span><span class="va">mdvis</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:countdata1"></span>
<img src="MicroEc_files/figure-html/countdata1-1.png" alt="Distribution of the number of doctor visits." width="95%"><p class="caption">
Figure 3.13: Distribution of the number of doctor visits.
</p>
</div>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">randdata</span><span class="op">$</span><span class="va">LC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="va">randdata</span><span class="op">$</span><span class="va">coins</span><span class="op">)</span></span>
<span><span class="va">model.OLS</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">mdvis</span> <span class="op">~</span> <span class="va">LC</span> <span class="op">+</span> <span class="va">idp</span> <span class="op">+</span> <span class="va">lpi</span> <span class="op">+</span> <span class="va">fmde</span> <span class="op">+</span> <span class="va">physlm</span> <span class="op">+</span> <span class="va">disea</span> <span class="op">+</span> <span class="va">hlthg</span> <span class="op">+</span> </span>
<span>                  <span class="va">hlthf</span> <span class="op">+</span> <span class="va">hlthp</span> <span class="op">-</span> <span class="fl">1</span>,data<span class="op">=</span><span class="va">randdata</span><span class="op">)</span></span>
<span><span class="va">model.poisson</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">mdvis</span> <span class="op">~</span> <span class="va">LC</span> <span class="op">+</span> <span class="va">idp</span> <span class="op">+</span> <span class="va">lpi</span> <span class="op">+</span> <span class="va">fmde</span> <span class="op">+</span> <span class="va">physlm</span> <span class="op">+</span> <span class="va">disea</span> <span class="op">+</span> </span>
<span>                       <span class="va">hlthg</span> <span class="op">+</span> <span class="va">hlthf</span> <span class="op">+</span> <span class="va">hlthp</span> <span class="op">-</span> <span class="fl">1</span>,data<span class="op">=</span><span class="va">randdata</span>,family <span class="op">=</span> <span class="va">poisson</span><span class="op">)</span></span>
<span><span class="va">model.neg.bin</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/glm.nb.html">glm.nb</a></span><span class="op">(</span><span class="va">mdvis</span> <span class="op">~</span> <span class="va">LC</span> <span class="op">+</span> <span class="va">idp</span> <span class="op">+</span> <span class="va">lpi</span> <span class="op">+</span> <span class="va">fmde</span> <span class="op">+</span> <span class="va">physlm</span> <span class="op">+</span> <span class="va">disea</span> <span class="op">+</span></span>
<span>                          <span class="va">hlthg</span> <span class="op">+</span> <span class="va">hlthf</span> <span class="op">+</span> <span class="va">hlthp</span> <span class="op">-</span> <span class="fl">1</span>,data<span class="op">=</span><span class="va">randdata</span><span class="op">)</span></span>
<span><span class="va">model.neg.bin.with.intercept</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/glm.nb.html">glm.nb</a></span><span class="op">(</span><span class="va">mdvis</span> <span class="op">~</span> <span class="va">LC</span> <span class="op">+</span> <span class="va">idp</span> <span class="op">+</span> <span class="va">lpi</span> <span class="op">+</span> <span class="va">fmde</span> <span class="op">+</span> <span class="va">physlm</span> <span class="op">+</span> <span class="va">disea</span> <span class="op">+</span> <span class="va">hlthg</span> <span class="op">+</span> </span>
<span>           <span class="va">hlthf</span> <span class="op">+</span> <span class="va">hlthp</span>,data<span class="op">=</span><span class="va">randdata</span><span class="op">)</span></span>
<span><span class="fu">stargazer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">model.OLS</span>,<span class="va">model.poisson</span>,<span class="va">model.neg.bin</span>,</span>
<span>                     <span class="va">model.neg.bin.with.intercept</span>,type<span class="op">=</span><span class="st">"text"</span>,</span>
<span>                     no.space <span class="op">=</span> <span class="cn">TRUE</span>,omit.stat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"f"</span>,<span class="st">"ser"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## =========================================================================
##                                     Dependent variable:                  
##                   -------------------------------------------------------
##                                            mdvis                         
##                      OLS      Poisson               negative             
##                                                     binomial             
##                      (1)        (2)           (3)              (4)       
## -------------------------------------------------------------------------
## LC                -0.155***  -0.051***     -0.057***        -0.058***    
##                    (0.020)    (0.003)       (0.006)          (0.006)     
## idp               -0.546***  -0.183***     -0.212***        -0.268***    
##                    (0.075)    (0.011)       (0.023)          (0.023)     
## lpi               0.230***   0.095***       0.088***         0.041***    
##                    (0.012)    (0.002)       (0.004)          (0.004)     
## fmde              -0.073***  -0.029***     -0.030***        -0.038***    
##                    (0.012)    (0.002)       (0.004)          (0.003)     
## physlm            0.945***   0.217***       0.229***         0.269***    
##                    (0.104)    (0.013)       (0.031)          (0.030)     
## disea             0.177***   0.050***       0.062***         0.038***    
##                    (0.004)   (0.0005)       (0.001)          (0.001)     
## hlthg             0.270***   0.126***       0.068***         -0.044**    
##                    (0.066)    (0.009)       (0.020)          (0.020)     
## hlthf             0.455***   0.149***       0.084**           0.017      
##                    (0.123)    (0.016)       (0.037)          (0.036)     
## hlthp             1.537***   0.197***       0.185**          0.178**     
##                    (0.263)    (0.027)       (0.076)          (0.074)     
## Constant                                                     0.664***    
##                                                              (0.025)     
## -------------------------------------------------------------------------
## Observations       20,190     20,190         20,190           20,190     
## R2                  0.322                                                
## Adjusted R2         0.322                                                
## Log Likelihood              -64,221.340   -43,745.860      -43,384.660   
## theta                                   0.732*** (0.010) 0.773*** (0.011)
## Akaike Inf. Crit.           128,460.700    87,509.710       86,789.320   
## =========================================================================
## Note:                                         *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Models’ predictions can be obtained as follows:</p>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># prediction of beta'x, equivalent to "model.poisson$fitted.values":</span></span>
<span><span class="va">predict_poisson.beta.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model.poisson</span><span class="op">)</span></span>
<span><span class="co"># prediction of the number of events (exp(beta'x)):</span></span>
<span><span class="va">predict_poisson</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model.poisson</span>,type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></span>
<span><span class="va">predict_NB</span> <span class="op">&lt;-</span> <span class="va">model.neg.bin</span><span class="op">$</span><span class="va">fitted.values</span></span></code></pre></div>
<p>Let us now compute the model-implied probabilities, and let’s compare them with the frequencies observed in the data.</p>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prop.table.data</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">randdata</span><span class="op">$</span><span class="va">mdvis</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">predprob.poisson</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/pscl/man/predprob.html">predprob</a></span><span class="op">(</span><span class="va">model.poisson</span><span class="op">)</span> <span class="co"># part of pscl package</span></span>
<span><span class="va">predprob.nb</span>      <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/pscl/man/predprob.html">predprob</a></span><span class="op">(</span><span class="va">model.neg.bin</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">prop.table.data</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>,</span>
<span>            <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">predprob.poisson</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>,<span class="fl">2</span>,<span class="va">mean</span><span class="op">)</span>,</span>
<span>            <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">predprob.nb</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>,<span class="fl">2</span>,<span class="va">mean</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>##              0         1         2          3          4          5
## [1,] 0.3124319 0.1890540 0.1385339 0.09331352 0.06661714 0.04794453
## [2,] 0.1220592 0.2230328 0.2271621 0.17173478 0.10888940 0.06244353
## [3,] 0.3486824 0.1884640 0.1219340 0.08385899 0.05968603 0.04350209</code></pre>
<p>It appears that the NB model is better at capturing the relatively large number of zeros than the Poisson model. This will also be the case for the Hurdle and Zero-Inflation models:</p>
</div>
</div>
<div id="hurdle-model" class="section level3" number="3.5.3">
<h3>
<span class="header-section-number">3.5.3</span> Hurdle model<a class="anchor" aria-label="anchor" href="#hurdle-model"><i class="fas fa-link"></i></a>
</h3>
<p>The main objective of this model, w.r.t. the Poisson model, is to generate more zeros in the data than predicted by the previous count models. The idea is to separate the modeling of the number of zeros and that of the number of non-zero counts. Specifically, the frequency of zeros is determined by <span class="math inline">\(f_1\)</span>, the (relative) frequencies of non-zero counts are determined by <span class="math inline">\(f_2\)</span>:
<span class="math display">\[
f(y) = \left\{
\begin{array}{lll}
f_1(0) &amp; \mbox{if $y=0$},\\
\dfrac{1-f_1(0)}{1-f_2(0)}f_2(y) &amp; \mbox{if $y&gt;0$}.
\end{array}
\right.
\]</span></p>
<p>Note that we are back to the standard Poisson model if <span class="math inline">\(f_1 \equiv f_2\)</span>. This model is straightforwardly estimated by ML.</p>
</div>
<div id="zero-inflated-model" class="section level3" number="3.5.4">
<h3>
<span class="header-section-number">3.5.4</span> Zero-inflated model<a class="anchor" aria-label="anchor" href="#zero-inflated-model"><i class="fas fa-link"></i></a>
</h3>
<p>The objective is the same as for the Hurdle model, the modeling is slightly different. It is based on a mixture of a binary process <span class="math inline">\(B\)</span> (p.d.f. <span class="math inline">\(f_1\)</span>) and a process <span class="math inline">\(Z\)</span> (p.d.f. <span class="math inline">\(f_2\)</span>). <span class="math inline">\(B\)</span> and <span class="math inline">\(Z\)</span> are independent. Formally:
<span class="math display">\[
y = B Z,
\]</span>
implying:
<span class="math display">\[
f(y) = \left\{
\begin{array}{lll}
f_1(0) + (1-f_1(0))f_2(0) &amp; \mbox{if $y=0$},\\
(1-f_1(0))f_2(y) &amp; \mbox{if $y&gt;0$}.
\end{array}
\right.
\]</span>
Typically, <span class="math inline">\(f_1\)</span> corresponds to a logit model and <span class="math inline">\(f_2\)</span> is Poisson or negative binomial density. This model is easily estimated by ML techniques.</p>
<div class="example">
<p><span id="exm:Doctorvisits2" class="example"><strong>Example 3.13  (Number of doctor visits) </strong></span>Let us come back to the data used in Example <a href="microeconometrics.html#exm:Doctorvisits">3.12</a>, and estimate Hurdle and a zero-inflation models:</p>
<!-- # See Subsection 2.2 of https://cran.r-project.org/web/packages/pscl/vignettes/countreg.pdf -->
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model.hurdle</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/pscl/man/hurdle.html">hurdle</a></span><span class="op">(</span><span class="va">mdvis</span> <span class="op">~</span> <span class="va">LC</span> <span class="op">+</span> <span class="va">idp</span> <span class="op">+</span> <span class="va">lpi</span> <span class="op">+</span> <span class="va">fmde</span> <span class="op">+</span> <span class="va">physlm</span> <span class="op">+</span> <span class="va">disea</span> <span class="op">+</span> <span class="va">hlthg</span> <span class="op">+</span> <span class="va">hlthf</span> <span class="op">+</span> </span>
<span>           <span class="va">hlthp</span>, data<span class="op">=</span><span class="va">randdata</span>,</span>
<span>         dist <span class="op">=</span> <span class="st">"poisson"</span>, zero.dist <span class="op">=</span> <span class="st">"binomial"</span>, link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span><span class="va">model.zeroinfl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/pscl/man/zeroinfl.html">zeroinfl</a></span><span class="op">(</span><span class="va">mdvis</span> <span class="op">~</span> <span class="va">LC</span> <span class="op">+</span> <span class="va">idp</span> <span class="op">+</span> <span class="va">lpi</span> <span class="op">+</span> <span class="va">fmde</span> <span class="op">+</span> <span class="va">physlm</span> <span class="op">+</span></span>
<span>                             <span class="va">disea</span> <span class="op">+</span> <span class="va">hlthg</span> <span class="op">+</span> <span class="va">hlthf</span> <span class="op">+</span> <span class="va">hlthp</span>, data<span class="op">=</span><span class="va">randdata</span>,</span>
<span>                           dist <span class="op">=</span> <span class="st">"poisson"</span>, link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">model.hurdle</span>,<span class="va">model.zeroinfl</span>,zero.component<span class="op">=</span><span class="cn">FALSE</span>,</span>
<span>          no.space<span class="op">=</span><span class="cn">TRUE</span>,type<span class="op">=</span><span class="st">"text"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ===========================================
##                    Dependent variable:     
##                ----------------------------
##                           mdvis            
##                    hurdle     zero-inflated
##                                count data  
##                     (1)            (2)     
## -------------------------------------------
## LC               -0.015***      -0.015***  
##                   (0.003)        (0.003)   
## idp              -0.085***      -0.086***  
##                   (0.011)        (0.011)   
## lpi               0.010***      0.010***   
##                   (0.002)        (0.002)   
## fmde             -0.021***      -0.021***  
##                   (0.002)        (0.002)   
## physlm            0.231***      0.231***   
##                   (0.012)        (0.012)   
## disea             0.022***      0.022***   
##                   (0.001)        (0.001)   
## hlthg             0.027***      0.026***   
##                   (0.010)        (0.010)   
## hlthf             0.147***      0.146***   
##                   (0.016)        (0.016)   
## hlthp             0.304***      0.303***   
##                   (0.026)        (0.026)   
## Constant          1.133***      1.133***   
##                   (0.012)        (0.012)   
## -------------------------------------------
## Observations       20,190        20,190    
## Log Likelihood  -54,772.100    -54,772.550 
## ===========================================
## Note:           *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">model.hurdle</span>,<span class="va">model.zeroinfl</span>,zero.component<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>          no.space<span class="op">=</span><span class="cn">TRUE</span>,type<span class="op">=</span><span class="st">"text"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ===========================================
##                    Dependent variable:     
##                ----------------------------
##                           mdvis            
##                    hurdle     zero-inflated
##                                count data  
##                     (1)            (2)     
## -------------------------------------------
## LC               -0.150***      0.154***   
##                   (0.010)        (0.011)   
## idp              -0.631***      0.637***   
##                   (0.038)        (0.040)   
## lpi               0.102***      -0.105***  
##                   (0.007)        (0.007)   
## fmde             -0.062***      0.060***   
##                   (0.006)        (0.006)   
## physlm            0.239***      -0.203***  
##                   (0.056)        (0.058)   
## disea             0.062***      -0.059***  
##                   (0.003)        (0.003)   
## hlthg            -0.142***      0.158***   
##                   (0.034)        (0.036)   
## hlthf            -0.352***      0.396***   
##                   (0.062)        (0.064)   
## hlthp              -0.181         0.233    
##                   (0.149)        (0.151)   
## Constant          0.411***      -0.528***  
##                   (0.044)        (0.047)   
## -------------------------------------------
## Observations       20,190        20,190    
## Log Likelihood  -54,772.100    -54,772.550 
## ===========================================
## Note:           *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Let us test the importance of <code>LC</code> in the model using a Wald test:</p>
<div class="sourceCode" id="cb92"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Test whether LC is important in the model:</span></span>
<span><span class="va">model.hurdle.reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">model.hurdle</span>,<span class="va">.</span><span class="op">~</span><span class="va">.</span><span class="op">-</span><span class="va">LC</span><span class="op">)</span></span>
<span><span class="fu">lmtest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">model.hurdle</span>, <span class="va">model.hurdle.reduced</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Wald test
## 
## Model 1: mdvis ~ LC + idp + lpi + fmde + physlm + disea + hlthg + hlthf + 
##     hlthp
## Model 2: mdvis ~ idp + lpi + fmde + physlm + disea + hlthg + hlthf + hlthp
##   Res.Df Df  Chisq Pr(&gt;Chisq)    
## 1  20170                         
## 2  20172 -2 247.64  &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>Finally, we compare average model-implied probabilities with the frequencies observed in the data:</p>
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">predprob.hurdle</span>   <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/pscl/man/predprob.html">predprob</a></span><span class="op">(</span><span class="va">model.hurdle</span><span class="op">)</span></span>
<span><span class="va">predprob.zeroinfl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/pscl/man/predprob.html">predprob</a></span><span class="op">(</span><span class="va">model.zeroinfl</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">prop.table.data</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">predprob.poisson</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>,<span class="fl">2</span>,<span class="va">mean</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">predprob.nb</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>,<span class="fl">2</span>,<span class="va">mean</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">predprob.hurdle</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>,<span class="fl">2</span>,<span class="va">mean</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">predprob.zeroinfl</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>,<span class="fl">2</span>,<span class="va">mean</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>##              0          1         2          3          4          5
## [1,] 0.3124319 0.18905399 0.1385339 0.09331352 0.06661714 0.04794453
## [2,] 0.1220592 0.22303277 0.2271621 0.17173478 0.10888940 0.06244353
## [3,] 0.3486824 0.18846395 0.1219340 0.08385899 0.05968603 0.04350209
## [4,] 0.3124319 0.06056959 0.1083120 0.13262624 0.12553899 0.09847017
## [5,] 0.3124684 0.06053026 0.1082799 0.13262562 0.12556531 0.09850218</code></pre>
</div>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="estimation-methods.html"><span class="header-section-number">2</span> Estimation Methods</a></div>
<div class="next"><a href="append.html"><span class="header-section-number">4</span> Appendix</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#microeconometrics"><span class="header-section-number">3</span> Microeconometrics</a></li>
<li>
<a class="nav-link" href="#binary-choice-models"><span class="header-section-number">3.1</span> Binary-choice models</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#latent"><span class="header-section-number">3.1.1</span> Interpretation in terms of latent variable, and utility-based models</a></li>
<li><a class="nav-link" href="#Avregressors"><span class="header-section-number">3.1.2</span> Alternative-Varying Regressors</a></li>
<li><a class="nav-link" href="#estimation"><span class="header-section-number">3.1.3</span> Estimation</a></li>
<li><a class="nav-link" href="#marginalFX"><span class="header-section-number">3.1.4</span> Marginal effects</a></li>
<li><a class="nav-link" href="#goodness-of-fit"><span class="header-section-number">3.1.5</span> Goodness of fit</a></li>
<li><a class="nav-link" href="#predictions-and-roc-curves"><span class="header-section-number">3.1.6</span> Predictions and ROC curves</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#multiple-choice-models"><span class="header-section-number">3.2</span> Multiple Choice Models</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#ordered-case"><span class="header-section-number">3.2.1</span> Ordered case</a></li>
<li><a class="nav-link" href="#MNL"><span class="header-section-number">3.2.2</span> General multinomial logit model</a></li>
<li><a class="nav-link" href="#nested-logits"><span class="header-section-number">3.2.3</span> Nested logits</a></li>
</ul>
</li>
<li><a class="nav-link" href="#tobit"><span class="header-section-number">3.3</span> Tobit models</a></li>
<li><a class="nav-link" href="#SSM"><span class="header-section-number">3.4</span> Sample Selection Models</a></li>
<li>
<a class="nav-link" href="#models-of-count-data"><span class="header-section-number">3.5</span> Models of Count Data</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#poisson-model"><span class="header-section-number">3.5.1</span> Poisson model</a></li>
<li><a class="nav-link" href="#negative-binomial-model"><span class="header-section-number">3.5.2</span> Negative binomial model</a></li>
<li><a class="nav-link" href="#hurdle-model"><span class="header-section-number">3.5.3</span> Hurdle model</a></li>
<li><a class="nav-link" href="#zero-inflated-model"><span class="header-section-number">3.5.4</span> Zero-inflated model</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Micro-Econometrics</strong>" was written by Jean-Paul Renne. It was last built on 2023-01-28.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
